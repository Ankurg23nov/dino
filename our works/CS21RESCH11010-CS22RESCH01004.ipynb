{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code include\n",
    "1. Setting up the code repository from the paper https://arxiv.org/pdf/2108.06747v2.pdf\n",
    "2. Model training on COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eY34JB2yvGpb",
    "outputId": "5091e3b6-e399-4925-97da-f6e530019c54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.1\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 4.3 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=fc06dabcb7e8bd33fe07bbf489d9206831e626fcd574ff743db594cea777951b\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed pyyaml-5.1\n",
      "torch:  1.10 ; cuda:  cu111\n",
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
      "Collecting detectron2\n",
      "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
      "Collecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 4.3 MB/s \n",
      "\u001b[?25hCollecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20220305.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.8 MB/s \n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
      "Collecting yacs>=0.1.8\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
      "Collecting omegaconf>=2.1\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 3.4 MB/s \n",
      "\u001b[?25hCollecting black==21.4b2\n",
      "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 42.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.63.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
      "Collecting toml>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pathspec<1,>=0.8.1\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
      "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Collecting typed-ast>=1.4.2\n",
      "  Downloading typed_ast-1.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
      "\u001b[K     |████████████████████████████████| 843 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting regex>=2020.1.8\n",
      "  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "\u001b[K     |████████████████████████████████| 749 kB 42.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 53.1 MB/s \n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.44.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n",
      "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220305-py3-none-any.whl size=61214 sha256=7bf2b357c38192460e856f0af89c27cd75a8f0cc233788c4b3be230b5de4295a\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/b7/6e/43b1693d06fac3633af48db68557513b0a37ab38b0a8b798f9\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=a27a3b0bf7f890678563875cabd9512b3962f165d9ff247b2453fcb0e890e223\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
      "Successfully built fvcore antlr4-python3-runtime\n",
      "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, toml, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2019.12.20\n",
      "    Uninstalling regex-2019.12.20:\n",
      "      Successfully uninstalled regex-2019.12.20\n",
      "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20220305 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.4.0 regex-2022.3.15 toml-0.10.2 typed-ast-1.5.2 yacs-0.1.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install pyyaml==5.1\n",
    "\n",
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
    "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "\n",
    "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y_GkiP55OMdK"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "#!pip install -q torchaudio==0.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oJOc8pE7Gq7"
   },
   "outputs": [],
   "source": [
    "!python -m pip install detectron2==0.2.1 -f \\\n",
    "  https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWHb24z8qT9i"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "#assert torch.__version__.startswith(\"1.9\")\n",
    "import torchvision\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k14NTaBSfvy_",
    "outputId": "27b1e503-8af4-4af5-a62a-ac60e5d85265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SOTR'...\n",
      "remote: Enumerating objects: 200, done.\u001b[K\n",
      "remote: Counting objects: 100% (200/200), done.\u001b[K\n",
      "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
      "remote: Total 200 (delta 48), reused 133 (delta 13), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (200/200), 588.77 KiB | 4.09 MiB/s, done.\n",
      "Resolving deltas: 100% (48/48), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/easton-cau/SOTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rs3tn8lagL_f",
    "outputId": "5186a3e6-2337-4548-ad90-434c607489ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/adet\n",
      "copying adet/__init__.py -> build/lib.linux-x86_64-3.7/adet\n",
      "creating build/lib.linux-x86_64-3.7/adet/checkpoint\n",
      "copying adet/checkpoint/adet_checkpoint.py -> build/lib.linux-x86_64-3.7/adet/checkpoint\n",
      "copying adet/checkpoint/__init__.py -> build/lib.linux-x86_64-3.7/adet/checkpoint\n",
      "creating build/lib.linux-x86_64-3.7/adet/data\n",
      "copying adet/data/builtin.py -> build/lib.linux-x86_64-3.7/adet/data\n",
      "copying adet/data/dataset_mapper.py -> build/lib.linux-x86_64-3.7/adet/data\n",
      "copying adet/data/detection_utils.py -> build/lib.linux-x86_64-3.7/adet/data\n",
      "copying adet/data/augmentation.py -> build/lib.linux-x86_64-3.7/adet/data\n",
      "copying adet/data/__init__.py -> build/lib.linux-x86_64-3.7/adet/data\n",
      "creating build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/naive_group_norm.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/bezier_align.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/def_roi_align.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/iou_loss.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/conv_with_kaiming_uniform.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/ml_nms.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/__init__.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/gcn.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "copying adet/layers/deform_conv.py -> build/lib.linux-x86_64-3.7/adet/layers\n",
      "creating build/lib.linux-x86_64-3.7/adet/modeling\n",
      "copying adet/modeling/__init__.py -> build/lib.linux-x86_64-3.7/adet/modeling\n",
      "creating build/lib.linux-x86_64-3.7/adet/evaluation\n",
      "copying adet/evaluation/text_evaluation.py -> build/lib.linux-x86_64-3.7/adet/evaluation\n",
      "copying adet/evaluation/text_eval_script.py -> build/lib.linux-x86_64-3.7/adet/evaluation\n",
      "copying adet/evaluation/__init__.py -> build/lib.linux-x86_64-3.7/adet/evaluation\n",
      "copying adet/evaluation/rrc_evaluation_funcs.py -> build/lib.linux-x86_64-3.7/adet/evaluation\n",
      "creating build/lib.linux-x86_64-3.7/adet/utils\n",
      "copying adet/utils/comm.py -> build/lib.linux-x86_64-3.7/adet/utils\n",
      "copying adet/utils/measures.py -> build/lib.linux-x86_64-3.7/adet/utils\n",
      "copying adet/utils/__init__.py -> build/lib.linux-x86_64-3.7/adet/utils\n",
      "copying adet/utils/visualizer.py -> build/lib.linux-x86_64-3.7/adet/utils\n",
      "creating build/lib.linux-x86_64-3.7/adet/structures\n",
      "copying adet/structures/beziers.py -> build/lib.linux-x86_64-3.7/adet/structures\n",
      "copying adet/structures/__init__.py -> build/lib.linux-x86_64-3.7/adet/structures\n",
      "creating build/lib.linux-x86_64-3.7/adet/config\n",
      "copying adet/config/defaults.py -> build/lib.linux-x86_64-3.7/adet/config\n",
      "copying adet/config/__init__.py -> build/lib.linux-x86_64-3.7/adet/config\n",
      "copying adet/config/config.py -> build/lib.linux-x86_64-3.7/adet/config\n",
      "creating build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/mobilenet.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/lpf.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/bifpn.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/resnet_interval.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/dla.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/resnet_lpf.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/vovnet.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "copying adet/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.7/adet/modeling/backbone\n",
      "creating build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "copying adet/modeling/sotr/transformer.py -> build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "copying adet/modeling/sotr/utils.py -> build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "copying adet/modeling/sotr/reversible.py -> build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "copying adet/modeling/sotr/__init__.py -> build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "copying adet/modeling/sotr/sotr.py -> build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "copying adet/modeling/sotr/loss.py -> build/lib.linux-x86_64-3.7/adet/modeling/sotr\n",
      "running build_ext\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "building 'adet._C' extension\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/content\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR/adet\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR/adet/layers\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/BezierAlign\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/ml_nms\n",
      "creating build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/DefROIAlign\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/SOTR/adet/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/SOTR/adet/layers/csrc/vision.cpp -o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:3:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::ml_nms(const at::Tensor&, const at::Tensor&, const at::Tensor&, float)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:18:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (dets.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:2\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:4:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::DefROIAlign_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, float, int, int, int, float, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign.h:47:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:2\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:4:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::DefROIAlign_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int, float, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign.h:82:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (grad.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:2\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:5:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:62:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:2\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:5:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:98:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (grad.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.h:2\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/SOTR/adet/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp -o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:62:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/TensorUtils.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:98:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   if (grad.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
      "                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/TensorUtils.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K, \"BezierAlign_forward\", [&] {\n",
      "                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:276:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                               \\\n",
      "                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/TensorUtils.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:278:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                      \\\n",
      "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"BezierAlign_forward\", [&] {\n",
      "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:176:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
      "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K, \"BezierAlign_forward\", [&] {\n",
      "                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:276:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                               \\\n",
      "                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/TensorUtils.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:278:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                      \\\n",
      "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
      "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(grad.type(), \"BezierAlign_forward\", [&] {\n",
      "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:176:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
      "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/SOTR/adet/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/SOTR/adet/layers/csrc/ml_nms/ml_nms.cu -o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::ml_nms_cuda(at::Tensor, float)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.cu:78:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_ASSERTM(boxes.type().is_cuda(), \"boxes must be a CUDA te\u001b[01;35m\u001b[Kn\u001b[m\u001b[Ksor\");\n",
      "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
      " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.cu:87:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   scalar_t* boxes_dev = boxes_sorted.data<scalar_\u001b[01;35m\u001b[Kt\u001b[m\u001b[K>();\n",
      "                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
      " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.cu:115:46:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   int64_t* keep_out = keep.data<int64_t>();\n",
      "                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
      " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/SOTR/adet/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cuda.cu -o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/SOTR/adet/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.cu -o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/SOTR/adet/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/SOTR/adet/layers/csrc/cuda_version.cu -o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/cuda_version.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/vision.o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cpu.o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/ml_nms/ml_nms.o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/BezierAlign/BezierAlign_cuda.o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.o build/temp.linux-x86_64-3.7/content/SOTR/adet/layers/csrc/cuda_version.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/adet/_C.cpython-37m-x86_64-linux-gnu.so\n",
      "running develop\n",
      "running egg_info\n",
      "creating AdelaiDet.egg-info\n",
      "writing AdelaiDet.egg-info/PKG-INFO\n",
      "writing dependency_links to AdelaiDet.egg-info/dependency_links.txt\n",
      "writing requirements to AdelaiDet.egg-info/requires.txt\n",
      "writing top-level names to AdelaiDet.egg-info/top_level.txt\n",
      "writing manifest file 'AdelaiDet.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'AdelaiDet.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "copying build/lib.linux-x86_64-3.7/adet/_C.cpython-37m-x86_64-linux-gnu.so -> adet\n",
      "Creating /usr/local/lib/python3.7/dist-packages/AdelaiDet.egg-link (link to .)\n",
      "Adding AdelaiDet 0.2.0 to easy-install.pth file\n",
      "\n",
      "Installed /content/SOTR\n",
      "Processing dependencies for AdelaiDet==0.2.0\n",
      "Searching for Polygon3\n",
      "Reading https://pypi.org/simple/Polygon3/\n",
      "Downloading https://files.pythonhosted.org/packages/1f/26/eea4112be43c8b7345477ad9150d499303494f32fb5951cb0f6e9104045b/Polygon3-3.0.9.1.tar.gz#sha256=2ddf8d06975f728d5b40786136c82e5b9d38a846bce236b7e6587bbd6a5e9b49\n",
      "Best match: Polygon3 3.0.9.1\n",
      "Processing Polygon3-3.0.9.1.tar.gz\n",
      "Writing /tmp/easy_install-4aay5k5l/Polygon3-3.0.9.1/setup.cfg\n",
      "Running Polygon3-3.0.9.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-4aay5k5l/Polygon3-3.0.9.1/egg-dist-tmp-7shbhlhn\n",
      "Using NumPy extension!\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgpc_polygon_clip\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1471:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdy\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kbuild_intersection_table(&it, aet, dy)\u001b[m\u001b[K;\n",
      "       \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1672:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kyt\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "         if \u001b[01;35m\u001b[K(\u001b[m\u001b[K(edge->top.y == yt) && succ_edge)\n",
      "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1133:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktr\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   int            vclass, bl, br, tl, \u001b[01;35m\u001b[Ktr\u001b[m\u001b[K;\n",
      "                                      \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1133:34:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktl\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   int            vclass, bl, br, \u001b[01;35m\u001b[Ktl\u001b[m\u001b[K, tr;\n",
      "                                  \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1133:30:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kbr\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   int            vclass, bl, \u001b[01;35m\u001b[Kbr\u001b[m\u001b[K, tl, tr;\n",
      "                              \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1328:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kbl\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "         vclass= tr + (tl << 1) + (br << 2) + \u001b[01;35m\u001b[K(bl << 3)\u001b[m\u001b[K;\n",
      "                                              \u001b[01;35m\u001b[K~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1330:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kcontributing\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "         if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kcontributing)\n",
      "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgpc_tristrip_clip\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:2131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdy\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kbuild_intersection_table(&it, aet, dy)\u001b[m\u001b[K;\n",
      "       \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:2361:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kyt\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "         if \u001b[01;35m\u001b[K(\u001b[m\u001b[K(edge->top.y == yt) && succ_edge)\n",
      "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1794:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktr\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   int            vclass, bl, br, tl, \u001b[01;35m\u001b[Ktr\u001b[m\u001b[K;\n",
      "                                      \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1794:34:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Ktl\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   int            vclass, bl, br, \u001b[01;35m\u001b[Ktl\u001b[m\u001b[K, tr;\n",
      "                                  \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1794:30:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kbr\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   int            vclass, bl, \u001b[01;35m\u001b[Kbr\u001b[m\u001b[K, tl, tr;\n",
      "                              \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1981:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kbl\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "         vclass= tr + (tl << 1) + (br << 2) + \u001b[01;35m\u001b[K(bl << 3)\u001b[m\u001b[K;\n",
      "                                              \u001b[01;35m\u001b[K~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:1983:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kcontributing\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "         if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kcontributing)\n",
      "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:2062:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kcft\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "             if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kcft == LED)\n",
      "                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/gpc.c:2064:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kcf\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "               if (\u001b[01;35m\u001b[Kcf->bot.y\u001b[m\u001b[K == yb)\n",
      "                   \u001b[01;35m\u001b[K~~~~~~~^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Ksrc/PolyUtil.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpoly_p_point_inside\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Ksrc/PolyUtil.c:197:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KinSolid\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "     return \u001b[01;35m\u001b[KinSolid\u001b[m\u001b[K;\n",
      "            \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "Polygon.__pycache__.cPolygon.cpython-37: module references __file__\n",
      "creating /usr/local/lib/python3.7/dist-packages/Polygon3-3.0.9.1-py3.7-linux-x86_64.egg\n",
      "Extracting Polygon3-3.0.9.1-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding Polygon3 3.0.9.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/Polygon3-3.0.9.1-py3.7-linux-x86_64.egg\n",
      "Searching for python-Levenshtein\n",
      "Reading https://pypi.org/simple/python-Levenshtein/\n",
      "Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz#sha256=dc2395fbd148a1ab31090dd113c366695934b9e85fe5a4b2a032745efd0346f6\n",
      "Best match: python-Levenshtein 0.12.2\n",
      "Processing python-Levenshtein-0.12.2.tar.gz\n",
      "Writing /tmp/easy_install-haoowg12/python-Levenshtein-0.12.2/setup.cfg\n",
      "Running python-Levenshtein-0.12.2/setup.py -q bdist_egg --dist-dir /tmp/easy_install-haoowg12/python-Levenshtein-0.12.2/egg-dist-tmp-n_z32mwq\n",
      "warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
      "warning: no previously-included files matching '*so' found anywhere in distribution\n",
      "warning: no previously-included files matching '.project' found anywhere in distribution\n",
      "warning: no previously-included files matching '.pydevproject' found anywhere in distribution\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Klevenshtein_common\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:731:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:732:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Khamming_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:816:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:817:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kjaro_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:860:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:861:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kjaro_winkler_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:910:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:911:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmedian_common\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1012:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in passing argument 1 of ‘\u001b[01m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K’ differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "       result = PyString_FromStringAndSize(\u001b[01;35m\u001b[Kmedstr\u001b[m\u001b[K, len);\n",
      "                                           \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python3.7m/Python.h:98:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KLevenshtein/_levenshtein.c:99\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/python3.7m/bytesobject.h:51:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst char *\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Klev_byte * {aka unsigned char *}\u001b[m\u001b[K’\n",
      " PyAPI_FUNC(PyObject *) \u001b[01;36m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K(const char *, Py_ssize_t);\n",
      "                        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmedian_improve_common\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/usr/include/python3.7m/bytesobject.h:87:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in initialization differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      " #define PyBytes_AS_STRING(op) \u001b[01;35m\u001b[K(\u001b[m\u001b[Kassert(PyBytes_Check(op)), \\\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:106:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KPyBytes_AS_STRING\u001b[m\u001b[K’\n",
      " #define PyString_AS_STRING \u001b[01;36m\u001b[KPyBytes_AS_STRING\u001b[m\u001b[K\n",
      "                            \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1091:19:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KPyString_AS_STRING\u001b[m\u001b[K’\n",
      "     lev_byte *s = \u001b[01;36m\u001b[KPyString_AS_STRING\u001b[m\u001b[K(arg1);\n",
      "                   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1097:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in passing argument 1 of ‘\u001b[01m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K’ differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "       result = PyString_FromStringAndSize(\u001b[01;35m\u001b[Kmedstr\u001b[m\u001b[K, len);\n",
      "                                           \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python3.7m/Python.h:98:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KLevenshtein/_levenshtein.c:99\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/python3.7m/bytesobject.h:51:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst char *\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Klev_byte * {aka unsigned char *}\u001b[m\u001b[K’\n",
      " PyAPI_FUNC(PyObject *) \u001b[01;36m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K(const char *, Py_ssize_t);\n",
      "                        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kextract_weightlist\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1135:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      "     if (PySequence_Fast_GET_SIZE(wlist) \u001b[01;35m\u001b[K!=\u001b[m\u001b[K n) {\n",
      "                                         \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kextract_stringlist\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1221:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     strings[0] \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(first);\n",
      "                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1233:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "       strings[i] \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(item);\n",
      "                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstring_to_edittype\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1399:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Klen\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      "   size_t i, \u001b[01;35m\u001b[Klen\u001b[m\u001b[K;\n",
      "             \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1398:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ks\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      "   const char *\u001b[01;35m\u001b[Ks\u001b[m\u001b[K;\n",
      "               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Keditops_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1670:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1671:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kopcodes_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1788:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1789:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kapply_edit_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1883:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string1 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg1);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1884:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in assignment differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "     string2 \u001b[01;35m\u001b[K=\u001b[m\u001b[K PyString_AS_STRING(arg2);\n",
      "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1898:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in passing argument 1 of ‘\u001b[01m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K’ differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "       result = PyString_FromStringAndSize(\u001b[01;35m\u001b[Ks\u001b[m\u001b[K, len);\n",
      "                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python3.7m/Python.h:98:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KLevenshtein/_levenshtein.c:99\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/python3.7m/bytesobject.h:51:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst char *\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Klev_byte * {aka unsigned char *}\u001b[m\u001b[K’\n",
      " PyAPI_FUNC(PyObject *) \u001b[01;36m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K(const char *, Py_ssize_t);\n",
      "                        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:1914:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpointer targets in passing argument 1 of ‘\u001b[01m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K’ differ in signedness [\u001b[01;35m\u001b[K-Wpointer-sign\u001b[m\u001b[K]\n",
      "       result = PyString_FromStringAndSize(\u001b[01;35m\u001b[Ks\u001b[m\u001b[K, len);\n",
      "                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python3.7m/Python.h:98:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KLevenshtein/_levenshtein.c:99\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/python3.7m/bytesobject.h:51:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kconst char *\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Klev_byte * {aka unsigned char *}\u001b[m\u001b[K’\n",
      " PyAPI_FUNC(PyObject *) \u001b[01;36m\u001b[KPyBytes_FromStringAndSize\u001b[m\u001b[K(const char *, Py_ssize_t);\n",
      "                        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ksubtract_edit_py\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:2080:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      "           if (!orem && nr \u001b[01;35m\u001b[K==\u001b[m\u001b[K -1) {\n",
      "                           \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "At top level:\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:6720:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Klev_opcodes_total_cost\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " \u001b[01;35m\u001b[Klev_opcodes_total_cost\u001b[m\u001b[K(size_t nb,\n",
      " \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:6675:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Klev_editops_normalize\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " \u001b[01;35m\u001b[Klev_editops_normalize\u001b[m\u001b[K(size_t n,\n",
      " \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:6650:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Klev_editops_total_cost\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " \u001b[01;35m\u001b[Klev_editops_total_cost\u001b[m\u001b[K(size_t n,\n",
      " \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:2570:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Klev_u_edit_distance_sod\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " \u001b[01;35m\u001b[Klev_u_edit_distance_sod\u001b[m\u001b[K(size_t len, const lev_wchar *string,\n",
      " \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KLevenshtein/_levenshtein.c:2391:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Klev_edit_distance_sod\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " \u001b[01;35m\u001b[Klev_edit_distance_sod\u001b[m\u001b[K(size_t len, const lev_byte *string,\n",
      " \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "creating /usr/local/lib/python3.7/dist-packages/python_Levenshtein-0.12.2-py3.7-linux-x86_64.egg\n",
      "Extracting python_Levenshtein-0.12.2-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding python-Levenshtein 0.12.2 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/python_Levenshtein-0.12.2-py3.7-linux-x86_64.egg\n",
      "Searching for Shapely==1.8.1.post1\n",
      "Best match: Shapely 1.8.1.post1\n",
      "Adding Shapely 1.8.1.post1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tensorboard==2.8.0\n",
      "Best match: tensorboard 2.8.0\n",
      "Adding tensorboard 2.8.0 to easy-install.pth file\n",
      "Installing tensorboard script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tqdm==4.63.0\n",
      "Best match: tqdm 4.63.0\n",
      "Adding tqdm 4.63.0 to easy-install.pth file\n",
      "Installing tqdm script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for matplotlib==3.2.2\n",
      "Best match: matplotlib 3.2.2\n",
      "Adding matplotlib 3.2.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for cloudpickle==1.3.0\n",
      "Best match: cloudpickle 1.3.0\n",
      "Adding cloudpickle 1.3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tabulate==0.8.9\n",
      "Best match: tabulate 0.8.9\n",
      "Adding tabulate 0.8.9 to easy-install.pth file\n",
      "Installing tabulate script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for yacs==0.1.8\n",
      "Best match: yacs 0.1.8\n",
      "Adding yacs 0.1.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Pillow==7.1.2\n",
      "Best match: Pillow 7.1.2\n",
      "Adding Pillow 7.1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for termcolor==1.1.0\n",
      "Best match: termcolor 1.1.0\n",
      "Adding termcolor 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for setuptools==57.4.0\n",
      "Best match: setuptools 57.4.0\n",
      "Adding setuptools 57.4.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for numpy==1.21.5\n",
      "Best match: numpy 1.21.5\n",
      "Adding numpy 1.21.5 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.7 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for google-auth-oauthlib==0.4.6\n",
      "Best match: google-auth-oauthlib 0.4.6\n",
      "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
      "Installing google-oauthlib-tool script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for protobuf==3.17.3\n",
      "Best match: protobuf 3.17.3\n",
      "Adding protobuf 3.17.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for requests==2.23.0\n",
      "Best match: requests 2.23.0\n",
      "Adding requests 2.23.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Markdown==3.3.6\n",
      "Best match: Markdown 3.3.6\n",
      "Adding Markdown 3.3.6 to easy-install.pth file\n",
      "Installing markdown_py script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Werkzeug==1.0.1\n",
      "Best match: Werkzeug 1.0.1\n",
      "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tensorboard-data-server==0.6.1\n",
      "Best match: tensorboard-data-server 0.6.1\n",
      "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for absl-py==1.0.0\n",
      "Best match: absl-py 1.0.0\n",
      "Adding absl-py 1.0.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for wheel==0.37.1\n",
      "Best match: wheel 0.37.1\n",
      "Adding wheel 0.37.1 to easy-install.pth file\n",
      "Installing wheel script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for google-auth==1.35.0\n",
      "Best match: google-auth 1.35.0\n",
      "Adding google-auth 1.35.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for grpcio==1.44.0\n",
      "Best match: grpcio 1.44.0\n",
      "Adding grpcio 1.44.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tensorboard-plugin-wit==1.8.1\n",
      "Best match: tensorboard-plugin-wit 1.8.1\n",
      "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for kiwisolver==1.4.0\n",
      "Best match: kiwisolver 1.4.0\n",
      "Adding kiwisolver 1.4.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pyparsing==3.0.7\n",
      "Best match: pyparsing 3.0.7\n",
      "Adding pyparsing 3.0.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for PyYAML==5.1\n",
      "Best match: PyYAML 5.1\n",
      "Adding PyYAML 5.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for requests-oauthlib==1.3.1\n",
      "Best match: requests-oauthlib 1.3.1\n",
      "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for certifi==2021.10.8\n",
      "Best match: certifi 2021.10.8\n",
      "Adding certifi 2021.10.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for idna==2.10\n",
      "Best match: idna 2.10\n",
      "Adding idna 2.10 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for chardet==3.0.4\n",
      "Best match: chardet 3.0.4\n",
      "Adding chardet 3.0.4 to easy-install.pth file\n",
      "Installing chardetect script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for urllib3==1.24.3\n",
      "Best match: urllib3 1.24.3\n",
      "Adding urllib3 1.24.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for importlib-metadata==4.11.3\n",
      "Best match: importlib-metadata 4.11.3\n",
      "Adding importlib-metadata 4.11.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for rsa==4.8\n",
      "Best match: rsa 4.8\n",
      "Adding rsa 4.8 to easy-install.pth file\n",
      "Installing pyrsa-decrypt script to /usr/local/bin\n",
      "Installing pyrsa-encrypt script to /usr/local/bin\n",
      "Installing pyrsa-keygen script to /usr/local/bin\n",
      "Installing pyrsa-priv2pub script to /usr/local/bin\n",
      "Installing pyrsa-sign script to /usr/local/bin\n",
      "Installing pyrsa-verify script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pyasn1-modules==0.2.8\n",
      "Best match: pyasn1-modules 0.2.8\n",
      "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for cachetools==4.2.4\n",
      "Best match: cachetools 4.2.4\n",
      "Adding cachetools 4.2.4 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for typing-extensions==3.10.0.2\n",
      "Best match: typing-extensions 3.10.0.2\n",
      "Adding typing-extensions 3.10.0.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for oauthlib==3.2.0\n",
      "Best match: oauthlib 3.2.0\n",
      "Adding oauthlib 3.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for zipp==3.7.0\n",
      "Best match: zipp 3.7.0\n",
      "Adding zipp 3.7.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pyasn1==0.4.8\n",
      "Best match: pyasn1 0.4.8\n",
      "Adding pyasn1 0.4.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Finished processing dependencies for AdelaiDet==0.2.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"/content/SOTR\")\n",
    "!python setup.py build develop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvRMuGXpcFrH"
   },
   "outputs": [],
   "source": [
    "#!wget http://images.cocodataset.org/zips/train2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYeCAvOUyr_V",
    "outputId": "6bddc84f-41a6-4db2-fa39-0727e8fa3b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      " extracting: val2017/000000365745.jpg  \n",
      " extracting: val2017/000000320425.jpg  \n",
      " extracting: val2017/000000481404.jpg  \n",
      " extracting: val2017/000000314294.jpg  \n",
      " extracting: val2017/000000335328.jpg  \n",
      " extracting: val2017/000000513688.jpg  \n",
      " extracting: val2017/000000158548.jpg  \n",
      " extracting: val2017/000000132116.jpg  \n",
      " extracting: val2017/000000415238.jpg  \n",
      " extracting: val2017/000000321333.jpg  \n",
      " extracting: val2017/000000081738.jpg  \n",
      " extracting: val2017/000000577584.jpg  \n",
      " extracting: val2017/000000346905.jpg  \n",
      " extracting: val2017/000000433980.jpg  \n",
      " extracting: val2017/000000228144.jpg  \n",
      " extracting: val2017/000000041872.jpg  \n",
      " extracting: val2017/000000117492.jpg  \n",
      " extracting: val2017/000000368900.jpg  \n",
      " extracting: val2017/000000376900.jpg  \n",
      " extracting: val2017/000000352491.jpg  \n",
      " extracting: val2017/000000330790.jpg  \n",
      " extracting: val2017/000000384850.jpg  \n",
      " extracting: val2017/000000032735.jpg  \n",
      " extracting: val2017/000000197004.jpg  \n",
      " extracting: val2017/000000526751.jpg  \n",
      " extracting: val2017/000000041488.jpg  \n",
      " extracting: val2017/000000153632.jpg  \n",
      " extracting: val2017/000000501523.jpg  \n",
      " extracting: val2017/000000405691.jpg  \n",
      " extracting: val2017/000000040757.jpg  \n",
      " extracting: val2017/000000219485.jpg  \n",
      " extracting: val2017/000000428280.jpg  \n",
      " extracting: val2017/000000209222.jpg  \n",
      " extracting: val2017/000000353051.jpg  \n",
      " extracting: val2017/000000191471.jpg  \n",
      " extracting: val2017/000000539962.jpg  \n",
      " extracting: val2017/000000462371.jpg  \n",
      " extracting: val2017/000000574315.jpg  \n",
      " extracting: val2017/000000005037.jpg  \n",
      " extracting: val2017/000000083540.jpg  \n",
      " extracting: val2017/000000145665.jpg  \n",
      " extracting: val2017/000000174231.jpg  \n",
      " extracting: val2017/000000389812.jpg  \n",
      " extracting: val2017/000000245513.jpg  \n",
      " extracting: val2017/000000122046.jpg  \n",
      " extracting: val2017/000000143931.jpg  \n",
      " extracting: val2017/000000555005.jpg  \n",
      " extracting: val2017/000000142472.jpg  \n",
      " extracting: val2017/000000246883.jpg  \n",
      " extracting: val2017/000000459272.jpg  \n",
      " extracting: val2017/000000356261.jpg  \n",
      " extracting: val2017/000000169996.jpg  \n",
      " extracting: val2017/000000311909.jpg  \n",
      " extracting: val2017/000000253433.jpg  \n",
      " extracting: val2017/000000396568.jpg  \n",
      " extracting: val2017/000000089045.jpg  \n",
      " extracting: val2017/000000387383.jpg  \n",
      " extracting: val2017/000000095155.jpg  \n",
      " extracting: val2017/000000036494.jpg  \n",
      " extracting: val2017/000000495054.jpg  \n",
      " extracting: val2017/000000297595.jpg  \n",
      " extracting: val2017/000000030213.jpg  \n",
      " extracting: val2017/000000357903.jpg  \n",
      " extracting: val2017/000000231237.jpg  \n",
      " extracting: val2017/000000182805.jpg  \n",
      " extracting: val2017/000000147740.jpg  \n",
      " extracting: val2017/000000424721.jpg  \n",
      " extracting: val2017/000000165257.jpg  \n",
      " extracting: val2017/000000080340.jpg  \n",
      " extracting: val2017/000000295420.jpg  \n",
      " extracting: val2017/000000289659.jpg  \n",
      " extracting: val2017/000000529528.jpg  \n",
      " extracting: val2017/000000360951.jpg  \n",
      " extracting: val2017/000000000885.jpg  \n",
      " extracting: val2017/000000552842.jpg  \n",
      " extracting: val2017/000000466156.jpg  \n",
      " extracting: val2017/000000309452.jpg  \n",
      " extracting: val2017/000000015254.jpg  \n",
      " extracting: val2017/000000442323.jpg  \n",
      " extracting: val2017/000000561335.jpg  \n",
      " extracting: val2017/000000324927.jpg  \n",
      " extracting: val2017/000000198489.jpg  \n",
      " extracting: val2017/000000163290.jpg  \n",
      " extracting: val2017/000000001425.jpg  \n",
      " extracting: val2017/000000280891.jpg  \n",
      " extracting: val2017/000000003661.jpg  \n",
      " extracting: val2017/000000383838.jpg  \n",
      " extracting: val2017/000000409268.jpg  \n",
      " extracting: val2017/000000112798.jpg  \n",
      " extracting: val2017/000000288584.jpg  \n",
      " extracting: val2017/000000231879.jpg  \n",
      " extracting: val2017/000000496571.jpg  \n",
      " extracting: val2017/000000143998.jpg  \n",
      " extracting: val2017/000000404191.jpg  \n",
      " extracting: val2017/000000066817.jpg  \n",
      " extracting: val2017/000000381360.jpg  \n",
      " extracting: val2017/000000376307.jpg  \n",
      " extracting: val2017/000000424545.jpg  \n",
      " extracting: val2017/000000085576.jpg  \n",
      " extracting: val2017/000000400044.jpg  \n",
      " extracting: val2017/000000066886.jpg  \n",
      " extracting: val2017/000000509656.jpg  \n",
      " extracting: val2017/000000308753.jpg  \n",
      " extracting: val2017/000000315492.jpg  \n",
      " extracting: val2017/000000359855.jpg  \n",
      " extracting: val2017/000000161820.jpg  \n",
      " extracting: val2017/000000090208.jpg  \n",
      " extracting: val2017/000000233567.jpg  \n",
      " extracting: val2017/000000182441.jpg  \n",
      " extracting: val2017/000000146825.jpg  \n",
      " extracting: val2017/000000459757.jpg  \n",
      " extracting: val2017/000000229311.jpg  \n",
      " extracting: val2017/000000164115.jpg  \n",
      " extracting: val2017/000000323799.jpg  \n",
      " extracting: val2017/000000534041.jpg  \n",
      " extracting: val2017/000000341094.jpg  \n",
      " extracting: val2017/000000485480.jpg  \n",
      " extracting: val2017/000000322829.jpg  \n",
      " extracting: val2017/000000142585.jpg  \n",
      " extracting: val2017/000000388215.jpg  \n",
      " extracting: val2017/000000279887.jpg  \n",
      " extracting: val2017/000000027972.jpg  \n",
      " extracting: val2017/000000029393.jpg  \n",
      " extracting: val2017/000000428562.jpg  \n",
      " extracting: val2017/000000338624.jpg  \n",
      " extracting: val2017/000000485027.jpg  \n",
      " extracting: val2017/000000550714.jpg  \n",
      " extracting: val2017/000000018833.jpg  \n",
      " extracting: val2017/000000121506.jpg  \n",
      " extracting: val2017/000000259690.jpg  \n",
      " extracting: val2017/000000509258.jpg  \n",
      " extracting: val2017/000000046048.jpg  \n",
      " extracting: val2017/000000113354.jpg  \n",
      " extracting: val2017/000000315187.jpg  \n",
      " extracting: val2017/000000262487.jpg  \n",
      " extracting: val2017/000000067180.jpg  \n",
      " extracting: val2017/000000145591.jpg  \n",
      " extracting: val2017/000000261097.jpg  \n",
      " extracting: val2017/000000063552.jpg  \n",
      " extracting: val2017/000000510329.jpg  \n",
      " extracting: val2017/000000261061.jpg  \n",
      " extracting: val2017/000000137950.jpg  \n",
      " extracting: val2017/000000379533.jpg  \n",
      " extracting: val2017/000000524280.jpg  \n",
      " extracting: val2017/000000306700.jpg  \n",
      " extracting: val2017/000000345252.jpg  \n",
      " extracting: val2017/000000010583.jpg  \n",
      " extracting: val2017/000000008277.jpg  \n",
      " extracting: val2017/000000560371.jpg  \n",
      " extracting: val2017/000000406611.jpg  \n",
      " extracting: val2017/000000336053.jpg  \n",
      " extracting: val2017/000000320664.jpg  \n",
      " extracting: val2017/000000002587.jpg  \n",
      " extracting: val2017/000000176446.jpg  \n",
      " extracting: val2017/000000242678.jpg  \n",
      " extracting: val2017/000000433192.jpg  \n",
      " extracting: val2017/000000101780.jpg  \n",
      " extracting: val2017/000000506178.jpg  \n",
      " extracting: val2017/000000319607.jpg  \n",
      " extracting: val2017/000000430048.jpg  \n",
      " extracting: val2017/000000184978.jpg  \n",
      " extracting: val2017/000000280325.jpg  \n",
      " extracting: val2017/000000166768.jpg  \n",
      " extracting: val2017/000000411817.jpg  \n",
      " extracting: val2017/000000486046.jpg  \n",
      " extracting: val2017/000000287545.jpg  \n",
      " extracting: val2017/000000427338.jpg  \n",
      " extracting: val2017/000000274066.jpg  \n",
      " extracting: val2017/000000361147.jpg  \n",
      " extracting: val2017/000000557501.jpg  \n",
      " extracting: val2017/000000161642.jpg  \n",
      " extracting: val2017/000000451043.jpg  \n",
      " extracting: val2017/000000082085.jpg  \n",
      " extracting: val2017/000000129945.jpg  \n",
      " extracting: val2017/000000086956.jpg  \n",
      " extracting: val2017/000000058655.jpg  \n",
      " extracting: val2017/000000427500.jpg  \n",
      " extracting: val2017/000000339870.jpg  \n",
      " extracting: val2017/000000066706.jpg  \n",
      " extracting: val2017/000000311190.jpg  \n",
      " extracting: val2017/000000210855.jpg  \n",
      " extracting: val2017/000000190007.jpg  \n",
      " extracting: val2017/000000182021.jpg  \n",
      " extracting: val2017/000000384136.jpg  \n",
      " extracting: val2017/000000453634.jpg  \n",
      " extracting: val2017/000000160666.jpg  \n",
      " extracting: val2017/000000318080.jpg  \n",
      " extracting: val2017/000000097337.jpg  \n",
      " extracting: val2017/000000441586.jpg  \n",
      " extracting: val2017/000000079034.jpg  \n",
      " extracting: val2017/000000508730.jpg  \n",
      " extracting: val2017/000000270705.jpg  \n",
      " extracting: val2017/000000272049.jpg  \n",
      " extracting: val2017/000000131273.jpg  \n",
      " extracting: val2017/000000360661.jpg  \n",
      " extracting: val2017/000000187585.jpg  \n",
      " extracting: val2017/000000551660.jpg  \n",
      " extracting: val2017/000000462576.jpg  \n",
      " extracting: val2017/000000359937.jpg  \n",
      " extracting: val2017/000000245915.jpg  \n",
      " extracting: val2017/000000185890.jpg  \n",
      " extracting: val2017/000000226154.jpg  \n",
      " extracting: val2017/000000148508.jpg  \n",
      " extracting: val2017/000000293300.jpg  \n",
      " extracting: val2017/000000075393.jpg  \n",
      " extracting: val2017/000000089296.jpg  \n",
      " extracting: val2017/000000506707.jpg  \n",
      " extracting: val2017/000000344614.jpg  \n",
      " extracting: val2017/000000341973.jpg  \n",
      " extracting: val2017/000000012639.jpg  \n",
      " extracting: val2017/000000493442.jpg  \n",
      " extracting: val2017/000000471756.jpg  \n",
      " extracting: val2017/000000307172.jpg  \n",
      " extracting: val2017/000000551215.jpg  \n",
      " extracting: val2017/000000420230.jpg  \n",
      " extracting: val2017/000000357737.jpg  \n",
      " extracting: val2017/000000261732.jpg  \n",
      " extracting: val2017/000000214205.jpg  \n",
      " extracting: val2017/000000302107.jpg  \n",
      " extracting: val2017/000000128476.jpg  \n",
      " extracting: val2017/000000290293.jpg  \n",
      " extracting: val2017/000000420069.jpg  \n",
      " extracting: val2017/000000239274.jpg  \n",
      " extracting: val2017/000000317024.jpg  \n",
      " extracting: val2017/000000222235.jpg  \n",
      " extracting: val2017/000000236845.jpg  \n",
      " extracting: val2017/000000120420.jpg  \n",
      " extracting: val2017/000000312406.jpg  \n",
      " extracting: val2017/000000088345.jpg  \n",
      " extracting: val2017/000000088218.jpg  \n",
      " extracting: val2017/000000100489.jpg  \n",
      " extracting: val2017/000000562059.jpg  \n",
      " extracting: val2017/000000524456.jpg  \n",
      " extracting: val2017/000000265816.jpg  \n",
      " extracting: val2017/000000423944.jpg  \n",
      " extracting: val2017/000000454798.jpg  \n",
      " extracting: val2017/000000399560.jpg  \n",
      " extracting: val2017/000000401991.jpg  \n",
      " extracting: val2017/000000380913.jpg  \n",
      " extracting: val2017/000000312278.jpg  \n",
      " extracting: val2017/000000066561.jpg  \n",
      " extracting: val2017/000000519208.jpg  \n",
      " extracting: val2017/000000407646.jpg  \n",
      " extracting: val2017/000000141821.jpg  \n",
      " extracting: val2017/000000493905.jpg  \n",
      " extracting: val2017/000000481567.jpg  \n",
      " extracting: val2017/000000378673.jpg  \n",
      " extracting: val2017/000000060363.jpg  \n",
      " extracting: val2017/000000553664.jpg  \n",
      " extracting: val2017/000000240767.jpg  \n",
      " extracting: val2017/000000167159.jpg  \n",
      " extracting: val2017/000000150417.jpg  \n",
      " extracting: val2017/000000064462.jpg  \n",
      " extracting: val2017/000000091619.jpg  \n",
      " extracting: val2017/000000550471.jpg  \n",
      " extracting: val2017/000000147223.jpg  \n",
      " extracting: val2017/000000574823.jpg  \n",
      " extracting: val2017/000000433774.jpg  \n",
      " extracting: val2017/000000561465.jpg  \n",
      " extracting: val2017/000000296969.jpg  \n",
      " extracting: val2017/000000348045.jpg  \n",
      " extracting: val2017/000000455219.jpg  \n",
      " extracting: val2017/000000486438.jpg  \n",
      " extracting: val2017/000000414638.jpg  \n",
      " extracting: val2017/000000383339.jpg  \n",
      " extracting: val2017/000000222455.jpg  \n",
      " extracting: val2017/000000158744.jpg  \n",
      " extracting: val2017/000000003255.jpg  \n",
      " extracting: val2017/000000030504.jpg  \n",
      " extracting: val2017/000000209757.jpg  \n",
      " extracting: val2017/000000089271.jpg  \n",
      " extracting: val2017/000000466835.jpg  \n",
      " extracting: val2017/000000163117.jpg  \n",
      " extracting: val2017/000000469246.jpg  \n",
      " extracting: val2017/000000006763.jpg  \n",
      " extracting: val2017/000000035963.jpg  \n",
      " extracting: val2017/000000466085.jpg  \n",
      " extracting: val2017/000000051712.jpg  \n",
      " extracting: val2017/000000383384.jpg  \n",
      " extracting: val2017/000000561889.jpg  \n",
      " extracting: val2017/000000277005.jpg  \n",
      " extracting: val2017/000000060932.jpg  \n",
      " extracting: val2017/000000153011.jpg  \n",
      " extracting: val2017/000000266892.jpg  \n",
      " extracting: val2017/000000045070.jpg  \n",
      " extracting: val2017/000000519039.jpg  \n",
      " extracting: val2017/000000529966.jpg  \n",
      " extracting: val2017/000000548780.jpg  \n",
      " extracting: val2017/000000144784.jpg  \n",
      " extracting: val2017/000000258541.jpg  \n",
      " extracting: val2017/000000187271.jpg  \n",
      " extracting: val2017/000000044699.jpg  \n",
      " extracting: val2017/000000210099.jpg  \n",
      " extracting: val2017/000000575081.jpg  \n",
      " extracting: val2017/000000405279.jpg  \n",
      " extracting: val2017/000000368982.jpg  \n",
      " extracting: val2017/000000150224.jpg  \n",
      " extracting: val2017/000000434247.jpg  \n",
      " extracting: val2017/000000109916.jpg  \n",
      " extracting: val2017/000000319369.jpg  \n",
      " extracting: val2017/000000176701.jpg  \n",
      " extracting: val2017/000000336209.jpg  \n",
      " extracting: val2017/000000225946.jpg  \n",
      " extracting: val2017/000000138115.jpg  \n",
      " extracting: val2017/000000334977.jpg  \n",
      " extracting: val2017/000000403584.jpg  \n",
      " extracting: val2017/000000338905.jpg  \n",
      " extracting: val2017/000000389109.jpg  \n",
      " extracting: val2017/000000572388.jpg  \n",
      " extracting: val2017/000000544605.jpg  \n",
      " extracting: val2017/000000066135.jpg  \n",
      " extracting: val2017/000000535578.jpg  \n",
      " extracting: val2017/000000490515.jpg  \n",
      " extracting: val2017/000000010764.jpg  \n",
      " extracting: val2017/000000349594.jpg  \n",
      " extracting: val2017/000000356498.jpg  \n",
      " extracting: val2017/000000367680.jpg  \n",
      " extracting: val2017/000000046872.jpg  \n",
      " extracting: val2017/000000152465.jpg  \n",
      " extracting: val2017/000000079144.jpg  \n",
      " extracting: val2017/000000243204.jpg  \n",
      " extracting: val2017/000000351530.jpg  \n",
      " extracting: val2017/000000389451.jpg  \n",
      " extracting: val2017/000000179765.jpg  \n",
      " extracting: val2017/000000449312.jpg  \n",
      " extracting: val2017/000000458702.jpg  \n",
      " extracting: val2017/000000269632.jpg  \n",
      " extracting: val2017/000000425361.jpg  \n",
      " extracting: val2017/000000386457.jpg  \n",
      " extracting: val2017/000000347265.jpg  \n",
      " extracting: val2017/000000498463.jpg  \n",
      " extracting: val2017/000000022623.jpg  \n",
      " extracting: val2017/000000362434.jpg  \n",
      " extracting: val2017/000000009378.jpg  \n",
      " extracting: val2017/000000521509.jpg  \n",
      " extracting: val2017/000000423519.jpg  \n",
      " extracting: val2017/000000322610.jpg  \n",
      " extracting: val2017/000000438304.jpg  \n",
      " extracting: val2017/000000180383.jpg  \n",
      " extracting: val2017/000000511999.jpg  \n",
      " extracting: val2017/000000330396.jpg  \n",
      " extracting: val2017/000000157098.jpg  \n",
      " extracting: val2017/000000312237.jpg  \n",
      " extracting: val2017/000000232348.jpg  \n",
      " extracting: val2017/000000060899.jpg  \n",
      " extracting: val2017/000000127955.jpg  \n",
      " extracting: val2017/000000117425.jpg  \n",
      " extracting: val2017/000000218249.jpg  \n",
      " extracting: val2017/000000176037.jpg  \n",
      " extracting: val2017/000000467176.jpg  \n",
      " extracting: val2017/000000377239.jpg  \n",
      " extracting: val2017/000000566923.jpg  \n",
      " extracting: val2017/000000093261.jpg  \n",
      " extracting: val2017/000000322959.jpg  \n",
      " extracting: val2017/000000160728.jpg  \n",
      " extracting: val2017/000000346968.jpg  \n",
      " extracting: val2017/000000332570.jpg  \n",
      " extracting: val2017/000000212166.jpg  \n",
      " extracting: val2017/000000343315.jpg  \n",
      " extracting: val2017/000000019924.jpg  \n",
      " extracting: val2017/000000532901.jpg  \n",
      " extracting: val2017/000000074733.jpg  \n",
      " extracting: val2017/000000189698.jpg  \n",
      " extracting: val2017/000000520871.jpg  \n",
      " extracting: val2017/000000300842.jpg  \n",
      " extracting: val2017/000000453722.jpg  \n",
      " extracting: val2017/000000518326.jpg  \n",
      " extracting: val2017/000000450559.jpg  \n",
      " extracting: val2017/000000032038.jpg  \n",
      " extracting: val2017/000000376093.jpg  \n",
      " extracting: val2017/000000163640.jpg  \n",
      " extracting: val2017/000000449909.jpg  \n",
      " extracting: val2017/000000036844.jpg  \n",
      " extracting: val2017/000000195045.jpg  \n",
      " extracting: val2017/000000184400.jpg  \n",
      " extracting: val2017/000000369757.jpg  \n",
      " extracting: val2017/000000442822.jpg  \n",
      " extracting: val2017/000000112626.jpg  \n",
      " extracting: val2017/000000165336.jpg  \n",
      " extracting: val2017/000000320632.jpg  \n",
      " extracting: val2017/000000370818.jpg  \n",
      " extracting: val2017/000000009400.jpg  \n",
      " extracting: val2017/000000032285.jpg  \n",
      " extracting: val2017/000000544052.jpg  \n",
      " extracting: val2017/000000509131.jpg  \n",
      " extracting: val2017/000000402096.jpg  \n",
      " extracting: val2017/000000091406.jpg  \n",
      " extracting: val2017/000000283785.jpg  \n",
      " extracting: val2017/000000271471.jpg  \n",
      " extracting: val2017/000000192964.jpg  \n",
      " extracting: val2017/000000455085.jpg  \n",
      " extracting: val2017/000000522007.jpg  \n",
      " extracting: val2017/000000319100.jpg  \n",
      " extracting: val2017/000000340175.jpg  \n",
      " extracting: val2017/000000101884.jpg  \n",
      " extracting: val2017/000000177893.jpg  \n",
      " extracting: val2017/000000260925.jpg  \n",
      " extracting: val2017/000000015272.jpg  \n",
      " extracting: val2017/000000515350.jpg  \n",
      " extracting: val2017/000000470924.jpg  \n",
      " extracting: val2017/000000031118.jpg  \n",
      " extracting: val2017/000000544519.jpg  \n",
      " extracting: val2017/000000303908.jpg  \n",
      " extracting: val2017/000000513580.jpg  \n",
      " extracting: val2017/000000340697.jpg  \n",
      " extracting: val2017/000000213255.jpg  \n",
      " extracting: val2017/000000464786.jpg  \n",
      " extracting: val2017/000000021879.jpg  \n",
      " extracting: val2017/000000104119.jpg  \n",
      " extracting: val2017/000000542776.jpg  \n",
      " extracting: val2017/000000505565.jpg  \n",
      " extracting: val2017/000000372349.jpg  \n",
      " extracting: val2017/000000060835.jpg  \n",
      " extracting: val2017/000000474164.jpg  \n",
      " extracting: val2017/000000110784.jpg  \n",
      " extracting: val2017/000000438955.jpg  \n",
      " extracting: val2017/000000327769.jpg  \n",
      " extracting: val2017/000000119088.jpg  \n",
      " extracting: val2017/000000437110.jpg  \n",
      " extracting: val2017/000000256916.jpg  \n",
      " extracting: val2017/000000431848.jpg  \n",
      " extracting: val2017/000000061658.jpg  \n",
      " extracting: val2017/000000434459.jpg  \n",
      " extracting: val2017/000000379476.jpg  \n",
      " extracting: val2017/000000093437.jpg  \n",
      " extracting: val2017/000000576955.jpg  \n",
      " extracting: val2017/000000577735.jpg  \n",
      " extracting: val2017/000000544565.jpg  \n",
      " extracting: val2017/000000194471.jpg  \n",
      " extracting: val2017/000000286422.jpg  \n",
      " extracting: val2017/000000532530.jpg  \n",
      " extracting: val2017/000000205647.jpg  \n",
      " extracting: val2017/000000308587.jpg  \n",
      " extracting: val2017/000000026926.jpg  \n",
      " extracting: val2017/000000065455.jpg  \n",
      " extracting: val2017/000000140420.jpg  \n",
      " extracting: val2017/000000449579.jpg  \n",
      " extracting: val2017/000000308430.jpg  \n",
      " extracting: val2017/000000220310.jpg  \n",
      " extracting: val2017/000000206831.jpg  \n",
      " extracting: val2017/000000074646.jpg  \n",
      " extracting: val2017/000000440475.jpg  \n",
      " extracting: val2017/000000420472.jpg  \n",
      " extracting: val2017/000000553731.jpg  \n",
      " extracting: val2017/000000561958.jpg  \n",
      " extracting: val2017/000000290081.jpg  \n",
      " extracting: val2017/000000256192.jpg  \n",
      " extracting: val2017/000000261318.jpg  \n",
      " extracting: val2017/000000248980.jpg  \n",
      " extracting: val2017/000000058384.jpg  \n",
      " extracting: val2017/000000197022.jpg  \n",
      " extracting: val2017/000000233771.jpg  \n",
      " extracting: val2017/000000174004.jpg  \n",
      " extracting: val2017/000000500477.jpg  \n",
      " extracting: val2017/000000438862.jpg  \n",
      " extracting: val2017/000000243344.jpg  \n",
      " extracting: val2017/000000549220.jpg  \n",
      " extracting: val2017/000000071451.jpg  \n",
      " extracting: val2017/000000363666.jpg  \n",
      " extracting: val2017/000000201676.jpg  \n",
      " extracting: val2017/000000308531.jpg  \n",
      " extracting: val2017/000000493799.jpg  \n",
      " extracting: val2017/000000523807.jpg  \n",
      " extracting: val2017/000000219578.jpg  \n",
      " extracting: val2017/000000382088.jpg  \n",
      " extracting: val2017/000000294831.jpg  \n",
      " extracting: val2017/000000164602.jpg  \n",
      " extracting: val2017/000000148783.jpg  \n",
      " extracting: val2017/000000174482.jpg  \n",
      " extracting: val2017/000000359677.jpg  \n",
      " extracting: val2017/000000391648.jpg  \n",
      " extracting: val2017/000000312552.jpg  \n",
      " extracting: val2017/000000356248.jpg  \n",
      " extracting: val2017/000000427256.jpg  \n",
      " extracting: val2017/000000376112.jpg  \n",
      " extracting: val2017/000000484415.jpg  \n",
      " extracting: val2017/000000061584.jpg  \n",
      " extracting: val2017/000000505789.jpg  \n",
      " extracting: val2017/000000298396.jpg  \n",
      " extracting: val2017/000000395633.jpg  \n",
      " extracting: val2017/000000452122.jpg  \n",
      " extracting: val2017/000000521717.jpg  \n",
      " extracting: val2017/000000149568.jpg  \n",
      " extracting: val2017/000000486104.jpg  \n",
      " extracting: val2017/000000442661.jpg  \n",
      " extracting: val2017/000000245311.jpg  \n",
      " extracting: val2017/000000266409.jpg  \n",
      " extracting: val2017/000000571804.jpg  \n",
      " extracting: val2017/000000322844.jpg  \n",
      " extracting: val2017/000000429718.jpg  \n",
      " extracting: val2017/000000285047.jpg  \n",
      " extracting: val2017/000000229601.jpg  \n",
      " extracting: val2017/000000367569.jpg  \n",
      " extracting: val2017/000000460347.jpg  \n",
      " extracting: val2017/000000524742.jpg  \n",
      " extracting: val2017/000000269932.jpg  \n",
      " extracting: val2017/000000069106.jpg  \n",
      " extracting: val2017/000000411665.jpg  \n",
      " extracting: val2017/000000182155.jpg  \n",
      " extracting: val2017/000000314914.jpg  \n",
      " extracting: val2017/000000090284.jpg  \n",
      " extracting: val2017/000000319617.jpg  \n",
      " extracting: val2017/000000447313.jpg  \n",
      " extracting: val2017/000000449432.jpg  \n",
      " extracting: val2017/000000263068.jpg  \n",
      " extracting: val2017/000000131131.jpg  \n",
      " extracting: val2017/000000101762.jpg  \n",
      " extracting: val2017/000000377497.jpg  \n",
      " extracting: val2017/000000012748.jpg  \n",
      " extracting: val2017/000000213445.jpg  \n",
      " extracting: val2017/000000167128.jpg  \n",
      " extracting: val2017/000000198915.jpg  \n",
      " extracting: val2017/000000139872.jpg  \n",
      " extracting: val2017/000000382734.jpg  \n",
      " extracting: val2017/000000226408.jpg  \n",
      " extracting: val2017/000000172083.jpg  \n",
      " extracting: val2017/000000313588.jpg  \n",
      " extracting: val2017/000000480021.jpg  \n",
      " extracting: val2017/000000267946.jpg  \n",
      " extracting: val2017/000000305695.jpg  \n",
      " extracting: val2017/000000171740.jpg  \n",
      " extracting: val2017/000000520301.jpg  \n",
      " extracting: val2017/000000504711.jpg  \n",
      " extracting: val2017/000000251824.jpg  \n",
      " extracting: val2017/000000256407.jpg  \n",
      " extracting: val2017/000000455157.jpg  \n",
      " extracting: val2017/000000236308.jpg  \n",
      " extracting: val2017/000000064495.jpg  \n",
      " extracting: val2017/000000252701.jpg  \n",
      " extracting: val2017/000000173830.jpg  \n",
      " extracting: val2017/000000107339.jpg  \n",
      " extracting: val2017/000000066841.jpg  \n",
      " extracting: val2017/000000350148.jpg  \n",
      " extracting: val2017/000000558073.jpg  \n",
      " extracting: val2017/000000514586.jpg  \n",
      " extracting: val2017/000000143068.jpg  \n",
      " extracting: val2017/000000085376.jpg  \n",
      " extracting: val2017/000000240250.jpg  \n",
      " extracting: val2017/000000359781.jpg  \n",
      " extracting: val2017/000000246968.jpg  \n",
      " extracting: val2017/000000132587.jpg  \n",
      " extracting: val2017/000000134689.jpg  \n",
      " extracting: val2017/000000350833.jpg  \n",
      " extracting: val2017/000000579158.jpg  \n",
      " extracting: val2017/000000131386.jpg  \n",
      " extracting: val2017/000000191580.jpg  \n",
      " extracting: val2017/000000032861.jpg  \n",
      " extracting: val2017/000000433515.jpg  \n",
      " extracting: val2017/000000099053.jpg  \n",
      " extracting: val2017/000000490936.jpg  \n",
      " extracting: val2017/000000177065.jpg  \n",
      " extracting: val2017/000000391140.jpg  \n",
      " extracting: val2017/000000014888.jpg  \n",
      " extracting: val2017/000000166165.jpg  \n",
      " extracting: val2017/000000188296.jpg  \n",
      " extracting: val2017/000000546829.jpg  \n",
      " extracting: val2017/000000076211.jpg  \n",
      " extracting: val2017/000000284445.jpg  \n",
      " extracting: val2017/000000261888.jpg  \n",
      " extracting: val2017/000000271402.jpg  \n",
      " extracting: val2017/000000195918.jpg  \n",
      " extracting: val2017/000000476787.jpg  \n",
      " extracting: val2017/000000003934.jpg  \n",
      " extracting: val2017/000000052007.jpg  \n",
      " extracting: val2017/000000226903.jpg  \n",
      " extracting: val2017/000000080057.jpg  \n",
      " extracting: val2017/000000516173.jpg  \n",
      " extracting: val2017/000000314177.jpg  \n",
      " extracting: val2017/000000184791.jpg  \n",
      " extracting: val2017/000000579900.jpg  \n",
      " extracting: val2017/000000000285.jpg  \n",
      " extracting: val2017/000000489046.jpg  \n",
      " extracting: val2017/000000499768.jpg  \n",
      " extracting: val2017/000000446522.jpg  \n",
      " extracting: val2017/000000562818.jpg  \n",
      " extracting: val2017/000000414795.jpg  \n",
      " extracting: val2017/000000392933.jpg  \n",
      " extracting: val2017/000000334555.jpg  \n",
      " extracting: val2017/000000150649.jpg  \n",
      " extracting: val2017/000000345397.jpg  \n",
      " extracting: val2017/000000266768.jpg  \n",
      " extracting: val2017/000000230166.jpg  \n",
      " extracting: val2017/000000130613.jpg  \n",
      " extracting: val2017/000000309964.jpg  \n",
      " extracting: val2017/000000380203.jpg  \n",
      " extracting: val2017/000000171190.jpg  \n",
      " extracting: val2017/000000303653.jpg  \n",
      " extracting: val2017/000000147725.jpg  \n",
      " extracting: val2017/000000396903.jpg  \n",
      " extracting: val2017/000000300155.jpg  \n",
      " extracting: val2017/000000245576.jpg  \n",
      " extracting: val2017/000000121417.jpg  \n",
      " extracting: val2017/000000055150.jpg  \n",
      " extracting: val2017/000000571313.jpg  \n",
      " extracting: val2017/000000248810.jpg  \n",
      " extracting: val2017/000000484978.jpg  \n",
      " extracting: val2017/000000539883.jpg  \n",
      " extracting: val2017/000000215644.jpg  \n",
      " extracting: val2017/000000187990.jpg  \n",
      " extracting: val2017/000000527528.jpg  \n",
      " extracting: val2017/000000538364.jpg  \n",
      " extracting: val2017/000000330818.jpg  \n",
      " extracting: val2017/000000193926.jpg  \n",
      " extracting: val2017/000000030785.jpg  \n",
      " extracting: val2017/000000085089.jpg  \n",
      " extracting: val2017/000000268996.jpg  \n",
      " extracting: val2017/000000519688.jpg  \n",
      " extracting: val2017/000000006040.jpg  \n",
      " extracting: val2017/000000473219.jpg  \n",
      " extracting: val2017/000000555597.jpg  \n",
      " extracting: val2017/000000492362.jpg  \n",
      " extracting: val2017/000000189451.jpg  \n",
      " extracting: val2017/000000476215.jpg  \n",
      " extracting: val2017/000000191614.jpg  \n",
      " extracting: val2017/000000571893.jpg  \n",
      " extracting: val2017/000000209613.jpg  \n",
      " extracting: val2017/000000484893.jpg  \n",
      " extracting: val2017/000000516804.jpg  \n",
      " extracting: val2017/000000534673.jpg  \n",
      " extracting: val2017/000000022479.jpg  \n",
      " extracting: val2017/000000459153.jpg  \n",
      " extracting: val2017/000000272136.jpg  \n",
      " extracting: val2017/000000231508.jpg  \n",
      " extracting: val2017/000000000724.jpg  \n",
      " extracting: val2017/000000477955.jpg  \n",
      " extracting: val2017/000000418959.jpg  \n",
      " extracting: val2017/000000257478.jpg  \n",
      " extracting: val2017/000000173371.jpg  \n",
      " extracting: val2017/000000415716.jpg  \n",
      " extracting: val2017/000000571598.jpg  \n",
      " extracting: val2017/000000426268.jpg  \n",
      " extracting: val2017/000000164363.jpg  \n",
      " extracting: val2017/000000171757.jpg  \n",
      " extracting: val2017/000000260105.jpg  \n",
      " extracting: val2017/000000474021.jpg  \n",
      " extracting: val2017/000000034760.jpg  \n",
      " extracting: val2017/000000402615.jpg  \n",
      " extracting: val2017/000000507042.jpg  \n",
      " extracting: val2017/000000077396.jpg  \n",
      " extracting: val2017/000000282037.jpg  \n",
      " extracting: val2017/000000255912.jpg  \n",
      " extracting: val2017/000000452784.jpg  \n",
      " extracting: val2017/000000308476.jpg  \n",
      " extracting: val2017/000000288391.jpg  \n",
      " extracting: val2017/000000439525.jpg  \n",
      " extracting: val2017/000000034139.jpg  \n",
      " extracting: val2017/000000025057.jpg  \n",
      " extracting: val2017/000000272148.jpg  \n",
      " extracting: val2017/000000419882.jpg  \n",
      " extracting: val2017/000000183709.jpg  \n",
      " extracting: val2017/000000166521.jpg  \n",
      " extracting: val2017/000000550084.jpg  \n",
      " extracting: val2017/000000050149.jpg  \n",
      " extracting: val2017/000000078843.jpg  \n",
      " extracting: val2017/000000424776.jpg  \n",
      " extracting: val2017/000000441468.jpg  \n",
      " extracting: val2017/000000186938.jpg  \n",
      " extracting: val2017/000000046804.jpg  \n",
      " extracting: val2017/000000213605.jpg  \n",
      " extracting: val2017/000000556193.jpg  \n",
      " extracting: val2017/000000133087.jpg  \n",
      " extracting: val2017/000000280918.jpg  \n",
      " extracting: val2017/000000350019.jpg  \n",
      " extracting: val2017/000000504415.jpg  \n",
      " extracting: val2017/000000565962.jpg  \n",
      " extracting: val2017/000000413689.jpg  \n",
      " extracting: val2017/000000520832.jpg  \n",
      " extracting: val2017/000000338560.jpg  \n",
      " extracting: val2017/000000163682.jpg  \n",
      " extracting: val2017/000000232692.jpg  \n",
      " extracting: val2017/000000338428.jpg  \n",
      " extracting: val2017/000000100510.jpg  \n",
      " extracting: val2017/000000565469.jpg  \n",
      " extracting: val2017/000000485130.jpg  \n",
      " extracting: val2017/000000149770.jpg  \n",
      " extracting: val2017/000000080666.jpg  \n",
      " extracting: val2017/000000537827.jpg  \n",
      " extracting: val2017/000000198960.jpg  \n",
      " extracting: val2017/000000521540.jpg  \n",
      " extracting: val2017/000000543047.jpg  \n",
      " extracting: val2017/000000409358.jpg  \n",
      " extracting: val2017/000000208901.jpg  \n",
      " extracting: val2017/000000338625.jpg  \n",
      " extracting: val2017/000000278463.jpg  \n",
      " extracting: val2017/000000171050.jpg  \n",
      " extracting: val2017/000000311002.jpg  \n",
      " extracting: val2017/000000051598.jpg  \n",
      " extracting: val2017/000000534605.jpg  \n",
      " extracting: val2017/000000127092.jpg  \n",
      " extracting: val2017/000000479732.jpg  \n",
      " extracting: val2017/000000042102.jpg  \n",
      " extracting: val2017/000000478420.jpg  \n",
      " extracting: val2017/000000423617.jpg  \n",
      " extracting: val2017/000000236412.jpg  \n",
      " extracting: val2017/000000560266.jpg  \n",
      " extracting: val2017/000000541123.jpg  \n",
      " extracting: val2017/000000464872.jpg  \n",
      " extracting: val2017/000000231339.jpg  \n",
      " extracting: val2017/000000430056.jpg  \n",
      " extracting: val2017/000000005193.jpg  \n",
      " extracting: val2017/000000351823.jpg  \n",
      " extracting: val2017/000000081988.jpg  \n",
      " extracting: val2017/000000459954.jpg  \n",
      " extracting: val2017/000000255917.jpg  \n",
      " extracting: val2017/000000464689.jpg  \n",
      " extracting: val2017/000000151938.jpg  \n",
      " extracting: val2017/000000173057.jpg  \n",
      " extracting: val2017/000000181666.jpg  \n",
      " extracting: val2017/000000009891.jpg  \n",
      " extracting: val2017/000000015497.jpg  \n",
      " extracting: val2017/000000249025.jpg  \n",
      " extracting: val2017/000000443303.jpg  \n",
      " extracting: val2017/000000335658.jpg  \n",
      " extracting: val2017/000000243626.jpg  \n",
      " extracting: val2017/000000065074.jpg  \n",
      " extracting: val2017/000000504580.jpg  \n",
      " extracting: val2017/000000015751.jpg  \n",
      " extracting: val2017/000000164969.jpg  \n",
      " extracting: val2017/000000473121.jpg  \n",
      " extracting: val2017/000000246308.jpg  \n",
      " extracting: val2017/000000521719.jpg  \n",
      " extracting: val2017/000000001000.jpg  \n",
      " extracting: val2017/000000094157.jpg  \n",
      " extracting: val2017/000000401446.jpg  \n",
      " extracting: val2017/000000093154.jpg  \n",
      " extracting: val2017/000000139077.jpg  \n",
      " extracting: val2017/000000581357.jpg  \n",
      " extracting: val2017/000000137246.jpg  \n",
      " extracting: val2017/000000113403.jpg  \n",
      " extracting: val2017/000000447169.jpg  \n",
      " extracting: val2017/000000161978.jpg  \n",
      " extracting: val2017/000000521405.jpg  \n",
      " extracting: val2017/000000289222.jpg  \n",
      " extracting: val2017/000000516318.jpg  \n",
      " extracting: val2017/000000027768.jpg  \n",
      " extracting: val2017/000000237517.jpg  \n",
      " extracting: val2017/000000256941.jpg  \n",
      " extracting: val2017/000000200162.jpg  \n",
      " extracting: val2017/000000104603.jpg  \n",
      " extracting: val2017/000000431545.jpg  \n",
      " extracting: val2017/000000013597.jpg  \n",
      " extracting: val2017/000000562448.jpg  \n",
      " extracting: val2017/000000221754.jpg  \n",
      " extracting: val2017/000000577976.jpg  \n",
      " extracting: val2017/000000555009.jpg  \n",
      " extracting: val2017/000000357081.jpg  \n",
      " extracting: val2017/000000248631.jpg  \n",
      " extracting: val2017/000000491130.jpg  \n",
      " extracting: val2017/000000001584.jpg  \n",
      " extracting: val2017/000000309938.jpg  \n",
      " extracting: val2017/000000395180.jpg  \n",
      " extracting: val2017/000000482487.jpg  \n",
      " extracting: val2017/000000198510.jpg  \n",
      " extracting: val2017/000000080153.jpg  \n",
      " extracting: val2017/000000096427.jpg  \n",
      " extracting: val2017/000000348012.jpg  \n",
      " extracting: val2017/000000518213.jpg  \n",
      " extracting: val2017/000000376278.jpg  \n",
      " extracting: val2017/000000056350.jpg  \n",
      " extracting: val2017/000000168458.jpg  \n",
      " extracting: val2017/000000262587.jpg  \n",
      " extracting: val2017/000000151480.jpg  \n",
      " extracting: val2017/000000419312.jpg  \n",
      " extracting: val2017/000000029187.jpg  \n",
      " extracting: val2017/000000067406.jpg  \n",
      " extracting: val2017/000000371749.jpg  \n",
      " extracting: val2017/000000334767.jpg  \n",
      " extracting: val2017/000000190307.jpg  \n",
      " extracting: val2017/000000400794.jpg  \n",
      " extracting: val2017/000000218091.jpg  \n",
      " extracting: val2017/000000484029.jpg  \n",
      " extracting: val2017/000000461405.jpg  \n",
      " extracting: val2017/000000393056.jpg  \n",
      " extracting: val2017/000000552612.jpg  \n",
      " extracting: val2017/000000322574.jpg  \n",
      " extracting: val2017/000000140640.jpg  \n",
      " extracting: val2017/000000229753.jpg  \n",
      " extracting: val2017/000000013291.jpg  \n",
      " extracting: val2017/000000050896.jpg  \n",
      " extracting: val2017/000000104619.jpg  \n",
      " extracting: val2017/000000061108.jpg  \n",
      " extracting: val2017/000000081394.jpg  \n",
      " extracting: val2017/000000055950.jpg  \n",
      " extracting: val2017/000000256195.jpg  \n",
      " extracting: val2017/000000304404.jpg  \n",
      " extracting: val2017/000000133645.jpg  \n",
      " extracting: val2017/000000217872.jpg  \n",
      " extracting: val2017/000000308631.jpg  \n",
      " extracting: val2017/000000458410.jpg  \n",
      " extracting: val2017/000000523175.jpg  \n",
      " extracting: val2017/000000078823.jpg  \n",
      " extracting: val2017/000000392722.jpg  \n",
      " extracting: val2017/000000480122.jpg  \n",
      " extracting: val2017/000000142620.jpg  \n",
      " extracting: val2017/000000006471.jpg  \n",
      " extracting: val2017/000000195165.jpg  \n",
      " extracting: val2017/000000098520.jpg  \n",
      " extracting: val2017/000000473974.jpg  \n",
      " extracting: val2017/000000022371.jpg  \n",
      " extracting: val2017/000000136633.jpg  \n",
      " extracting: val2017/000000079408.jpg  \n",
      " extracting: val2017/000000307145.jpg  \n",
      " extracting: val2017/000000429623.jpg  \n",
      " extracting: val2017/000000466416.jpg  \n",
      " extracting: val2017/000000394677.jpg  \n",
      " extracting: val2017/000000324818.jpg  \n",
      " extracting: val2017/000000017115.jpg  \n",
      " extracting: val2017/000000389197.jpg  \n",
      " extracting: val2017/000000046378.jpg  \n",
      " extracting: val2017/000000474452.jpg  \n",
      " extracting: val2017/000000327605.jpg  \n",
      " extracting: val2017/000000508370.jpg  \n",
      " extracting: val2017/000000263425.jpg  \n",
      " extracting: val2017/000000463527.jpg  \n",
      " extracting: val2017/000000301981.jpg  \n",
      " extracting: val2017/000000186632.jpg  \n",
      " extracting: val2017/000000057244.jpg  \n",
      " extracting: val2017/000000007088.jpg  \n",
      " extracting: val2017/000000177489.jpg  \n",
      " extracting: val2017/000000177861.jpg  \n",
      " extracting: val2017/000000200152.jpg  \n",
      " extracting: val2017/000000096960.jpg  \n",
      " extracting: val2017/000000565391.jpg  \n",
      " extracting: val2017/000000132408.jpg  \n",
      " extracting: val2017/000000218997.jpg  \n",
      " extracting: val2017/000000194832.jpg  \n",
      " extracting: val2017/000000302882.jpg  \n",
      " extracting: val2017/000000292997.jpg  \n",
      " extracting: val2017/000000427077.jpg  \n",
      " extracting: val2017/000000560011.jpg  \n",
      " extracting: val2017/000000499031.jpg  \n",
      " extracting: val2017/000000411530.jpg  \n",
      " extracting: val2017/000000413395.jpg  \n",
      " extracting: val2017/000000346638.jpg  \n",
      " extracting: val2017/000000122217.jpg  \n",
      " extracting: val2017/000000199055.jpg  \n",
      " extracting: val2017/000000421923.jpg  \n",
      " extracting: val2017/000000261161.jpg  \n",
      " extracting: val2017/000000567825.jpg  \n",
      " extracting: val2017/000000456303.jpg  \n",
      " extracting: val2017/000000450488.jpg  \n",
      " extracting: val2017/000000527960.jpg  \n",
      " extracting: val2017/000000246454.jpg  \n",
      " extracting: val2017/000000328117.jpg  \n",
      " extracting: val2017/000000508602.jpg  \n",
      " extracting: val2017/000000017436.jpg  \n",
      " extracting: val2017/000000159311.jpg  \n",
      " extracting: val2017/000000293858.jpg  \n",
      " extracting: val2017/000000294163.jpg  \n",
      " extracting: val2017/000000157138.jpg  \n",
      " extracting: val2017/000000460229.jpg  \n",
      " extracting: val2017/000000473821.jpg  \n",
      " extracting: val2017/000000108244.jpg  \n",
      " extracting: val2017/000000546219.jpg  \n",
      " extracting: val2017/000000344888.jpg  \n",
      " extracting: val2017/000000439290.jpg  \n",
      " extracting: val2017/000000294855.jpg  \n",
      " extracting: val2017/000000417608.jpg  \n",
      " extracting: val2017/000000229997.jpg  \n",
      " extracting: val2017/000000092124.jpg  \n",
      " extracting: val2017/000000474078.jpg  \n",
      " extracting: val2017/000000103548.jpg  \n",
      " extracting: val2017/000000577959.jpg  \n",
      " extracting: val2017/000000227985.jpg  \n",
      " extracting: val2017/000000546976.jpg  \n",
      " extracting: val2017/000000577932.jpg  \n",
      " extracting: val2017/000000350003.jpg  \n",
      " extracting: val2017/000000235784.jpg  \n",
      " extracting: val2017/000000028285.jpg  \n",
      " extracting: val2017/000000075612.jpg  \n",
      " extracting: val2017/000000270677.jpg  \n",
      " extracting: val2017/000000018150.jpg  \n",
      " extracting: val2017/000000268000.jpg  \n",
      " extracting: val2017/000000558854.jpg  \n",
      " extracting: val2017/000000121586.jpg  \n",
      " extracting: val2017/000000566758.jpg  \n",
      " extracting: val2017/000000537153.jpg  \n",
      " extracting: val2017/000000554002.jpg  \n",
      " extracting: val2017/000000455937.jpg  \n",
      " extracting: val2017/000000157928.jpg  \n",
      " extracting: val2017/000000262048.jpg  \n",
      " extracting: val2017/000000320490.jpg  \n",
      " extracting: val2017/000000313130.jpg  \n",
      " extracting: val2017/000000054628.jpg  \n",
      " extracting: val2017/000000273493.jpg  \n",
      " extracting: val2017/000000517056.jpg  \n",
      " extracting: val2017/000000567432.jpg  \n",
      " extracting: val2017/000000180792.jpg  \n",
      " extracting: val2017/000000078959.jpg  \n",
      " extracting: val2017/000000118405.jpg  \n",
      " extracting: val2017/000000506279.jpg  \n",
      " extracting: val2017/000000180101.jpg  \n",
      " extracting: val2017/000000426795.jpg  \n",
      " extracting: val2017/000000311928.jpg  \n",
      " extracting: val2017/000000297085.jpg  \n",
      " extracting: val2017/000000186296.jpg  \n",
      " extracting: val2017/000000070254.jpg  \n",
      " extracting: val2017/000000569565.jpg  \n",
      " extracting: val2017/000000056288.jpg  \n",
      " extracting: val2017/000000244411.jpg  \n",
      " extracting: val2017/000000056127.jpg  \n",
      " extracting: val2017/000000147415.jpg  \n",
      " extracting: val2017/000000522638.jpg  \n",
      " extracting: val2017/000000405205.jpg  \n",
      " extracting: val2017/000000311394.jpg  \n",
      " extracting: val2017/000000475064.jpg  \n",
      " extracting: val2017/000000061418.jpg  \n",
      " extracting: val2017/000000134034.jpg  \n",
      " extracting: val2017/000000335177.jpg  \n",
      " extracting: val2017/000000571857.jpg  \n",
      " extracting: val2017/000000468233.jpg  \n",
      " extracting: val2017/000000192047.jpg  \n",
      " extracting: val2017/000000559513.jpg  \n",
      " extracting: val2017/000000534664.jpg  \n",
      " extracting: val2017/000000545129.jpg  \n",
      " extracting: val2017/000000434479.jpg  \n",
      " extracting: val2017/000000179141.jpg  \n",
      " extracting: val2017/000000316666.jpg  \n",
      " extracting: val2017/000000013546.jpg  \n",
      " extracting: val2017/000000156372.jpg  \n",
      " extracting: val2017/000000384808.jpg  \n",
      " extracting: val2017/000000243989.jpg  \n",
      " extracting: val2017/000000521052.jpg  \n",
      " extracting: val2017/000000290163.jpg  \n",
      " extracting: val2017/000000002299.jpg  \n",
      " extracting: val2017/000000223738.jpg  \n",
      " extracting: val2017/000000140439.jpg  \n",
      " extracting: val2017/000000364884.jpg  \n",
      " extracting: val2017/000000499266.jpg  \n",
      " extracting: val2017/000000113720.jpg  \n",
      " extracting: val2017/000000085478.jpg  \n",
      " extracting: val2017/000000510095.jpg  \n",
      " extracting: val2017/000000155571.jpg  \n",
      " extracting: val2017/000000512564.jpg  \n",
      " extracting: val2017/000000332351.jpg  \n",
      " extracting: val2017/000000511453.jpg  \n",
      " extracting: val2017/000000415882.jpg  \n",
      " extracting: val2017/000000088269.jpg  \n",
      " extracting: val2017/000000365521.jpg  \n",
      " extracting: val2017/000000071226.jpg  \n",
      " extracting: val2017/000000234526.jpg  \n",
      " extracting: val2017/000000413404.jpg  \n",
      " extracting: val2017/000000415990.jpg  \n",
      " extracting: val2017/000000107087.jpg  \n",
      " extracting: val2017/000000139099.jpg  \n",
      " extracting: val2017/000000540962.jpg  \n",
      " extracting: val2017/000000275791.jpg  \n",
      " extracting: val2017/000000257169.jpg  \n",
      " extracting: val2017/000000546826.jpg  \n",
      " extracting: val2017/000000147498.jpg  \n",
      " extracting: val2017/000000493286.jpg  \n",
      " extracting: val2017/000000085682.jpg  \n",
      " extracting: val2017/000000412286.jpg  \n",
      " extracting: val2017/000000463283.jpg  \n",
      " extracting: val2017/000000368335.jpg  \n",
      " extracting: val2017/000000337498.jpg  \n",
      " extracting: val2017/000000227044.jpg  \n",
      " extracting: val2017/000000051938.jpg  \n",
      " extracting: val2017/000000028809.jpg  \n",
      " extracting: val2017/000000170474.jpg  \n",
      " extracting: val2017/000000279774.jpg  \n",
      " extracting: val2017/000000383386.jpg  \n",
      " extracting: val2017/000000363461.jpg  \n",
      " extracting: val2017/000000432553.jpg  \n",
      " extracting: val2017/000000332455.jpg  \n",
      " extracting: val2017/000000281447.jpg  \n",
      " extracting: val2017/000000217425.jpg  \n",
      " extracting: val2017/000000291664.jpg  \n",
      " extracting: val2017/000000050679.jpg  \n",
      " extracting: val2017/000000137106.jpg  \n",
      " extracting: val2017/000000249643.jpg  \n",
      " extracting: val2017/000000322352.jpg  \n",
      " extracting: val2017/000000345356.jpg  \n",
      " extracting: val2017/000000480936.jpg  \n",
      " extracting: val2017/000000225532.jpg  \n",
      " extracting: val2017/000000226147.jpg  \n",
      " extracting: val2017/000000445365.jpg  \n",
      " extracting: val2017/000000125072.jpg  \n",
      " extracting: val2017/000000023034.jpg  \n",
      " extracting: val2017/000000558421.jpg  \n",
      " extracting: val2017/000000328430.jpg  \n",
      " extracting: val2017/000000524850.jpg  \n",
      " extracting: val2017/000000467511.jpg  \n",
      " extracting: val2017/000000088250.jpg  \n",
      " extracting: val2017/000000188906.jpg  \n",
      " extracting: val2017/000000259625.jpg  \n",
      " extracting: val2017/000000127182.jpg  \n",
      " extracting: val2017/000000422998.jpg  \n",
      " extracting: val2017/000000076261.jpg  \n",
      " extracting: val2017/000000448448.jpg  \n",
      " extracting: val2017/000000212895.jpg  \n",
      " extracting: val2017/000000534827.jpg  \n",
      " extracting: val2017/000000312421.jpg  \n",
      " extracting: val2017/000000371677.jpg  \n",
      " extracting: val2017/000000541664.jpg  \n",
      " extracting: val2017/000000416885.jpg  \n",
      " extracting: val2017/000000446703.jpg  \n",
      " extracting: val2017/000000103585.jpg  \n",
      " extracting: val2017/000000572555.jpg  \n",
      " extracting: val2017/000000177934.jpg  \n",
      " extracting: val2017/000000026465.jpg  \n",
      " extracting: val2017/000000563702.jpg  \n",
      " extracting: val2017/000000376442.jpg  \n",
      " extracting: val2017/000000163057.jpg  \n",
      " extracting: val2017/000000117374.jpg  \n",
      " extracting: val2017/000000477623.jpg  \n",
      " extracting: val2017/000000086220.jpg  \n",
      " extracting: val2017/000000006771.jpg  \n",
      " extracting: val2017/000000052891.jpg  \n",
      " extracting: val2017/000000453584.jpg  \n",
      " extracting: val2017/000000286849.jpg  \n",
      " extracting: val2017/000000165351.jpg  \n",
      " extracting: val2017/000000567011.jpg  \n",
      " extracting: val2017/000000203629.jpg  \n",
      " extracting: val2017/000000154000.jpg  \n",
      " extracting: val2017/000000121153.jpg  \n",
      " extracting: val2017/000000043737.jpg  \n",
      " extracting: val2017/000000202445.jpg  \n",
      " extracting: val2017/000000499313.jpg  \n",
      " extracting: val2017/000000084170.jpg  \n",
      " extracting: val2017/000000186345.jpg  \n",
      " extracting: val2017/000000272364.jpg  \n",
      " extracting: val2017/000000364557.jpg  \n",
      " extracting: val2017/000000010995.jpg  \n",
      " extracting: val2017/000000115885.jpg  \n",
      " extracting: val2017/000000011760.jpg  \n",
      " extracting: val2017/000000235064.jpg  \n",
      " extracting: val2017/000000391144.jpg  \n",
      " extracting: val2017/000000206579.jpg  \n",
      " extracting: val2017/000000098018.jpg  \n",
      " extracting: val2017/000000365207.jpg  \n",
      " extracting: val2017/000000140270.jpg  \n",
      " extracting: val2017/000000301563.jpg  \n",
      " extracting: val2017/000000439854.jpg  \n",
      " extracting: val2017/000000325114.jpg  \n",
      " extracting: val2017/000000016228.jpg  \n",
      " extracting: val2017/000000461751.jpg  \n",
      " extracting: val2017/000000192607.jpg  \n",
      " extracting: val2017/000000182923.jpg  \n",
      " extracting: val2017/000000111036.jpg  \n",
      " extracting: val2017/000000127517.jpg  \n",
      " extracting: val2017/000000076416.jpg  \n",
      " extracting: val2017/000000289516.jpg  \n",
      " extracting: val2017/000000179898.jpg  \n",
      " extracting: val2017/000000542127.jpg  \n",
      " extracting: val2017/000000495732.jpg  \n",
      " extracting: val2017/000000123480.jpg  \n",
      " extracting: val2017/000000092660.jpg  \n",
      " extracting: val2017/000000144706.jpg  \n",
      " extracting: val2017/000000333772.jpg  \n",
      " extracting: val2017/000000060823.jpg  \n",
      " extracting: val2017/000000161397.jpg  \n",
      " extracting: val2017/000000175438.jpg  \n",
      " extracting: val2017/000000241602.jpg  \n",
      " extracting: val2017/000000315257.jpg  \n",
      " extracting: val2017/000000235836.jpg  \n",
      " extracting: val2017/000000387098.jpg  \n",
      " extracting: val2017/000000398742.jpg  \n",
      " extracting: val2017/000000248616.jpg  \n",
      " extracting: val2017/000000456559.jpg  \n",
      " extracting: val2017/000000357888.jpg  \n",
      " extracting: val2017/000000392228.jpg  \n",
      " extracting: val2017/000000512330.jpg  \n",
      " extracting: val2017/000000548506.jpg  \n",
      " extracting: val2017/000000472298.jpg  \n",
      " extracting: val2017/000000087875.jpg  \n",
      " extracting: val2017/000000514508.jpg  \n",
      " extracting: val2017/000000051976.jpg  \n",
      " extracting: val2017/000000163118.jpg  \n",
      " extracting: val2017/000000037777.jpg  \n",
      " extracting: val2017/000000235057.jpg  \n",
      " extracting: val2017/000000492937.jpg  \n",
      " extracting: val2017/000000546556.jpg  \n",
      " extracting: val2017/000000383337.jpg  \n",
      " extracting: val2017/000000110638.jpg  \n",
      " extracting: val2017/000000180798.jpg  \n",
      " extracting: val2017/000000297022.jpg  \n",
      " extracting: val2017/000000250758.jpg  \n",
      " extracting: val2017/000000579970.jpg  \n",
      " extracting: val2017/000000523241.jpg  \n",
      " extracting: val2017/000000581062.jpg  \n",
      " extracting: val2017/000000157365.jpg  \n",
      " extracting: val2017/000000374052.jpg  \n",
      " extracting: val2017/000000390246.jpg  \n",
      " extracting: val2017/000000193743.jpg  \n",
      " extracting: val2017/000000203294.jpg  \n",
      " extracting: val2017/000000492077.jpg  \n",
      " extracting: val2017/000000199551.jpg  \n",
      " extracting: val2017/000000033368.jpg  \n",
      " extracting: val2017/000000164885.jpg  \n",
      " extracting: val2017/000000249219.jpg  \n",
      " extracting: val2017/000000092939.jpg  \n",
      " extracting: val2017/000000382125.jpg  \n",
      " extracting: val2017/000000088432.jpg  \n",
      " extracting: val2017/000000333956.jpg  \n",
      " extracting: val2017/000000567197.jpg  \n",
      " extracting: val2017/000000102356.jpg  \n",
      " extracting: val2017/000000274460.jpg  \n",
      " extracting: val2017/000000459662.jpg  \n",
      " extracting: val2017/000000447342.jpg  \n",
      " extracting: val2017/000000173004.jpg  \n",
      " extracting: val2017/000000505169.jpg  \n",
      " extracting: val2017/000000059635.jpg  \n",
      " extracting: val2017/000000050331.jpg  \n",
      " extracting: val2017/000000232684.jpg  \n",
      " extracting: val2017/000000454978.jpg  \n",
      " extracting: val2017/000000292005.jpg  \n",
      " extracting: val2017/000000165518.jpg  \n",
      " extracting: val2017/000000019042.jpg  \n",
      " extracting: val2017/000000174123.jpg  \n",
      " extracting: val2017/000000507893.jpg  \n",
      " extracting: val2017/000000025393.jpg  \n",
      " extracting: val2017/000000331352.jpg  \n",
      " extracting: val2017/000000109992.jpg  \n",
      " extracting: val2017/000000180751.jpg  \n",
      " extracting: val2017/000000097230.jpg  \n",
      " extracting: val2017/000000459887.jpg  \n",
      " extracting: val2017/000000404601.jpg  \n",
      " extracting: val2017/000000300233.jpg  \n",
      " extracting: val2017/000000359219.jpg  \n",
      " extracting: val2017/000000310622.jpg  \n",
      " extracting: val2017/000000557672.jpg  \n",
      " extracting: val2017/000000293794.jpg  \n",
      " extracting: val2017/000000153797.jpg  \n",
      " extracting: val2017/000000320232.jpg  \n",
      " extracting: val2017/000000237984.jpg  \n",
      " extracting: val2017/000000170955.jpg  \n",
      " extracting: val2017/000000348881.jpg  \n",
      " extracting: val2017/000000129062.jpg  \n",
      " extracting: val2017/000000547816.jpg  \n",
      " extracting: val2017/000000551822.jpg  \n",
      " extracting: val2017/000000251065.jpg  \n",
      " extracting: val2017/000000398237.jpg  \n",
      " extracting: val2017/000000181969.jpg  \n",
      " extracting: val2017/000000455301.jpg  \n",
      " extracting: val2017/000000051309.jpg  \n",
      " extracting: val2017/000000411938.jpg  \n",
      " extracting: val2017/000000050844.jpg  \n",
      " extracting: val2017/000000054967.jpg  \n",
      " extracting: val2017/000000112997.jpg  \n",
      " extracting: val2017/000000206994.jpg  \n",
      " extracting: val2017/000000259854.jpg  \n",
      " extracting: val2017/000000068093.jpg  \n",
      " extracting: val2017/000000465180.jpg  \n",
      " extracting: val2017/000000006213.jpg  \n",
      " extracting: val2017/000000292330.jpg  \n",
      " extracting: val2017/000000267434.jpg  \n",
      " extracting: val2017/000000428867.jpg  \n",
      " extracting: val2017/000000239347.jpg  \n",
      " extracting: val2017/000000365642.jpg  \n",
      " extracting: val2017/000000155451.jpg  \n",
      " extracting: val2017/000000568290.jpg  \n",
      " extracting: val2017/000000062554.jpg  \n",
      " extracting: val2017/000000057597.jpg  \n",
      " extracting: val2017/000000178469.jpg  \n",
      " extracting: val2017/000000357238.jpg  \n",
      " extracting: val2017/000000263966.jpg  \n",
      " extracting: val2017/000000044260.jpg  \n",
      " extracting: val2017/000000168974.jpg  \n",
      " extracting: val2017/000000281179.jpg  \n",
      " extracting: val2017/000000414673.jpg  \n",
      " extracting: val2017/000000124975.jpg  \n",
      " extracting: val2017/000000491470.jpg  \n",
      " extracting: val2017/000000450439.jpg  \n",
      " extracting: val2017/000000100723.jpg  \n",
      " extracting: val2017/000000034071.jpg  \n",
      " extracting: val2017/000000368684.jpg  \n",
      " extracting: val2017/000000329041.jpg  \n",
      " extracting: val2017/000000116068.jpg  \n",
      " extracting: val2017/000000031093.jpg  \n",
      " extracting: val2017/000000581317.jpg  \n",
      " extracting: val2017/000000360960.jpg  \n",
      " extracting: val2017/000000068286.jpg  \n",
      " extracting: val2017/000000179285.jpg  \n",
      " extracting: val2017/000000442480.jpg  \n",
      " extracting: val2017/000000130599.jpg  \n",
      " extracting: val2017/000000378244.jpg  \n",
      " extracting: val2017/000000262227.jpg  \n",
      " extracting: val2017/000000523229.jpg  \n",
      " extracting: val2017/000000042276.jpg  \n",
      " extracting: val2017/000000115118.jpg  \n",
      " extracting: val2017/000000490470.jpg  \n",
      " extracting: val2017/000000242287.jpg  \n",
      " extracting: val2017/000000136772.jpg  \n",
      " extracting: val2017/000000035682.jpg  \n",
      " extracting: val2017/000000464251.jpg  \n",
      " extracting: val2017/000000291791.jpg  \n",
      " extracting: val2017/000000481159.jpg  \n",
      " extracting: val2017/000000178028.jpg  \n",
      " extracting: val2017/000000215245.jpg  \n",
      " extracting: val2017/000000297578.jpg  \n",
      " extracting: val2017/000000198928.jpg  \n",
      " extracting: val2017/000000209972.jpg  \n",
      " extracting: val2017/000000090956.jpg  \n",
      " extracting: val2017/000000171788.jpg  \n",
      " extracting: val2017/000000035770.jpg  \n",
      " extracting: val2017/000000336658.jpg  \n",
      " extracting: val2017/000000010092.jpg  \n",
      " extracting: val2017/000000008899.jpg  \n",
      " extracting: val2017/000000237316.jpg  \n",
      " extracting: val2017/000000114770.jpg  \n",
      " extracting: val2017/000000331799.jpg  \n",
      " extracting: val2017/000000366141.jpg  \n",
      " extracting: val2017/000000560178.jpg  \n",
      " extracting: val2017/000000244099.jpg  \n",
      " extracting: val2017/000000194940.jpg  \n",
      " extracting: val2017/000000249180.jpg  \n",
      " extracting: val2017/000000274272.jpg  \n",
      " extracting: val2017/000000085823.jpg  \n",
      " extracting: val2017/000000473406.jpg  \n",
      " extracting: val2017/000000101787.jpg  \n",
      " extracting: val2017/000000106389.jpg  \n",
      " extracting: val2017/000000447314.jpg  \n",
      " extracting: val2017/000000303713.jpg  \n",
      " extracting: val2017/000000117525.jpg  \n",
      " extracting: val2017/000000492905.jpg  \n",
      " extracting: val2017/000000311950.jpg  \n",
      " extracting: val2017/000000227511.jpg  \n",
      " extracting: val2017/000000032811.jpg  \n",
      " extracting: val2017/000000209530.jpg  \n",
      " extracting: val2017/000000170670.jpg  \n",
      " extracting: val2017/000000022892.jpg  \n",
      " extracting: val2017/000000398905.jpg  \n",
      " extracting: val2017/000000074457.jpg  \n",
      " extracting: val2017/000000050828.jpg  \n",
      " extracting: val2017/000000224664.jpg  \n",
      " extracting: val2017/000000530624.jpg  \n",
      " extracting: val2017/000000006460.jpg  \n",
      " extracting: val2017/000000189078.jpg  \n",
      " extracting: val2017/000000408112.jpg  \n",
      " extracting: val2017/000000258911.jpg  \n",
      " extracting: val2017/000000572303.jpg  \n",
      " extracting: val2017/000000389684.jpg  \n",
      " extracting: val2017/000000161861.jpg  \n",
      " extracting: val2017/000000024243.jpg  \n",
      " extracting: val2017/000000125572.jpg  \n",
      " extracting: val2017/000000213033.jpg  \n",
      " extracting: val2017/000000130826.jpg  \n",
      " extracting: val2017/000000457262.jpg  \n",
      " extracting: val2017/000000372317.jpg  \n",
      " extracting: val2017/000000252294.jpg  \n",
      " extracting: val2017/000000031322.jpg  \n",
      " extracting: val2017/000000506933.jpg  \n",
      " extracting: val2017/000000276018.jpg  \n",
      " extracting: val2017/000000563603.jpg  \n",
      " extracting: val2017/000000108864.jpg  \n",
      " extracting: val2017/000000273232.jpg  \n",
      " extracting: val2017/000000253452.jpg  \n",
      " extracting: val2017/000000201775.jpg  \n",
      " extracting: val2017/000000351589.jpg  \n",
      " extracting: val2017/000000018519.jpg  \n",
      " extracting: val2017/000000399296.jpg  \n",
      " extracting: val2017/000000002473.jpg  \n",
      " extracting: val2017/000000160772.jpg  \n",
      " extracting: val2017/000000054593.jpg  \n",
      " extracting: val2017/000000127270.jpg  \n",
      " extracting: val2017/000000303566.jpg  \n",
      " extracting: val2017/000000354547.jpg  \n",
      " extracting: val2017/000000405432.jpg  \n",
      " extracting: val2017/000000548267.jpg  \n",
      " extracting: val2017/000000091654.jpg  \n",
      " extracting: val2017/000000138639.jpg  \n",
      " extracting: val2017/000000501368.jpg  \n",
      " extracting: val2017/000000458255.jpg  \n",
      " extracting: val2017/000000050006.jpg  \n",
      " extracting: val2017/000000564127.jpg  \n",
      " extracting: val2017/000000109976.jpg  \n",
      " extracting: val2017/000000246963.jpg  \n",
      " extracting: val2017/000000098839.jpg  \n",
      " extracting: val2017/000000475779.jpg  \n",
      " extracting: val2017/000000287959.jpg  \n",
      " extracting: val2017/000000429761.jpg  \n",
      " extracting: val2017/000000130699.jpg  \n",
      " extracting: val2017/000000188439.jpg  \n",
      " extracting: val2017/000000507235.jpg  \n",
      " extracting: val2017/000000561256.jpg  \n",
      " extracting: val2017/000000216296.jpg  \n",
      " extracting: val2017/000000445439.jpg  \n",
      " extracting: val2017/000000344621.jpg  \n",
      " extracting: val2017/000000504439.jpg  \n",
      " extracting: val2017/000000143961.jpg  \n",
      " extracting: val2017/000000032570.jpg  \n",
      " extracting: val2017/000000462756.jpg  \n",
      " extracting: val2017/000000575372.jpg  \n",
      " extracting: val2017/000000154947.jpg  \n",
      " extracting: val2017/000000462629.jpg  \n",
      " extracting: val2017/000000157807.jpg  \n",
      " extracting: val2017/000000417632.jpg  \n",
      " extracting: val2017/000000374083.jpg  \n",
      " extracting: val2017/000000209753.jpg  \n",
      " extracting: val2017/000000133000.jpg  \n",
      " extracting: val2017/000000144932.jpg  \n",
      " extracting: val2017/000000145597.jpg  \n",
      " extracting: val2017/000000528314.jpg  \n",
      " extracting: val2017/000000481480.jpg  \n",
      " extracting: val2017/000000525286.jpg  \n",
      " extracting: val2017/000000038210.jpg  \n",
      " extracting: val2017/000000306893.jpg  \n",
      " extracting: val2017/000000046497.jpg  \n",
      " extracting: val2017/000000488075.jpg  \n",
      " extracting: val2017/000000438907.jpg  \n",
      " extracting: val2017/000000312586.jpg  \n",
      " extracting: val2017/000000471087.jpg  \n",
      " extracting: val2017/000000364322.jpg  \n",
      " extracting: val2017/000000252559.jpg  \n",
      " extracting: val2017/000000475732.jpg  \n",
      " extracting: val2017/000000350405.jpg  \n",
      " extracting: val2017/000000200421.jpg  \n",
      " extracting: val2017/000000304180.jpg  \n",
      " extracting: val2017/000000200961.jpg  \n",
      " extracting: val2017/000000177015.jpg  \n",
      " extracting: val2017/000000412887.jpg  \n",
      " extracting: val2017/000000265108.jpg  \n",
      " extracting: val2017/000000533145.jpg  \n",
      " extracting: val2017/000000356432.jpg  \n",
      " extracting: val2017/000000491464.jpg  \n",
      " extracting: val2017/000000521956.jpg  \n",
      " extracting: val2017/000000219440.jpg  \n",
      " extracting: val2017/000000357816.jpg  \n",
      " extracting: val2017/000000066635.jpg  \n",
      " extracting: val2017/000000181499.jpg  \n",
      " extracting: val2017/000000275058.jpg  \n",
      " extracting: val2017/000000020553.jpg  \n",
      " extracting: val2017/000000440617.jpg  \n",
      " extracting: val2017/000000085195.jpg  \n",
      " extracting: val2017/000000104455.jpg  \n",
      " extracting: val2017/000000257566.jpg  \n",
      " extracting: val2017/000000547886.jpg  \n",
      " extracting: val2017/000000512836.jpg  \n",
      " extracting: val2017/000000074092.jpg  \n",
      " extracting: val2017/000000233370.jpg  \n",
      " extracting: val2017/000000370711.jpg  \n",
      " extracting: val2017/000000003156.jpg  \n",
      " extracting: val2017/000000243867.jpg  \n",
      " extracting: val2017/000000231747.jpg  \n",
      " extracting: val2017/000000020992.jpg  \n",
      " extracting: val2017/000000159458.jpg  \n",
      " extracting: val2017/000000025593.jpg  \n",
      " extracting: val2017/000000231097.jpg  \n",
      " extracting: val2017/000000106881.jpg  \n",
      " extracting: val2017/000000326248.jpg  \n",
      " extracting: val2017/000000354072.jpg  \n",
      " extracting: val2017/000000474028.jpg  \n",
      " extracting: val2017/000000122969.jpg  \n",
      " extracting: val2017/000000167353.jpg  \n",
      " extracting: val2017/000000122962.jpg  \n",
      " extracting: val2017/000000086483.jpg  \n",
      " extracting: val2017/000000541291.jpg  \n",
      " extracting: val2017/000000155341.jpg  \n",
      " extracting: val2017/000000360325.jpg  \n",
      " extracting: val2017/000000172396.jpg  \n",
      " extracting: val2017/000000192716.jpg  \n",
      " extracting: val2017/000000291551.jpg  \n",
      " extracting: val2017/000000189475.jpg  \n",
      " extracting: val2017/000000254016.jpg  \n",
      " extracting: val2017/000000335427.jpg  \n",
      " extracting: val2017/000000120777.jpg  \n",
      " extracting: val2017/000000375430.jpg  \n",
      " extracting: val2017/000000502599.jpg  \n",
      " extracting: val2017/000000394559.jpg  \n",
      " extracting: val2017/000000500423.jpg  \n",
      " extracting: val2017/000000059386.jpg  \n",
      " extracting: val2017/000000269316.jpg  \n",
      " extracting: val2017/000000273198.jpg  \n",
      " extracting: val2017/000000104782.jpg  \n",
      " extracting: val2017/000000052591.jpg  \n",
      " extracting: val2017/000000444879.jpg  \n",
      " extracting: val2017/000000482477.jpg  \n",
      " extracting: val2017/000000254814.jpg  \n",
      " extracting: val2017/000000185473.jpg  \n",
      " extracting: val2017/000000132544.jpg  \n",
      " extracting: val2017/000000540502.jpg  \n",
      " extracting: val2017/000000370677.jpg  \n",
      " extracting: val2017/000000229948.jpg  \n",
      " extracting: val2017/000000293625.jpg  \n",
      " extracting: val2017/000000320642.jpg  \n",
      " extracting: val2017/000000007977.jpg  \n",
      " extracting: val2017/000000570782.jpg  \n",
      " extracting: val2017/000000577862.jpg  \n",
      " extracting: val2017/000000052462.jpg  \n",
      " extracting: val2017/000000203580.jpg  \n",
      " extracting: val2017/000000180487.jpg  \n",
      " extracting: val2017/000000394510.jpg  \n",
      " extracting: val2017/000000285894.jpg  \n",
      " extracting: val2017/000000504589.jpg  \n",
      " extracting: val2017/000000384468.jpg  \n",
      " extracting: val2017/000000472046.jpg  \n",
      " extracting: val2017/000000491683.jpg  \n",
      " extracting: val2017/000000550322.jpg  \n",
      " extracting: val2017/000000430961.jpg  \n",
      " extracting: val2017/000000527750.jpg  \n",
      " extracting: val2017/000000387387.jpg  \n",
      " extracting: val2017/000000424521.jpg  \n",
      " extracting: val2017/000000288862.jpg  \n",
      " extracting: val2017/000000074256.jpg  \n",
      " extracting: val2017/000000181816.jpg  \n",
      " extracting: val2017/000000158945.jpg  \n",
      " extracting: val2017/000000284698.jpg  \n",
      " extracting: val2017/000000396205.jpg  \n",
      " extracting: val2017/000000341921.jpg  \n",
      " extracting: val2017/000000426166.jpg  \n",
      " extracting: val2017/000000057672.jpg  \n",
      " extracting: val2017/000000140203.jpg  \n",
      " extracting: val2017/000000185292.jpg  \n",
      " extracting: val2017/000000322968.jpg  \n",
      " extracting: val2017/000000381587.jpg  \n",
      " extracting: val2017/000000034205.jpg  \n",
      " extracting: val2017/000000279278.jpg  \n",
      " extracting: val2017/000000572900.jpg  \n",
      " extracting: val2017/000000396863.jpg  \n",
      " extracting: val2017/000000458223.jpg  \n",
      " extracting: val2017/000000127624.jpg  \n",
      " extracting: val2017/000000573626.jpg  \n",
      " extracting: val2017/000000500663.jpg  \n",
      " extracting: val2017/000000121591.jpg  \n",
      " extracting: val2017/000000068933.jpg  \n",
      " extracting: val2017/000000386352.jpg  \n",
      " extracting: val2017/000000181796.jpg  \n",
      " extracting: val2017/000000329542.jpg  \n",
      " extracting: val2017/000000145020.jpg  \n",
      " extracting: val2017/000000069224.jpg  \n",
      " extracting: val2017/000000354307.jpg  \n",
      " extracting: val2017/000000178982.jpg  \n",
      " extracting: val2017/000000517523.jpg  \n",
      " extracting: val2017/000000255165.jpg  \n",
      " extracting: val2017/000000281687.jpg  \n",
      " extracting: val2017/000000349184.jpg  \n",
      " extracting: val2017/000000012576.jpg  \n",
      " extracting: val2017/000000242411.jpg  \n",
      " extracting: val2017/000000566042.jpg  \n",
      " extracting: val2017/000000398810.jpg  \n",
      " extracting: val2017/000000432898.jpg  \n",
      " extracting: val2017/000000295797.jpg  \n",
      " extracting: val2017/000000180011.jpg  \n",
      " extracting: val2017/000000175443.jpg  \n",
      " extracting: val2017/000000311303.jpg  \n",
      " extracting: val2017/000000179653.jpg  \n",
      " extracting: val2017/000000079588.jpg  \n",
      " extracting: val2017/000000267351.jpg  \n",
      " extracting: val2017/000000042889.jpg  \n",
      " extracting: val2017/000000479912.jpg  \n",
      " extracting: val2017/000000563882.jpg  \n",
      " extracting: val2017/000000023899.jpg  \n",
      " extracting: val2017/000000064718.jpg  \n",
      " extracting: val2017/000000509014.jpg  \n",
      " extracting: val2017/000000156076.jpg  \n",
      " extracting: val2017/000000579321.jpg  \n",
      " extracting: val2017/000000471450.jpg  \n",
      " extracting: val2017/000000169169.jpg  \n",
      " extracting: val2017/000000422706.jpg  \n",
      " extracting: val2017/000000183391.jpg  \n",
      " extracting: val2017/000000008690.jpg  \n",
      " extracting: val2017/000000361919.jpg  \n",
      " extracting: val2017/000000421757.jpg  \n",
      " extracting: val2017/000000369503.jpg  \n",
      " extracting: val2017/000000201148.jpg  \n",
      " extracting: val2017/000000250205.jpg  \n",
      " extracting: val2017/000000327592.jpg  \n",
      " extracting: val2017/000000464476.jpg  \n",
      " extracting: val2017/000000238866.jpg  \n",
      " extracting: val2017/000000048153.jpg  \n",
      " extracting: val2017/000000151662.jpg  \n",
      " extracting: val2017/000000060770.jpg  \n",
      " extracting: val2017/000000383921.jpg  \n",
      " extracting: val2017/000000046252.jpg  \n",
      " extracting: val2017/000000439522.jpg  \n",
      " extracting: val2017/000000152120.jpg  \n",
      " extracting: val2017/000000179265.jpg  \n",
      " extracting: val2017/000000058393.jpg  \n",
      " extracting: val2017/000000559348.jpg  \n",
      " extracting: val2017/000000029397.jpg  \n",
      " extracting: val2017/000000205542.jpg  \n",
      " extracting: val2017/000000540280.jpg  \n",
      " extracting: val2017/000000368752.jpg  \n",
      " extracting: val2017/000000368940.jpg  \n",
      " extracting: val2017/000000423506.jpg  \n",
      " extracting: val2017/000000312263.jpg  \n",
      " extracting: val2017/000000397279.jpg  \n",
      " extracting: val2017/000000015956.jpg  \n",
      " extracting: val2017/000000333402.jpg  \n",
      " extracting: val2017/000000308391.jpg  \n",
      " extracting: val2017/000000311295.jpg  \n",
      " extracting: val2017/000000340272.jpg  \n",
      " extracting: val2017/000000344268.jpg  \n",
      " extracting: val2017/000000258388.jpg  \n",
      " extracting: val2017/000000418281.jpg  \n",
      " extracting: val2017/000000248314.jpg  \n",
      " extracting: val2017/000000280710.jpg  \n",
      " extracting: val2017/000000001761.jpg  \n",
      " extracting: val2017/000000064084.jpg  \n",
      " extracting: val2017/000000474167.jpg  \n",
      " extracting: val2017/000000319184.jpg  \n",
      " extracting: val2017/000000482719.jpg  \n",
      " extracting: val2017/000000498032.jpg  \n",
      " extracting: val2017/000000210520.jpg  \n",
      " extracting: val2017/000000343937.jpg  \n",
      " extracting: val2017/000000230819.jpg  \n",
      " extracting: val2017/000000484760.jpg  \n",
      " extracting: val2017/000000488385.jpg  \n",
      " extracting: val2017/000000292415.jpg  \n",
      " extracting: val2017/000000124659.jpg  \n",
      " extracting: val2017/000000259597.jpg  \n",
      " extracting: val2017/000000270883.jpg  \n",
      " extracting: val2017/000000297698.jpg  \n",
      " extracting: val2017/000000494869.jpg  \n",
      " extracting: val2017/000000336628.jpg  \n",
      " extracting: val2017/000000417911.jpg  \n",
      " extracting: val2017/000000536343.jpg  \n",
      " extracting: val2017/000000443844.jpg  \n",
      " extracting: val2017/000000460841.jpg  \n",
      " extracting: val2017/000000528977.jpg  \n",
      " extracting: val2017/000000558114.jpg  \n",
      " extracting: val2017/000000199310.jpg  \n",
      " extracting: val2017/000000050811.jpg  \n",
      " extracting: val2017/000000507797.jpg  \n",
      " extracting: val2017/000000282298.jpg  \n",
      " extracting: val2017/000000430973.jpg  \n",
      " extracting: val2017/000000070229.jpg  \n",
      " extracting: val2017/000000119677.jpg  \n",
      " extracting: val2017/000000498919.jpg  \n",
      " extracting: val2017/000000142324.jpg  \n",
      " extracting: val2017/000000447611.jpg  \n",
      " extracting: val2017/000000189775.jpg  \n",
      " extracting: val2017/000000454661.jpg  \n",
      " extracting: val2017/000000197870.jpg  \n",
      " extracting: val2017/000000551820.jpg  \n",
      " extracting: val2017/000000255664.jpg  \n",
      " extracting: val2017/000000248112.jpg  \n",
      " extracting: val2017/000000308193.jpg  \n",
      " extracting: val2017/000000281032.jpg  \n",
      " extracting: val2017/000000365208.jpg  \n",
      " extracting: val2017/000000021839.jpg  \n",
      " extracting: val2017/000000372466.jpg  \n",
      " extracting: val2017/000000458790.jpg  \n",
      " extracting: val2017/000000108440.jpg  \n",
      " extracting: val2017/000000055167.jpg  \n",
      " extracting: val2017/000000575187.jpg  \n",
      " extracting: val2017/000000334417.jpg  \n",
      " extracting: val2017/000000172648.jpg  \n",
      " extracting: val2017/000000513524.jpg  \n",
      " extracting: val2017/000000051738.jpg  \n",
      " extracting: val2017/000000024567.jpg  \n",
      " extracting: val2017/000000054592.jpg  \n",
      " extracting: val2017/000000343149.jpg  \n",
      " extracting: val2017/000000415748.jpg  \n",
      " extracting: val2017/000000308394.jpg  \n",
      " extracting: val2017/000000519522.jpg  \n",
      " extracting: val2017/000000211674.jpg  \n",
      " extracting: val2017/000000253835.jpg  \n",
      " extracting: val2017/000000079031.jpg  \n",
      " extracting: val2017/000000084664.jpg  \n",
      " extracting: val2017/000000323496.jpg  \n",
      " extracting: val2017/000000331604.jpg  \n",
      " extracting: val2017/000000098261.jpg  \n",
      " extracting: val2017/000000451879.jpg  \n",
      " extracting: val2017/000000057027.jpg  \n",
      " extracting: val2017/000000067310.jpg  \n",
      " extracting: val2017/000000078748.jpg  \n",
      " extracting: val2017/000000407574.jpg  \n",
      " extracting: val2017/000000078266.jpg  \n",
      " extracting: val2017/000000483531.jpg  \n",
      " extracting: val2017/000000134856.jpg  \n",
      " extracting: val2017/000000133567.jpg  \n",
      " extracting: val2017/000000278848.jpg  \n",
      " extracting: val2017/000000236914.jpg  \n",
      " extracting: val2017/000000376365.jpg  \n",
      " extracting: val2017/000000341719.jpg  \n",
      " extracting: val2017/000000532481.jpg  \n",
      " extracting: val2017/000000407518.jpg  \n",
      " extracting: val2017/000000446651.jpg  \n",
      " extracting: val2017/000000475387.jpg  \n",
      " extracting: val2017/000000243199.jpg  \n",
      " extracting: val2017/000000255824.jpg  \n",
      " extracting: val2017/000000383621.jpg  \n",
      " extracting: val2017/000000017959.jpg  \n",
      " extracting: val2017/000000221281.jpg  \n",
      " extracting: val2017/000000076625.jpg  \n",
      " extracting: val2017/000000156278.jpg  \n",
      " extracting: val2017/000000439994.jpg  \n",
      " extracting: val2017/000000336232.jpg  \n",
      " extracting: val2017/000000342367.jpg  \n",
      " extracting: val2017/000000362520.jpg  \n",
      " extracting: val2017/000000213086.jpg  \n",
      " extracting: val2017/000000193348.jpg  \n",
      " extracting: val2017/000000222094.jpg  \n",
      " extracting: val2017/000000197528.jpg  \n",
      " extracting: val2017/000000282296.jpg  \n",
      " extracting: val2017/000000488710.jpg  \n",
      " extracting: val2017/000000565989.jpg  \n",
      " extracting: val2017/000000025181.jpg  \n",
      " extracting: val2017/000000135410.jpg  \n",
      " extracting: val2017/000000393226.jpg  \n",
      " extracting: val2017/000000450202.jpg  \n",
      " extracting: val2017/000000450075.jpg  \n",
      " extracting: val2017/000000025394.jpg  \n",
      " extracting: val2017/000000257370.jpg  \n",
      " extracting: val2017/000000191672.jpg  \n",
      " extracting: val2017/000000049810.jpg  \n",
      " extracting: val2017/000000031749.jpg  \n",
      " extracting: val2017/000000406417.jpg  \n",
      " extracting: val2017/000000573258.jpg  \n",
      " extracting: val2017/000000352900.jpg  \n",
      " extracting: val2017/000000343803.jpg  \n",
      " extracting: val2017/000000002923.jpg  \n",
      " extracting: val2017/000000373315.jpg  \n",
      " extracting: val2017/000000496854.jpg  \n",
      " extracting: val2017/000000474170.jpg  \n",
      " extracting: val2017/000000327780.jpg  \n",
      " extracting: val2017/000000414510.jpg  \n",
      " extracting: val2017/000000172649.jpg  \n",
      " extracting: val2017/000000445999.jpg  \n",
      " extracting: val2017/000000351609.jpg  \n",
      " extracting: val2017/000000512776.jpg  \n",
      " extracting: val2017/000000494188.jpg  \n",
      " extracting: val2017/000000057760.jpg  \n",
      " extracting: val2017/000000414170.jpg  \n",
      " extracting: val2017/000000478721.jpg  \n",
      " extracting: val2017/000000475150.jpg  \n",
      " extracting: val2017/000000541055.jpg  \n",
      " extracting: val2017/000000175251.jpg  \n",
      " extracting: val2017/000000049759.jpg  \n",
      " extracting: val2017/000000448810.jpg  \n",
      " extracting: val2017/000000491213.jpg  \n",
      " extracting: val2017/000000069356.jpg  \n",
      " extracting: val2017/000000242934.jpg  \n",
      " extracting: val2017/000000550939.jpg  \n",
      " extracting: val2017/000000326970.jpg  \n",
      " extracting: val2017/000000127263.jpg  \n",
      " extracting: val2017/000000100274.jpg  \n",
      " extracting: val2017/000000323571.jpg  \n",
      " extracting: val2017/000000152870.jpg  \n",
      " extracting: val2017/000000085911.jpg  \n",
      " extracting: val2017/000000134882.jpg  \n",
      " extracting: val2017/000000236426.jpg  \n",
      " extracting: val2017/000000527695.jpg  \n",
      " extracting: val2017/000000407002.jpg  \n",
      " extracting: val2017/000000426836.jpg  \n",
      " extracting: val2017/000000578967.jpg  \n",
      " extracting: val2017/000000552883.jpg  \n",
      " extracting: val2017/000000545219.jpg  \n",
      " extracting: val2017/000000548555.jpg  \n",
      " extracting: val2017/000000308545.jpg  \n",
      " extracting: val2017/000000485071.jpg  \n",
      " extracting: val2017/000000511398.jpg  \n",
      " extracting: val2017/000000417779.jpg  \n",
      " extracting: val2017/000000155051.jpg  \n",
      " extracting: val2017/000000535608.jpg  \n",
      " extracting: val2017/000000126107.jpg  \n",
      " extracting: val2017/000000084752.jpg  \n",
      " extracting: val2017/000000038576.jpg  \n",
      " extracting: val2017/000000270474.jpg  \n",
      " extracting: val2017/000000343524.jpg  \n",
      " extracting: val2017/000000570834.jpg  \n",
      " extracting: val2017/000000448263.jpg  \n",
      " extracting: val2017/000000004395.jpg  \n",
      " extracting: val2017/000000010707.jpg  \n",
      " extracting: val2017/000000082688.jpg  \n",
      " extracting: val2017/000000398028.jpg  \n",
      " extracting: val2017/000000453708.jpg  \n",
      " extracting: val2017/000000365098.jpg  \n",
      " extracting: val2017/000000172946.jpg  \n",
      " extracting: val2017/000000131556.jpg  \n",
      " extracting: val2017/000000023126.jpg  \n",
      " extracting: val2017/000000407614.jpg  \n",
      " extracting: val2017/000000087476.jpg  \n",
      " extracting: val2017/000000105923.jpg  \n",
      " extracting: val2017/000000545730.jpg  \n",
      " extracting: val2017/000000516316.jpg  \n",
      " extracting: val2017/000000108026.jpg  \n",
      " extracting: val2017/000000151962.jpg  \n",
      " extracting: val2017/000000548524.jpg  \n",
      " extracting: val2017/000000373353.jpg  \n",
      " extracting: val2017/000000508586.jpg  \n",
      " extracting: val2017/000000215072.jpg  \n",
      " extracting: val2017/000000365387.jpg  \n",
      " extracting: val2017/000000089556.jpg  \n",
      " extracting: val2017/000000111179.jpg  \n",
      " extracting: val2017/000000176778.jpg  \n",
      " extracting: val2017/000000017379.jpg  \n",
      " extracting: val2017/000000303499.jpg  \n",
      " extracting: val2017/000000119641.jpg  \n",
      " extracting: val2017/000000210032.jpg  \n",
      " extracting: val2017/000000492878.jpg  \n",
      " extracting: val2017/000000096493.jpg  \n",
      " extracting: val2017/000000430377.jpg  \n",
      " extracting: val2017/000000122745.jpg  \n",
      " extracting: val2017/000000307598.jpg  \n",
      " extracting: val2017/000000166391.jpg  \n",
      " extracting: val2017/000000173033.jpg  \n",
      " extracting: val2017/000000146498.jpg  \n",
      " extracting: val2017/000000581206.jpg  \n",
      " extracting: val2017/000000173044.jpg  \n",
      " extracting: val2017/000000079837.jpg  \n",
      " extracting: val2017/000000375469.jpg  \n",
      " extracting: val2017/000000290619.jpg  \n",
      " extracting: val2017/000000416256.jpg  \n",
      " extracting: val2017/000000070158.jpg  \n",
      " extracting: val2017/000000465836.jpg  \n",
      " extracting: val2017/000000051008.jpg  \n",
      " extracting: val2017/000000364126.jpg  \n",
      " extracting: val2017/000000502732.jpg  \n",
      " extracting: val2017/000000006012.jpg  \n",
      " extracting: val2017/000000242946.jpg  \n",
      " extracting: val2017/000000229747.jpg  \n",
      " extracting: val2017/000000110972.jpg  \n",
      " extracting: val2017/000000453302.jpg  \n",
      " extracting: val2017/000000206025.jpg  \n",
      " extracting: val2017/000000015517.jpg  \n",
      " extracting: val2017/000000528524.jpg  \n",
      " extracting: val2017/000000458045.jpg  \n",
      " extracting: val2017/000000303863.jpg  \n",
      " extracting: val2017/000000516916.jpg  \n",
      " extracting: val2017/000000449198.jpg  \n",
      " extracting: val2017/000000185250.jpg  \n",
      " extracting: val2017/000000187513.jpg  \n",
      " extracting: val2017/000000488664.jpg  \n",
      " extracting: val2017/000000274687.jpg  \n",
      " extracting: val2017/000000318455.jpg  \n",
      " extracting: val2017/000000533536.jpg  \n",
      " extracting: val2017/000000252216.jpg  \n",
      " extracting: val2017/000000328683.jpg  \n",
      " extracting: val2017/000000363072.jpg  \n",
      " extracting: val2017/000000289415.jpg  \n",
      " extracting: val2017/000000150726.jpg  \n",
      " extracting: val2017/000000573391.jpg  \n",
      " extracting: val2017/000000473869.jpg  \n",
      " extracting: val2017/000000365886.jpg  \n",
      " extracting: val2017/000000108495.jpg  \n",
      " extracting: val2017/000000245651.jpg  \n",
      " extracting: val2017/000000253386.jpg  \n",
      " extracting: val2017/000000271728.jpg  \n",
      " extracting: val2017/000000456292.jpg  \n",
      " extracting: val2017/000000532071.jpg  \n",
      " extracting: val2017/000000229358.jpg  \n",
      " extracting: val2017/000000351096.jpg  \n",
      " extracting: val2017/000000545826.jpg  \n",
      " extracting: val2017/000000532129.jpg  \n",
      " extracting: val2017/000000481582.jpg  \n",
      " extracting: val2017/000000287347.jpg  \n",
      " extracting: val2017/000000508639.jpg  \n",
      " extracting: val2017/000000304396.jpg  \n",
      " extracting: val2017/000000493284.jpg  \n",
      " extracting: val2017/000000308799.jpg  \n",
      " extracting: val2017/000000084650.jpg  \n",
      " extracting: val2017/000000408120.jpg  \n",
      " extracting: val2017/000000129416.jpg  \n",
      " extracting: val2017/000000356169.jpg  \n",
      " extracting: val2017/000000558213.jpg  \n",
      " extracting: val2017/000000084031.jpg  \n",
      " extracting: val2017/000000171611.jpg  \n",
      " extracting: val2017/000000276720.jpg  \n",
      " extracting: val2017/000000147338.jpg  \n",
      " extracting: val2017/000000221291.jpg  \n",
      " extracting: val2017/000000194216.jpg  \n",
      " extracting: val2017/000000543528.jpg  \n",
      " extracting: val2017/000000474039.jpg  \n",
      " extracting: val2017/000000447088.jpg  \n",
      " extracting: val2017/000000322163.jpg  \n",
      " extracting: val2017/000000234757.jpg  \n",
      " extracting: val2017/000000569030.jpg  \n",
      " extracting: val2017/000000350388.jpg  \n",
      " extracting: val2017/000000534639.jpg  \n",
      " extracting: val2017/000000352584.jpg  \n",
      " extracting: val2017/000000347544.jpg  \n",
      " extracting: val2017/000000292446.jpg  \n",
      " extracting: val2017/000000417465.jpg  \n",
      " extracting: val2017/000000462031.jpg  \n",
      " extracting: val2017/000000574520.jpg  \n",
      " extracting: val2017/000000466986.jpg  \n",
      " extracting: val2017/000000133343.jpg  \n",
      " extracting: val2017/000000106266.jpg  \n",
      " extracting: val2017/000000416170.jpg  \n",
      " extracting: val2017/000000095069.jpg  \n",
      " extracting: val2017/000000489305.jpg  \n",
      " extracting: val2017/000000223188.jpg  \n",
      " extracting: val2017/000000284106.jpg  \n",
      " extracting: val2017/000000379332.jpg  \n",
      " extracting: val2017/000000012667.jpg  \n",
      " extracting: val2017/000000275392.jpg  \n",
      " extracting: val2017/000000045728.jpg  \n",
      " extracting: val2017/000000201072.jpg  \n",
      " extracting: val2017/000000120584.jpg  \n",
      " extracting: val2017/000000023937.jpg  \n",
      " extracting: val2017/000000516601.jpg  \n",
      " extracting: val2017/000000275198.jpg  \n",
      " extracting: val2017/000000505942.jpg  \n",
      " extracting: val2017/000000521231.jpg  \n",
      " extracting: val2017/000000023023.jpg  \n",
      " extracting: val2017/000000369541.jpg  \n",
      " extracting: val2017/000000250766.jpg  \n",
      " extracting: val2017/000000276284.jpg  \n",
      " extracting: val2017/000000565776.jpg  \n",
      " extracting: val2017/000000299355.jpg  \n",
      " extracting: val2017/000000488270.jpg  \n",
      " extracting: val2017/000000088040.jpg  \n",
      " extracting: val2017/000000062353.jpg  \n",
      " extracting: val2017/000000157418.jpg  \n",
      " extracting: val2017/000000102707.jpg  \n",
      " extracting: val2017/000000405195.jpg  \n",
      " extracting: val2017/000000177935.jpg  \n",
      " extracting: val2017/000000361180.jpg  \n",
      " extracting: val2017/000000278973.jpg  \n",
      " extracting: val2017/000000426376.jpg  \n",
      " extracting: val2017/000000572408.jpg  \n",
      " extracting: val2017/000000424162.jpg  \n",
      " extracting: val2017/000000251140.jpg  \n",
      " extracting: val2017/000000205282.jpg  \n",
      " extracting: val2017/000000163155.jpg  \n",
      " extracting: val2017/000000461573.jpg  \n",
      " extracting: val2017/000000349837.jpg  \n",
      " extracting: val2017/000000084362.jpg  \n",
      " extracting: val2017/000000132375.jpg  \n",
      " extracting: val2017/000000085157.jpg  \n",
      " extracting: val2017/000000391290.jpg  \n",
      " extracting: val2017/000000564280.jpg  \n",
      " extracting: val2017/000000492992.jpg  \n",
      " extracting: val2017/000000568814.jpg  \n",
      " extracting: val2017/000000423123.jpg  \n",
      " extracting: val2017/000000247806.jpg  \n",
      " extracting: val2017/000000334399.jpg  \n",
      " extracting: val2017/000000106048.jpg  \n",
      " extracting: val2017/000000332901.jpg  \n",
      " extracting: val2017/000000270244.jpg  \n",
      " extracting: val2017/000000150930.jpg  \n",
      " extracting: val2017/000000356428.jpg  \n",
      " extracting: val2017/000000151657.jpg  \n",
      " extracting: val2017/000000223789.jpg  \n",
      " extracting: val2017/000000222863.jpg  \n",
      " extracting: val2017/000000385997.jpg  \n",
      " extracting: val2017/000000312489.jpg  \n",
      " extracting: val2017/000000064499.jpg  \n",
      " extracting: val2017/000000485895.jpg  \n",
      " extracting: val2017/000000007991.jpg  \n",
      " extracting: val2017/000000227478.jpg  \n",
      " extracting: val2017/000000334483.jpg  \n",
      " extracting: val2017/000000313182.jpg  \n",
      " extracting: val2017/000000247917.jpg  \n",
      " extracting: val2017/000000386277.jpg  \n",
      " extracting: val2017/000000273642.jpg  \n",
      " extracting: val2017/000000024610.jpg  \n",
      " extracting: val2017/000000008844.jpg  \n",
      " extracting: val2017/000000107226.jpg  \n",
      " extracting: val2017/000000436738.jpg  \n",
      " extracting: val2017/000000553788.jpg  \n",
      " extracting: val2017/000000033104.jpg  \n",
      " extracting: val2017/000000039956.jpg  \n",
      " extracting: val2017/000000557884.jpg  \n",
      " extracting: val2017/000000426297.jpg  \n",
      " extracting: val2017/000000338718.jpg  \n",
      " extracting: val2017/000000456496.jpg  \n",
      " extracting: val2017/000000216419.jpg  \n",
      " extracting: val2017/000000157213.jpg  \n",
      " extracting: val2017/000000232649.jpg  \n",
      " extracting: val2017/000000172571.jpg  \n",
      " extracting: val2017/000000141597.jpg  \n",
      " extracting: val2017/000000076547.jpg  \n",
      " extracting: val2017/000000474881.jpg  \n",
      " extracting: val2017/000000329323.jpg  \n",
      " extracting: val2017/000000162858.jpg  \n",
      " extracting: val2017/000000343496.jpg  \n",
      " extracting: val2017/000000036539.jpg  \n",
      " extracting: val2017/000000170116.jpg  \n",
      " extracting: val2017/000000565607.jpg  \n",
      " extracting: val2017/000000244496.jpg  \n",
      " extracting: val2017/000000143572.jpg  \n",
      " extracting: val2017/000000210273.jpg  \n",
      " extracting: val2017/000000133778.jpg  \n",
      " extracting: val2017/000000094852.jpg  \n",
      " extracting: val2017/000000172856.jpg  \n",
      " extracting: val2017/000000463647.jpg  \n",
      " extracting: val2017/000000520324.jpg  \n",
      " extracting: val2017/000000226802.jpg  \n",
      " extracting: val2017/000000432085.jpg  \n",
      " extracting: val2017/000000532761.jpg  \n",
      " extracting: val2017/000000499622.jpg  \n",
      " extracting: val2017/000000563604.jpg  \n",
      " extracting: val2017/000000438269.jpg  \n",
      " extracting: val2017/000000409211.jpg  \n",
      " extracting: val2017/000000283037.jpg  \n",
      " extracting: val2017/000000551815.jpg  \n",
      " extracting: val2017/000000189226.jpg  \n",
      " extracting: val2017/000000258793.jpg  \n",
      " extracting: val2017/000000206411.jpg  \n",
      " extracting: val2017/000000522940.jpg  \n",
      " extracting: val2017/000000465806.jpg  \n",
      " extracting: val2017/000000414340.jpg  \n",
      " extracting: val2017/000000483667.jpg  \n",
      " extracting: val2017/000000354829.jpg  \n",
      " extracting: val2017/000000013659.jpg  \n",
      " extracting: val2017/000000196141.jpg  \n",
      " extracting: val2017/000000390902.jpg  \n",
      " extracting: val2017/000000221693.jpg  \n",
      " extracting: val2017/000000305609.jpg  \n",
      " extracting: val2017/000000565153.jpg  \n",
      " extracting: val2017/000000404805.jpg  \n",
      " extracting: val2017/000000060090.jpg  \n",
      " extracting: val2017/000000530820.jpg  \n",
      " extracting: val2017/000000230450.jpg  \n",
      " extracting: val2017/000000353180.jpg  \n",
      " extracting: val2017/000000118515.jpg  \n",
      " extracting: val2017/000000283520.jpg  \n",
      " extracting: val2017/000000410712.jpg  \n",
      " extracting: val2017/000000297353.jpg  \n",
      " extracting: val2017/000000331317.jpg  \n",
      " extracting: val2017/000000128051.jpg  \n",
      " extracting: val2017/000000579635.jpg  \n",
      " extracting: val2017/000000227482.jpg  \n",
      " extracting: val2017/000000185409.jpg  \n",
      " extracting: val2017/000000099182.jpg  \n",
      " extracting: val2017/000000122927.jpg  \n",
      " extracting: val2017/000000255718.jpg  \n",
      " extracting: val2017/000000552371.jpg  \n",
      " extracting: val2017/000000470952.jpg  \n",
      " extracting: val2017/000000039405.jpg  \n",
      " extracting: val2017/000000016010.jpg  \n",
      " extracting: val2017/000000470173.jpg  \n",
      " extracting: val2017/000000459437.jpg  \n",
      " extracting: val2017/000000045472.jpg  \n",
      " extracting: val2017/000000277020.jpg  \n",
      " extracting: val2017/000000282912.jpg  \n",
      " extracting: val2017/000000314034.jpg  \n",
      " extracting: val2017/000000148730.jpg  \n",
      " extracting: val2017/000000101068.jpg  \n",
      " extracting: val2017/000000407960.jpg  \n",
      " extracting: val2017/000000022396.jpg  \n",
      " extracting: val2017/000000541634.jpg  \n",
      " extracting: val2017/000000288762.jpg  \n",
      " extracting: val2017/000000439426.jpg  \n",
      " extracting: val2017/000000112110.jpg  \n",
      " extracting: val2017/000000022705.jpg  \n",
      " extracting: val2017/000000038829.jpg  \n",
      " extracting: val2017/000000361730.jpg  \n",
      " extracting: val2017/000000382030.jpg  \n",
      " extracting: val2017/000000402783.jpg  \n",
      " extracting: val2017/000000413247.jpg  \n",
      " extracting: val2017/000000578792.jpg  \n",
      " extracting: val2017/000000126226.jpg  \n",
      " extracting: val2017/000000372307.jpg  \n",
      " extracting: val2017/000000226984.jpg  \n",
      " extracting: val2017/000000295231.jpg  \n",
      " extracting: val2017/000000146358.jpg  \n",
      " extracting: val2017/000000455981.jpg  \n",
      " extracting: val2017/000000147518.jpg  \n",
      " extracting: val2017/000000090155.jpg  \n",
      " extracting: val2017/000000007795.jpg  \n",
      " extracting: val2017/000000468245.jpg  \n",
      " extracting: val2017/000000307074.jpg  \n",
      " extracting: val2017/000000082696.jpg  \n",
      " extracting: val2017/000000545958.jpg  \n",
      " extracting: val2017/000000411774.jpg  \n",
      " extracting: val2017/000000166747.jpg  \n",
      " extracting: val2017/000000308466.jpg  \n",
      " extracting: val2017/000000021167.jpg  \n",
      " extracting: val2017/000000402473.jpg  \n",
      " extracting: val2017/000000376625.jpg  \n",
      " extracting: val2017/000000347174.jpg  \n",
      " extracting: val2017/000000530146.jpg  \n",
      " extracting: val2017/000000430871.jpg  \n",
      " extracting: val2017/000000300913.jpg  \n",
      " extracting: val2017/000000291861.jpg  \n",
      " extracting: val2017/000000105912.jpg  \n",
      " extracting: val2017/000000489339.jpg  \n",
      " extracting: val2017/000000045090.jpg  \n",
      " extracting: val2017/000000485424.jpg  \n",
      " extracting: val2017/000000006723.jpg  \n",
      " extracting: val2017/000000431896.jpg  \n",
      " extracting: val2017/000000491497.jpg  \n",
      " extracting: val2017/000000402992.jpg  \n",
      " extracting: val2017/000000135872.jpg  \n",
      " extracting: val2017/000000098716.jpg  \n",
      " extracting: val2017/000000430875.jpg  \n",
      " extracting: val2017/000000414385.jpg  \n",
      " extracting: val2017/000000447917.jpg  \n",
      " extracting: val2017/000000362682.jpg  \n",
      " extracting: val2017/000000386210.jpg  \n",
      " extracting: val2017/000000110282.jpg  \n",
      " extracting: val2017/000000315001.jpg  \n",
      " extracting: val2017/000000354753.jpg  \n",
      " extracting: val2017/000000018770.jpg  \n",
      " extracting: val2017/000000005001.jpg  \n",
      " extracting: val2017/000000323355.jpg  \n",
      " extracting: val2017/000000427649.jpg  \n",
      " extracting: val2017/000000327617.jpg  \n",
      " extracting: val2017/000000187745.jpg  \n",
      " extracting: val2017/000000235778.jpg  \n",
      " extracting: val2017/000000352760.jpg  \n",
      " extracting: val2017/000000559707.jpg  \n",
      " extracting: val2017/000000059920.jpg  \n",
      " extracting: val2017/000000089880.jpg  \n",
      " extracting: val2017/000000288882.jpg  \n",
      " extracting: val2017/000000135670.jpg  \n",
      " extracting: val2017/000000470773.jpg  \n",
      " extracting: val2017/000000406570.jpg  \n",
      " extracting: val2017/000000410510.jpg  \n",
      " extracting: val2017/000000430073.jpg  \n",
      " extracting: val2017/000000153529.jpg  \n",
      " extracting: val2017/000000031217.jpg  \n",
      " extracting: val2017/000000190753.jpg  \n",
      " extracting: val2017/000000144798.jpg  \n",
      " extracting: val2017/000000430286.jpg  \n",
      " extracting: val2017/000000153299.jpg  \n",
      " extracting: val2017/000000334521.jpg  \n",
      " extracting: val2017/000000005477.jpg  \n",
      " extracting: val2017/000000378515.jpg  \n",
      " extracting: val2017/000000357501.jpg  \n",
      " extracting: val2017/000000131444.jpg  \n",
      " extracting: val2017/000000194746.jpg  \n",
      " extracting: val2017/000000290592.jpg  \n",
      " extracting: val2017/000000073118.jpg  \n",
      " extracting: val2017/000000131431.jpg  \n",
      " extracting: val2017/000000537270.jpg  \n",
      " extracting: val2017/000000297681.jpg  \n",
      " extracting: val2017/000000482275.jpg  \n",
      " extracting: val2017/000000125211.jpg  \n",
      " extracting: val2017/000000313454.jpg  \n",
      " extracting: val2017/000000566282.jpg  \n",
      " extracting: val2017/000000221017.jpg  \n",
      " extracting: val2017/000000117744.jpg  \n",
      " extracting: val2017/000000490413.jpg  \n",
      " extracting: val2017/000000205834.jpg  \n",
      " extracting: val2017/000000403565.jpg  \n",
      " extracting: val2017/000000237928.jpg  \n",
      " extracting: val2017/000000128598.jpg  \n",
      " extracting: val2017/000000448256.jpg  \n",
      " extracting: val2017/000000517069.jpg  \n",
      " extracting: val2017/000000163562.jpg  \n",
      " extracting: val2017/000000547336.jpg  \n",
      " extracting: val2017/000000194875.jpg  \n",
      " extracting: val2017/000000290843.jpg  \n",
      " extracting: val2017/000000116362.jpg  \n",
      " extracting: val2017/000000285349.jpg  \n",
      " extracting: val2017/000000293245.jpg  \n",
      " extracting: val2017/000000343561.jpg  \n",
      " extracting: val2017/000000530457.jpg  \n",
      " extracting: val2017/000000148620.jpg  \n",
      " extracting: val2017/000000512657.jpg  \n",
      " extracting: val2017/000000526256.jpg  \n",
      " extracting: val2017/000000453001.jpg  \n",
      " extracting: val2017/000000442463.jpg  \n",
      " extracting: val2017/000000196754.jpg  \n",
      " extracting: val2017/000000492758.jpg  \n",
      " extracting: val2017/000000459467.jpg  \n",
      " extracting: val2017/000000284743.jpg  \n",
      " extracting: val2017/000000356505.jpg  \n",
      " extracting: val2017/000000136466.jpg  \n",
      " extracting: val2017/000000294162.jpg  \n",
      " extracting: val2017/000000073533.jpg  \n",
      " extracting: val2017/000000535253.jpg  \n",
      " extracting: val2017/000000288685.jpg  \n",
      " extracting: val2017/000000577149.jpg  \n",
      " extracting: val2017/000000076731.jpg  \n",
      " extracting: val2017/000000223130.jpg  \n",
      " extracting: val2017/000000528578.jpg  \n",
      " extracting: val2017/000000580757.jpg  \n",
      " extracting: val2017/000000033854.jpg  \n",
      " extracting: val2017/000000286182.jpg  \n",
      " extracting: val2017/000000494863.jpg  \n",
      " extracting: val2017/000000305309.jpg  \n",
      " extracting: val2017/000000185599.jpg  \n",
      " extracting: val2017/000000107554.jpg  \n",
      " extracting: val2017/000000356125.jpg  \n",
      " extracting: val2017/000000015278.jpg  \n",
      " extracting: val2017/000000314251.jpg  \n",
      " extracting: val2017/000000238039.jpg  \n",
      " extracting: val2017/000000186873.jpg  \n",
      " extracting: val2017/000000052413.jpg  \n",
      " extracting: val2017/000000044590.jpg  \n",
      " extracting: val2017/000000361551.jpg  \n",
      " extracting: val2017/000000419201.jpg  \n",
      " extracting: val2017/000000568213.jpg  \n",
      " extracting: val2017/000000480212.jpg  \n",
      " extracting: val2017/000000281414.jpg  \n",
      " extracting: val2017/000000210299.jpg  \n",
      " extracting: val2017/000000080949.jpg  \n",
      " extracting: val2017/000000001675.jpg  \n",
      " extracting: val2017/000000141671.jpg  \n",
      " extracting: val2017/000000217948.jpg  \n",
      " extracting: val2017/000000386912.jpg  \n",
      " extracting: val2017/000000128654.jpg  \n",
      " extracting: val2017/000000509403.jpg  \n",
      " extracting: val2017/000000415194.jpg  \n",
      " extracting: val2017/000000509451.jpg  \n",
      " extracting: val2017/000000122606.jpg  \n",
      " extracting: val2017/000000400082.jpg  \n",
      " extracting: val2017/000000154718.jpg  \n",
      " extracting: val2017/000000057149.jpg  \n",
      " extracting: val2017/000000471789.jpg  \n",
      " extracting: val2017/000000401862.jpg  \n",
      " extracting: val2017/000000346707.jpg  \n",
      " extracting: val2017/000000491366.jpg  \n",
      " extracting: val2017/000000468332.jpg  \n",
      " extracting: val2017/000000345941.jpg  \n",
      " extracting: val2017/000000551794.jpg  \n",
      " extracting: val2017/000000297830.jpg  \n",
      " extracting: val2017/000000226592.jpg  \n",
      " extracting: val2017/000000046463.jpg  \n",
      " extracting: val2017/000000419098.jpg  \n",
      " extracting: val2017/000000122166.jpg  \n",
      " extracting: val2017/000000340451.jpg  \n",
      " extracting: val2017/000000143556.jpg  \n",
      " extracting: val2017/000000569825.jpg  \n",
      " extracting: val2017/000000520659.jpg  \n",
      " extracting: val2017/000000435205.jpg  \n",
      " extracting: val2017/000000467848.jpg  \n",
      " extracting: val2017/000000242060.jpg  \n",
      " extracting: val2017/000000007784.jpg  \n",
      " extracting: val2017/000000267537.jpg  \n",
      " extracting: val2017/000000172330.jpg  \n",
      " extracting: val2017/000000446117.jpg  \n",
      " extracting: val2017/000000445602.jpg  \n",
      " extracting: val2017/000000038070.jpg  \n",
      " extracting: val2017/000000281409.jpg  \n",
      " extracting: val2017/000000153527.jpg  \n",
      " extracting: val2017/000000410612.jpg  \n",
      " extracting: val2017/000000442993.jpg  \n",
      " extracting: val2017/000000319721.jpg  \n",
      " extracting: val2017/000000213830.jpg  \n",
      " extracting: val2017/000000533206.jpg  \n",
      " extracting: val2017/000000475484.jpg  \n",
      " extracting: val2017/000000117645.jpg  \n",
      " extracting: val2017/000000310862.jpg  \n",
      " extracting: val2017/000000504074.jpg  \n",
      " extracting: val2017/000000130579.jpg  \n",
      " extracting: val2017/000000289741.jpg  \n",
      " extracting: val2017/000000036936.jpg  \n",
      " extracting: val2017/000000441553.jpg  \n",
      " extracting: val2017/000000326627.jpg  \n",
      " extracting: val2017/000000029675.jpg  \n",
      " extracting: val2017/000000451144.jpg  \n",
      " extracting: val2017/000000341058.jpg  \n",
      " extracting: val2017/000000005586.jpg  \n",
      " extracting: val2017/000000092091.jpg  \n",
      " extracting: val2017/000000147745.jpg  \n",
      " extracting: val2017/000000119233.jpg  \n",
      " extracting: val2017/000000374727.jpg  \n",
      " extracting: val2017/000000100624.jpg  \n",
      " extracting: val2017/000000514979.jpg  \n",
      " extracting: val2017/000000344059.jpg  \n",
      " extracting: val2017/000000183049.jpg  \n",
      " extracting: val2017/000000394275.jpg  \n",
      " extracting: val2017/000000350054.jpg  \n",
      " extracting: val2017/000000551780.jpg  \n",
      " extracting: val2017/000000397303.jpg  \n",
      " extracting: val2017/000000041990.jpg  \n",
      " extracting: val2017/000000351810.jpg  \n",
      " extracting: val2017/000000315450.jpg  \n",
      " extracting: val2017/000000345385.jpg  \n",
      " extracting: val2017/000000513041.jpg  \n",
      " extracting: val2017/000000320554.jpg  \n",
      " extracting: val2017/000000283113.jpg  \n",
      " extracting: val2017/000000167067.jpg  \n",
      " extracting: val2017/000000489014.jpg  \n",
      " extracting: val2017/000000293324.jpg  \n",
      " extracting: val2017/000000087742.jpg  \n",
      " extracting: val2017/000000016439.jpg  \n",
      " extracting: val2017/000000166166.jpg  \n",
      " extracting: val2017/000000129492.jpg  \n",
      " extracting: val2017/000000125405.jpg  \n",
      " extracting: val2017/000000579307.jpg  \n",
      " extracting: val2017/000000412531.jpg  \n",
      " extracting: val2017/000000193674.jpg  \n",
      " extracting: val2017/000000252776.jpg  \n",
      " extracting: val2017/000000020059.jpg  \n",
      " extracting: val2017/000000500478.jpg  \n",
      " extracting: val2017/000000222735.jpg  \n",
      " extracting: val2017/000000039769.jpg  \n",
      " extracting: val2017/000000248334.jpg  \n",
      " extracting: val2017/000000436883.jpg  \n",
      " extracting: val2017/000000396729.jpg  \n",
      " extracting: val2017/000000507015.jpg  \n",
      " extracting: val2017/000000040036.jpg  \n",
      " extracting: val2017/000000543043.jpg  \n",
      " extracting: val2017/000000068078.jpg  \n",
      " extracting: val2017/000000280930.jpg  \n",
      " extracting: val2017/000000440336.jpg  \n",
      " extracting: val2017/000000277197.jpg  \n",
      " extracting: val2017/000000366225.jpg  \n",
      " extracting: val2017/000000316054.jpg  \n",
      " extracting: val2017/000000286994.jpg  \n",
      " extracting: val2017/000000409542.jpg  \n",
      " extracting: val2017/000000264335.jpg  \n",
      " extracting: val2017/000000067896.jpg  \n",
      " extracting: val2017/000000273712.jpg  \n",
      " extracting: val2017/000000092177.jpg  \n",
      " extracting: val2017/000000421455.jpg  \n",
      " extracting: val2017/000000394206.jpg  \n",
      " extracting: val2017/000000006818.jpg  \n",
      " extracting: val2017/000000006614.jpg  \n",
      " extracting: val2017/000000029596.jpg  \n",
      " extracting: val2017/000000551439.jpg  \n",
      " extracting: val2017/000000509824.jpg  \n",
      " extracting: val2017/000000531036.jpg  \n",
      " extracting: val2017/000000553094.jpg  \n",
      " extracting: val2017/000000382696.jpg  \n",
      " extracting: val2017/000000111207.jpg  \n",
      " extracting: val2017/000000176901.jpg  \n",
      " extracting: val2017/000000203488.jpg  \n",
      " extracting: val2017/000000338532.jpg  \n",
      " extracting: val2017/000000462904.jpg  \n",
      " extracting: val2017/000000469828.jpg  \n",
      " extracting: val2017/000000434230.jpg  \n",
      " extracting: val2017/000000136334.jpg  \n",
      " extracting: val2017/000000267191.jpg  \n",
      " extracting: val2017/000000193162.jpg  \n",
      " extracting: val2017/000000136915.jpg  \n",
      " extracting: val2017/000000220732.jpg  \n",
      " extracting: val2017/000000079188.jpg  \n",
      " extracting: val2017/000000451693.jpg  \n",
      " extracting: val2017/000000440171.jpg  \n",
      " extracting: val2017/000000045550.jpg  \n",
      " extracting: val2017/000000269942.jpg  \n",
      " extracting: val2017/000000293044.jpg  \n",
      " extracting: val2017/000000003553.jpg  \n",
      " extracting: val2017/000000357748.jpg  \n",
      " extracting: val2017/000000300659.jpg  \n",
      " extracting: val2017/000000563470.jpg  \n",
      " extracting: val2017/000000468954.jpg  \n",
      " extracting: val2017/000000081061.jpg  \n",
      " extracting: val2017/000000520910.jpg  \n",
      " extracting: val2017/000000568195.jpg  \n",
      " extracting: val2017/000000388927.jpg  \n",
      " extracting: val2017/000000357742.jpg  \n",
      " extracting: val2017/000000042296.jpg  \n",
      " extracting: val2017/000000482978.jpg  \n",
      " extracting: val2017/000000472375.jpg  \n",
      " extracting: val2017/000000363840.jpg  \n",
      " extracting: val2017/000000282046.jpg  \n",
      " extracting: val2017/000000400573.jpg  \n",
      " extracting: val2017/000000352618.jpg  \n",
      " extracting: val2017/000000427655.jpg  \n",
      " extracting: val2017/000000325527.jpg  \n",
      " extracting: val2017/000000523811.jpg  \n",
      " extracting: val2017/000000189820.jpg  \n",
      " extracting: val2017/000000439715.jpg  \n",
      " extracting: val2017/000000000785.jpg  \n",
      " extracting: val2017/000000512476.jpg  \n",
      " extracting: val2017/000000437331.jpg  \n",
      " extracting: val2017/000000325347.jpg  \n",
      " extracting: val2017/000000229659.jpg  \n",
      " extracting: val2017/000000225670.jpg  \n",
      " extracting: val2017/000000154087.jpg  \n",
      " extracting: val2017/000000232538.jpg  \n",
      " extracting: val2017/000000144333.jpg  \n",
      " extracting: val2017/000000300039.jpg  \n",
      " extracting: val2017/000000117719.jpg  \n",
      " extracting: val2017/000000297084.jpg  \n",
      " extracting: val2017/000000553669.jpg  \n",
      " extracting: val2017/000000409475.jpg  \n",
      " extracting: val2017/000000554579.jpg  \n",
      " extracting: val2017/000000398377.jpg  \n",
      " extracting: val2017/000000577182.jpg  \n",
      " extracting: val2017/000000080274.jpg  \n",
      " extracting: val2017/000000235241.jpg  \n",
      " extracting: val2017/000000359540.jpg  \n",
      " extracting: val2017/000000252716.jpg  \n",
      " extracting: val2017/000000562243.jpg  \n",
      " extracting: val2017/000000335450.jpg  \n",
      " extracting: val2017/000000128675.jpg  \n",
      " extracting: val2017/000000183648.jpg  \n",
      " extracting: val2017/000000437514.jpg  \n",
      " extracting: val2017/000000375763.jpg  \n",
      " extracting: val2017/000000357060.jpg  \n",
      " extracting: val2017/000000403353.jpg  \n",
      " extracting: val2017/000000507473.jpg  \n",
      " extracting: val2017/000000001353.jpg  \n",
      " extracting: val2017/000000153782.jpg  \n",
      " extracting: val2017/000000051610.jpg  \n",
      " extracting: val2017/000000210915.jpg  \n",
      " extracting: val2017/000000460494.jpg  \n",
      " extracting: val2017/000000396526.jpg  \n",
      " extracting: val2017/000000344611.jpg  \n",
      " extracting: val2017/000000160012.jpg  \n",
      " extracting: val2017/000000467315.jpg  \n",
      " extracting: val2017/000000535156.jpg  \n",
      " extracting: val2017/000000204329.jpg  \n",
      " extracting: val2017/000000084477.jpg  \n",
      " extracting: val2017/000000455448.jpg  \n",
      " extracting: val2017/000000452084.jpg  \n",
      " extracting: val2017/000000234607.jpg  \n",
      " extracting: val2017/000000301376.jpg  \n",
      " extracting: val2017/000000425906.jpg  \n",
      " extracting: val2017/000000151857.jpg  \n",
      " extracting: val2017/000000060449.jpg  \n",
      " extracting: val2017/000000145781.jpg  \n",
      " extracting: val2017/000000532493.jpg  \n",
      " extracting: val2017/000000298697.jpg  \n",
      " extracting: val2017/000000166478.jpg  \n",
      " extracting: val2017/000000551804.jpg  \n",
      " extracting: val2017/000000515828.jpg  \n",
      " extracting: val2017/000000463842.jpg  \n",
      " extracting: val2017/000000113867.jpg  \n",
      " extracting: val2017/000000485802.jpg  \n",
      " extracting: val2017/000000189310.jpg  \n",
      " extracting: val2017/000000519569.jpg  \n",
      " extracting: val2017/000000216739.jpg  \n",
      " extracting: val2017/000000098497.jpg  \n",
      " extracting: val2017/000000370478.jpg  \n",
      " extracting: val2017/000000121242.jpg  \n",
      " extracting: val2017/000000498286.jpg  \n",
      " extracting: val2017/000000136715.jpg  \n",
      " extracting: val2017/000000343218.jpg  \n",
      " extracting: val2017/000000348243.jpg  \n",
      " extracting: val2017/000000508917.jpg  \n",
      " extracting: val2017/000000058705.jpg  \n",
      " extracting: val2017/000000525600.jpg  \n",
      " extracting: val2017/000000347370.jpg  \n",
      " extracting: val2017/000000401244.jpg  \n",
      " extracting: val2017/000000333069.jpg  \n",
      " extracting: val2017/000000527215.jpg  \n",
      " extracting: val2017/000000199395.jpg  \n",
      " extracting: val2017/000000574810.jpg  \n",
      " extracting: val2017/000000273711.jpg  \n",
      " extracting: val2017/000000159282.jpg  \n",
      " extracting: val2017/000000576052.jpg  \n",
      " extracting: val2017/000000017182.jpg  \n",
      " extracting: val2017/000000276285.jpg  \n",
      " extracting: val2017/000000047769.jpg  \n",
      " extracting: val2017/000000513484.jpg  \n",
      " extracting: val2017/000000077460.jpg  \n",
      " extracting: val2017/000000136355.jpg  \n",
      " extracting: val2017/000000006954.jpg  \n",
      " extracting: val2017/000000115245.jpg  \n",
      " extracting: val2017/000000345466.jpg  \n",
      " extracting: val2017/000000302536.jpg  \n",
      " extracting: val2017/000000088951.jpg  \n",
      " extracting: val2017/000000044195.jpg  \n",
      " extracting: val2017/000000546626.jpg  \n",
      " extracting: val2017/000000009448.jpg  \n",
      " extracting: val2017/000000205324.jpg  \n",
      " extracting: val2017/000000061471.jpg  \n",
      " extracting: val2017/000000474786.jpg  \n",
      " extracting: val2017/000000462643.jpg  \n",
      " extracting: val2017/000000450399.jpg  \n",
      " extracting: val2017/000000410735.jpg  \n",
      " extracting: val2017/000000436551.jpg  \n",
      " extracting: val2017/000000232489.jpg  \n",
      " extracting: val2017/000000437205.jpg  \n",
      " extracting: val2017/000000575357.jpg  \n",
      " extracting: val2017/000000128699.jpg  \n",
      " extracting: val2017/000000017031.jpg  \n",
      " extracting: val2017/000000313034.jpg  \n",
      " extracting: val2017/000000457848.jpg  \n",
      " extracting: val2017/000000391375.jpg  \n",
      " extracting: val2017/000000535094.jpg  \n",
      " extracting: val2017/000000182162.jpg  \n",
      " extracting: val2017/000000095843.jpg  \n",
      " extracting: val2017/000000020247.jpg  \n",
      " extracting: val2017/000000144300.jpg  \n",
      " extracting: val2017/000000100283.jpg  \n",
      " extracting: val2017/000000417249.jpg  \n",
      " extracting: val2017/000000532855.jpg  \n",
      " extracting: val2017/000000433915.jpg  \n",
      " extracting: val2017/000000477288.jpg  \n",
      " extracting: val2017/000000210502.jpg  \n",
      " extracting: val2017/000000000776.jpg  \n",
      " extracting: val2017/000000166277.jpg  \n",
      " extracting: val2017/000000133631.jpg  \n",
      " extracting: val2017/000000085665.jpg  \n",
      " extracting: val2017/000000378284.jpg  \n",
      " extracting: val2017/000000190853.jpg  \n",
      " extracting: val2017/000000397354.jpg  \n",
      " extracting: val2017/000000353518.jpg  \n",
      " extracting: val2017/000000356427.jpg  \n",
      " extracting: val2017/000000477227.jpg  \n",
      " extracting: val2017/000000033114.jpg  \n",
      " extracting: val2017/000000565045.jpg  \n",
      " extracting: val2017/000000245102.jpg  \n",
      " extracting: val2017/000000296657.jpg  \n",
      " extracting: val2017/000000556158.jpg  \n",
      " extracting: val2017/000000554595.jpg  \n",
      " extracting: val2017/000000546717.jpg  \n",
      " extracting: val2017/000000557916.jpg  \n",
      " extracting: val2017/000000486040.jpg  \n",
      " extracting: val2017/000000095862.jpg  \n",
      " extracting: val2017/000000433374.jpg  \n",
      " extracting: val2017/000000184762.jpg  \n",
      " extracting: val2017/000000326541.jpg  \n",
      " extracting: val2017/000000113235.jpg  \n",
      " extracting: val2017/000000503855.jpg  \n",
      " extracting: val2017/000000044068.jpg  \n",
      " extracting: val2017/000000522156.jpg  \n",
      " extracting: val2017/000000338219.jpg  \n",
      " extracting: val2017/000000309173.jpg  \n",
      " extracting: val2017/000000416330.jpg  \n",
      " extracting: val2017/000000186042.jpg  \n",
      " extracting: val2017/000000574297.jpg  \n",
      " extracting: val2017/000000431693.jpg  \n",
      " extracting: val2017/000000060347.jpg  \n",
      " extracting: val2017/000000022192.jpg  \n",
      " extracting: val2017/000000566524.jpg  \n",
      " extracting: val2017/000000560312.jpg  \n",
      " extracting: val2017/000000364636.jpg  \n",
      " extracting: val2017/000000344100.jpg  \n",
      " extracting: val2017/000000537506.jpg  \n",
      " extracting: val2017/000000373382.jpg  \n",
      " extracting: val2017/000000398438.jpg  \n",
      " extracting: val2017/000000357459.jpg  \n",
      " extracting: val2017/000000528399.jpg  \n",
      " extracting: val2017/000000368038.jpg  \n",
      " extracting: val2017/000000575815.jpg  \n",
      " extracting: val2017/000000183965.jpg  \n",
      " extracting: val2017/000000014380.jpg  \n",
      " extracting: val2017/000000189213.jpg  \n",
      " extracting: val2017/000000148957.jpg  \n",
      " extracting: val2017/000000489842.jpg  \n",
      " extracting: val2017/000000085329.jpg  \n",
      " extracting: val2017/000000445834.jpg  \n",
      " extracting: val2017/000000047571.jpg  \n",
      " extracting: val2017/000000371472.jpg  \n",
      " extracting: val2017/000000232244.jpg  \n",
      " extracting: val2017/000000279145.jpg  \n",
      " extracting: val2017/000000324158.jpg  \n",
      " extracting: val2017/000000250901.jpg  \n",
      " extracting: val2017/000000418062.jpg  \n",
      " extracting: val2017/000000416269.jpg  \n",
      " extracting: val2017/000000312340.jpg  \n",
      " extracting: val2017/000000228771.jpg  \n",
      " extracting: val2017/000000524108.jpg  \n",
      " extracting: val2017/000000356094.jpg  \n",
      " extracting: val2017/000000553776.jpg  \n",
      " extracting: val2017/000000414133.jpg  \n",
      " extracting: val2017/000000579818.jpg  \n",
      " extracting: val2017/000000356387.jpg  \n",
      " extracting: val2017/000000269121.jpg  \n",
      " extracting: val2017/000000222458.jpg  \n",
      " extracting: val2017/000000537812.jpg  \n",
      " extracting: val2017/000000429598.jpg  \n",
      " extracting: val2017/000000025986.jpg  \n",
      " extracting: val2017/000000097022.jpg  \n",
      " extracting: val2017/000000362716.jpg  \n",
      " extracting: val2017/000000161875.jpg  \n",
      " extracting: val2017/000000028993.jpg  \n",
      " extracting: val2017/000000382743.jpg  \n",
      " extracting: val2017/000000290248.jpg  \n",
      " extracting: val2017/000000576031.jpg  \n",
      " extracting: val2017/000000273420.jpg  \n",
      " extracting: val2017/000000146667.jpg  \n",
      " extracting: val2017/000000369370.jpg  \n",
      " extracting: val2017/000000402720.jpg  \n",
      " extracting: val2017/000000056545.jpg  \n",
      " extracting: val2017/000000082846.jpg  \n",
      " extracting: val2017/000000454750.jpg  \n",
      " extracting: val2017/000000295478.jpg  \n",
      " extracting: val2017/000000194724.jpg  \n",
      " extracting: val2017/000000139684.jpg  \n",
      " extracting: val2017/000000451435.jpg  \n",
      " extracting: val2017/000000032901.jpg  \n",
      " extracting: val2017/000000580410.jpg  \n",
      " extracting: val2017/000000579070.jpg  \n",
      " extracting: val2017/000000355677.jpg  \n",
      " extracting: val2017/000000393093.jpg  \n",
      " extracting: val2017/000000370270.jpg  \n",
      " extracting: val2017/000000155179.jpg  \n",
      " extracting: val2017/000000256518.jpg  \n",
      " extracting: val2017/000000048555.jpg  \n",
      " extracting: val2017/000000119995.jpg  \n",
      " extracting: val2017/000000512248.jpg  \n",
      " extracting: val2017/000000038678.jpg  \n",
      " extracting: val2017/000000135673.jpg  \n",
      " extracting: val2017/000000498857.jpg  \n",
      " extracting: val2017/000000166642.jpg  \n",
      " extracting: val2017/000000542625.jpg  \n",
      " extracting: val2017/000000534601.jpg  \n",
      " extracting: val2017/000000255401.jpg  \n",
      " extracting: val2017/000000097278.jpg  \n",
      " extracting: val2017/000000291490.jpg  \n",
      " extracting: val2017/000000537964.jpg  \n",
      " extracting: val2017/000000369812.jpg  \n",
      " extracting: val2017/000000459500.jpg  \n",
      " extracting: val2017/000000322211.jpg  \n",
      " extracting: val2017/000000370208.jpg  \n",
      " extracting: val2017/000000550691.jpg  \n",
      " extracting: val2017/000000226130.jpg  \n",
      " extracting: val2017/000000212800.jpg  \n",
      " extracting: val2017/000000093353.jpg  \n",
      " extracting: val2017/000000161925.jpg  \n",
      " extracting: val2017/000000342006.jpg  \n",
      " extracting: val2017/000000128148.jpg  \n",
      " extracting: val2017/000000396200.jpg  \n",
      " extracting: val2017/000000396580.jpg  \n",
      " extracting: val2017/000000450303.jpg  \n",
      " extracting: val2017/000000463618.jpg  \n",
      " extracting: val2017/000000491613.jpg  \n",
      " extracting: val2017/000000433204.jpg  \n",
      " extracting: val2017/000000491008.jpg  \n",
      " extracting: val2017/000000152740.jpg  \n",
      " extracting: val2017/000000119445.jpg  \n",
      " extracting: val2017/000000089648.jpg  \n",
      " extracting: val2017/000000061268.jpg  \n",
      " extracting: val2017/000000570169.jpg  \n",
      " extracting: val2017/000000168593.jpg  \n",
      " extracting: val2017/000000526103.jpg  \n",
      " extracting: val2017/000000329614.jpg  \n",
      " extracting: val2017/000000079229.jpg  \n",
      " extracting: val2017/000000529148.jpg  \n",
      " extracting: val2017/000000034452.jpg  \n",
      " extracting: val2017/000000341196.jpg  \n",
      " extracting: val2017/000000457559.jpg  \n",
      " extracting: val2017/000000210394.jpg  \n",
      " extracting: val2017/000000471023.jpg  \n",
      " extracting: val2017/000000181753.jpg  \n",
      " extracting: val2017/000000497599.jpg  \n",
      " extracting: val2017/000000384513.jpg  \n",
      " extracting: val2017/000000559956.jpg  \n",
      " extracting: val2017/000000149622.jpg  \n",
      " extracting: val2017/000000529762.jpg  \n",
      " extracting: val2017/000000119516.jpg  \n",
      " extracting: val2017/000000295138.jpg  \n",
      " extracting: val2017/000000515579.jpg  \n",
      " extracting: val2017/000000559842.jpg  \n",
      " extracting: val2017/000000439623.jpg  \n",
      " extracting: val2017/000000557172.jpg  \n",
      " extracting: val2017/000000284623.jpg  \n",
      " extracting: val2017/000000277584.jpg  \n",
      " extracting: val2017/000000476514.jpg  \n",
      " extracting: val2017/000000463690.jpg  \n",
      " extracting: val2017/000000330369.jpg  \n",
      " extracting: val2017/000000116825.jpg  \n",
      " extracting: val2017/000000505451.jpg  \n",
      " extracting: val2017/000000070048.jpg  \n",
      " extracting: val2017/000000565877.jpg  \n",
      " extracting: val2017/000000220764.jpg  \n",
      " extracting: val2017/000000482585.jpg  \n",
      " extracting: val2017/000000468925.jpg  \n",
      " extracting: val2017/000000364102.jpg  \n",
      " extracting: val2017/000000407868.jpg  \n",
      " extracting: val2017/000000370042.jpg  \n",
      " extracting: val2017/000000581615.jpg  \n",
      " extracting: val2017/000000311081.jpg  \n",
      " extracting: val2017/000000502229.jpg  \n",
      " extracting: val2017/000000425227.jpg  \n",
      " extracting: val2017/000000157847.jpg  \n",
      " extracting: val2017/000000376310.jpg  \n",
      " extracting: val2017/000000170595.jpg  \n",
      " extracting: val2017/000000226171.jpg  \n",
      " extracting: val2017/000000082765.jpg  \n",
      " extracting: val2017/000000005992.jpg  \n",
      " extracting: val2017/000000435299.jpg  \n",
      " extracting: val2017/000000266206.jpg  \n",
      " extracting: val2017/000000121744.jpg  \n",
      " extracting: val2017/000000216497.jpg  \n",
      " extracting: val2017/000000425226.jpg  \n",
      " extracting: val2017/000000402519.jpg  \n",
      " extracting: val2017/000000326462.jpg  \n",
      " extracting: val2017/000000094326.jpg  \n",
      " extracting: val2017/000000549674.jpg  \n",
      " extracting: val2017/000000163951.jpg  \n",
      " extracting: val2017/000000455555.jpg  \n",
      " extracting: val2017/000000575205.jpg  \n",
      " extracting: val2017/000000502336.jpg  \n",
      " extracting: val2017/000000526197.jpg  \n",
      " extracting: val2017/000000504389.jpg  \n",
      " extracting: val2017/000000138550.jpg  \n",
      " extracting: val2017/000000255965.jpg  \n",
      " extracting: val2017/000000405306.jpg  \n",
      " extracting: val2017/000000199681.jpg  \n",
      " extracting: val2017/000000286660.jpg  \n",
      " extracting: val2017/000000300341.jpg  \n",
      " extracting: val2017/000000325483.jpg  \n",
      " extracting: val2017/000000187144.jpg  \n",
      " extracting: val2017/000000281929.jpg  \n",
      " extracting: val2017/000000451155.jpg  \n",
      " extracting: val2017/000000313562.jpg  \n",
      " extracting: val2017/000000231549.jpg  \n",
      " extracting: val2017/000000038825.jpg  \n",
      " extracting: val2017/000000259571.jpg  \n",
      " extracting: val2017/000000494913.jpg  \n",
      " extracting: val2017/000000213935.jpg  \n",
      " extracting: val2017/000000203864.jpg  \n",
      " extracting: val2017/000000334530.jpg  \n",
      " extracting: val2017/000000372718.jpg  \n",
      " extracting: val2017/000000356968.jpg  \n",
      " extracting: val2017/000000416837.jpg  \n",
      " extracting: val2017/000000514540.jpg  \n",
      " extracting: val2017/000000457884.jpg  \n",
      " extracting: val2017/000000511321.jpg  \n",
      " extracting: val2017/000000095899.jpg  \n",
      " extracting: val2017/000000064868.jpg  \n",
      " extracting: val2017/000000482100.jpg  \n",
      " extracting: val2017/000000442456.jpg  \n",
      " extracting: val2017/000000308328.jpg  \n",
      " extracting: val2017/000000528705.jpg  \n",
      " extracting: val2017/000000512929.jpg  \n",
      " extracting: val2017/000000569972.jpg  \n",
      " extracting: val2017/000000023230.jpg  \n",
      " extracting: val2017/000000319534.jpg  \n",
      " extracting: val2017/000000167898.jpg  \n",
      " extracting: val2017/000000139871.jpg  \n",
      " extracting: val2017/000000363875.jpg  \n",
      " extracting: val2017/000000017207.jpg  \n",
      " extracting: val2017/000000384670.jpg  \n",
      " extracting: val2017/000000489091.jpg  \n",
      " extracting: val2017/000000514797.jpg  \n",
      " extracting: val2017/000000274708.jpg  \n",
      " extracting: val2017/000000342971.jpg  \n",
      " extracting: val2017/000000126592.jpg  \n",
      " extracting: val2017/000000393282.jpg  \n",
      " extracting: val2017/000000150265.jpg  \n",
      " extracting: val2017/000000400922.jpg  \n",
      " extracting: val2017/000000050943.jpg  \n",
      " extracting: val2017/000000002532.jpg  \n",
      " extracting: val2017/000000290179.jpg  \n",
      " extracting: val2017/000000055528.jpg  \n",
      " extracting: val2017/000000429281.jpg  \n",
      " extracting: val2017/000000385190.jpg  \n",
      " extracting: val2017/000000372203.jpg  \n",
      " extracting: val2017/000000213035.jpg  \n",
      " extracting: val2017/000000377635.jpg  \n",
      " extracting: val2017/000000042178.jpg  \n",
      " extracting: val2017/000000309484.jpg  \n",
      " extracting: val2017/000000287527.jpg  \n",
      " extracting: val2017/000000412894.jpg  \n",
      " extracting: val2017/000000308793.jpg  \n",
      " extracting: val2017/000000357430.jpg  \n",
      " extracting: val2017/000000245764.jpg  \n",
      " extracting: val2017/000000416534.jpg  \n",
      " extracting: val2017/000000314709.jpg  \n",
      " extracting: val2017/000000415536.jpg  \n",
      " extracting: val2017/000000392818.jpg  \n",
      " extracting: val2017/000000339442.jpg  \n",
      " extracting: val2017/000000270402.jpg  \n",
      " extracting: val2017/000000146457.jpg  \n",
      " extracting: val2017/000000428454.jpg  \n",
      " extracting: val2017/000000268378.jpg  \n",
      " extracting: val2017/000000033638.jpg  \n",
      " extracting: val2017/000000307658.jpg  \n",
      " extracting: val2017/000000132329.jpg  \n",
      " extracting: val2017/000000394940.jpg  \n",
      " extracting: val2017/000000455872.jpg  \n",
      " extracting: val2017/000000099242.jpg  \n",
      " extracting: val2017/000000530466.jpg  \n",
      " extracting: val2017/000000482319.jpg  \n",
      " extracting: val2017/000000190923.jpg  \n",
      " extracting: val2017/000000543581.jpg  \n",
      " extracting: val2017/000000201646.jpg  \n",
      " extracting: val2017/000000011511.jpg  \n",
      " extracting: val2017/000000402433.jpg  \n",
      " extracting: val2017/000000376206.jpg  \n",
      " extracting: val2017/000000007281.jpg  \n",
      " extracting: val2017/000000445658.jpg  \n",
      " extracting: val2017/000000479030.jpg  \n",
      " extracting: val2017/000000321118.jpg  \n",
      " extracting: val2017/000000120572.jpg  \n",
      " extracting: val2017/000000186282.jpg  \n",
      " extracting: val2017/000000477805.jpg  \n",
      " extracting: val2017/000000438226.jpg  \n",
      " extracting: val2017/000000036660.jpg  \n",
      " extracting: val2017/000000230362.jpg  \n",
      " extracting: val2017/000000175535.jpg  \n",
      " extracting: val2017/000000255747.jpg  \n",
      " extracting: val2017/000000328959.jpg  \n",
      " extracting: val2017/000000460379.jpg  \n",
      " extracting: val2017/000000261982.jpg  \n",
      " extracting: val2017/000000461009.jpg  \n",
      " extracting: val2017/000000105264.jpg  \n",
      " extracting: val2017/000000525322.jpg  \n",
      " extracting: val2017/000000260266.jpg  \n",
      " extracting: val2017/000000001503.jpg  \n",
      " extracting: val2017/000000057232.jpg  \n",
      " extracting: val2017/000000374982.jpg  \n",
      " extracting: val2017/000000106757.jpg  \n",
      " extracting: val2017/000000132703.jpg  \n",
      " extracting: val2017/000000236690.jpg  \n",
      " extracting: val2017/000000405970.jpg  \n",
      " extracting: val2017/000000456662.jpg  \n",
      " extracting: val2017/000000259640.jpg  \n",
      " extracting: val2017/000000025560.jpg  \n",
      " extracting: val2017/000000134096.jpg  \n",
      " extracting: val2017/000000379441.jpg  \n",
      " extracting: val2017/000000217400.jpg  \n",
      " extracting: val2017/000000039670.jpg  \n",
      " extracting: val2017/000000236599.jpg  \n",
      " extracting: val2017/000000052996.jpg  \n",
      " extracting: val2017/000000214869.jpg  \n",
      " extracting: val2017/000000008211.jpg  \n",
      " extracting: val2017/000000106912.jpg  \n",
      " extracting: val2017/000000154004.jpg  \n",
      " extracting: val2017/000000173302.jpg  \n",
      " extracting: val2017/000000537355.jpg  \n",
      " extracting: val2017/000000221502.jpg  \n",
      " extracting: val2017/000000098287.jpg  \n",
      " extracting: val2017/000000343706.jpg  \n",
      " extracting: val2017/000000251537.jpg  \n",
      " extracting: val2017/000000238410.jpg  \n",
      " extracting: val2017/000000364166.jpg  \n",
      " extracting: val2017/000000187243.jpg  \n",
      " extracting: val2017/000000076468.jpg  \n",
      " extracting: val2017/000000387148.jpg  \n",
      " extracting: val2017/000000465549.jpg  \n",
      " extracting: val2017/000000153568.jpg  \n",
      " extracting: val2017/000000192191.jpg  \n",
      " extracting: val2017/000000379453.jpg  \n",
      " extracting: val2017/000000224093.jpg  \n",
      " extracting: val2017/000000349678.jpg  \n",
      " extracting: val2017/000000325838.jpg  \n",
      " extracting: val2017/000000042528.jpg  \n",
      " extracting: val2017/000000448365.jpg  \n",
      " extracting: val2017/000000388056.jpg  \n",
      " extracting: val2017/000000124442.jpg  \n",
      " extracting: val2017/000000361238.jpg  \n",
      " extracting: val2017/000000572462.jpg  \n",
      " extracting: val2017/000000161008.jpg  \n",
      " extracting: val2017/000000509735.jpg  \n",
      " extracting: val2017/000000465718.jpg  \n",
      " extracting: val2017/000000080413.jpg  \n",
      " extracting: val2017/000000185157.jpg  \n",
      " extracting: val2017/000000360393.jpg  \n",
      " extracting: val2017/000000496954.jpg  \n",
      " extracting: val2017/000000335529.jpg  \n",
      " extracting: val2017/000000559543.jpg  \n",
      " extracting: val2017/000000063965.jpg  \n",
      " extracting: val2017/000000467776.jpg  \n",
      " extracting: val2017/000000309467.jpg  \n",
      " extracting: val2017/000000516708.jpg  \n",
      " extracting: val2017/000000417043.jpg  \n",
      " extracting: val2017/000000375278.jpg  \n",
      " extracting: val2017/000000336265.jpg  \n",
      " extracting: val2017/000000552902.jpg  \n",
      " extracting: val2017/000000188592.jpg  \n",
      " extracting: val2017/000000161044.jpg  \n",
      " extracting: val2017/000000530052.jpg  \n",
      " extracting: val2017/000000431568.jpg  \n",
      " extracting: val2017/000000192871.jpg  \n",
      " extracting: val2017/000000217285.jpg  \n",
      " extracting: val2017/000000210789.jpg  \n",
      " extracting: val2017/000000482917.jpg  \n",
      " extracting: val2017/000000040083.jpg  \n",
      " extracting: val2017/000000106330.jpg  \n",
      " extracting: val2017/000000320696.jpg  \n",
      " extracting: val2017/000000002006.jpg  \n",
      " extracting: val2017/000000025228.jpg  \n",
      " extracting: val2017/000000072813.jpg  \n",
      " extracting: val2017/000000259097.jpg  \n",
      " extracting: val2017/000000077595.jpg  \n",
      " extracting: val2017/000000209829.jpg  \n",
      " extracting: val2017/000000554156.jpg  \n",
      " extracting: val2017/000000262938.jpg  \n",
      " extracting: val2017/000000236592.jpg  \n",
      " extracting: val2017/000000556873.jpg  \n",
      " extracting: val2017/000000064359.jpg  \n",
      " extracting: val2017/000000206487.jpg  \n",
      " extracting: val2017/000000432468.jpg  \n",
      " extracting: val2017/000000001296.jpg  \n",
      " extracting: val2017/000000027186.jpg  \n",
      " extracting: val2017/000000406997.jpg  \n",
      " extracting: val2017/000000546823.jpg  \n",
      " extracting: val2017/000000236730.jpg  \n",
      " extracting: val2017/000000460683.jpg  \n",
      " extracting: val2017/000000206271.jpg  \n",
      " extracting: val2017/000000213422.jpg  \n",
      " extracting: val2017/000000526392.jpg  \n",
      " extracting: val2017/000000337055.jpg  \n",
      " extracting: val2017/000000456394.jpg  \n",
      " extracting: val2017/000000378605.jpg  \n",
      " extracting: val2017/000000328238.jpg  \n",
      " extracting: val2017/000000522713.jpg  \n",
      " extracting: val2017/000000426241.jpg  \n",
      " extracting: val2017/000000048396.jpg  \n",
      " extracting: val2017/000000416104.jpg  \n",
      " extracting: val2017/000000041633.jpg  \n",
      " extracting: val2017/000000396338.jpg  \n",
      " extracting: val2017/000000404534.jpg  \n",
      " extracting: val2017/000000518770.jpg  \n",
      " extracting: val2017/000000500211.jpg  \n",
      " extracting: val2017/000000299720.jpg  \n",
      " extracting: val2017/000000177357.jpg  \n",
      " extracting: val2017/000000252332.jpg  \n",
      " extracting: val2017/000000276804.jpg  \n",
      " extracting: val2017/000000214224.jpg  \n",
      " extracting: val2017/000000484296.jpg  \n",
      " extracting: val2017/000000297396.jpg  \n",
      " extracting: val2017/000000214720.jpg  \n",
      " extracting: val2017/000000486479.jpg  \n",
      " extracting: val2017/000000023666.jpg  \n",
      " extracting: val2017/000000340930.jpg  \n",
      " extracting: val2017/000000528980.jpg  \n",
      " extracting: val2017/000000267300.jpg  \n",
      " extracting: val2017/000000559160.jpg  \n",
      " extracting: val2017/000000007386.jpg  \n",
      " extracting: val2017/000000105455.jpg  \n",
      " extracting: val2017/000000489764.jpg  \n",
      " extracting: val2017/000000537053.jpg  \n",
      " extracting: val2017/000000084674.jpg  \n",
      " extracting: val2017/000000117197.jpg  \n",
      " extracting: val2017/000000361586.jpg  \n",
      " extracting: val2017/000000250282.jpg  \n",
      " extracting: val2017/000000203931.jpg  \n",
      " extracting: val2017/000000050638.jpg  \n",
      " extracting: val2017/000000115946.jpg  \n",
      " extracting: val2017/000000538067.jpg  \n",
      " extracting: val2017/000000366178.jpg  \n",
      " extracting: val2017/000000402334.jpg  \n",
      " extracting: val2017/000000329827.jpg  \n",
      " extracting: val2017/000000127476.jpg  \n",
      " extracting: val2017/000000228214.jpg  \n",
      " extracting: val2017/000000347335.jpg  \n",
      " extracting: val2017/000000485972.jpg  \n",
      " extracting: val2017/000000496722.jpg  \n",
      " extracting: val2017/000000156071.jpg  \n",
      " extracting: val2017/000000434996.jpg  \n",
      " extracting: val2017/000000277051.jpg  \n",
      " extracting: val2017/000000579655.jpg  \n",
      " extracting: val2017/000000131379.jpg  \n",
      " extracting: val2017/000000110721.jpg  \n",
      " extracting: val2017/000000401250.jpg  \n",
      " extracting: val2017/000000162130.jpg  \n",
      " extracting: val2017/000000418696.jpg  \n",
      " extracting: val2017/000000286553.jpg  \n",
      " extracting: val2017/000000231822.jpg  \n",
      " extracting: val2017/000000268831.jpg  \n",
      " extracting: val2017/000000098633.jpg  \n",
      " extracting: val2017/000000423104.jpg  \n",
      " extracting: val2017/000000168330.jpg  \n",
      " extracting: val2017/000000172977.jpg  \n",
      " extracting: val2017/000000078426.jpg  \n",
      " extracting: val2017/000000279714.jpg  \n",
      " extracting: val2017/000000181542.jpg  \n",
      " extracting: val2017/000000404839.jpg  \n",
      " extracting: val2017/000000167540.jpg  \n",
      " extracting: val2017/000000159791.jpg  \n",
      " extracting: val2017/000000004795.jpg  \n",
      " extracting: val2017/000000208363.jpg  \n",
      " extracting: val2017/000000351331.jpg  \n",
      " extracting: val2017/000000511599.jpg  \n",
      " extracting: val2017/000000572517.jpg  \n",
      " extracting: val2017/000000517832.jpg  \n",
      " extracting: val2017/000000568981.jpg  \n",
      " extracting: val2017/000000422886.jpg  \n",
      " extracting: val2017/000000568147.jpg  \n",
      " extracting: val2017/000000448410.jpg  \n",
      " extracting: val2017/000000167902.jpg  \n",
      " extracting: val2017/000000278749.jpg  \n",
      " extracting: val2017/000000335800.jpg  \n",
      " extracting: val2017/000000224222.jpg  \n",
      " extracting: val2017/000000002592.jpg  \n",
      " extracting: val2017/000000010363.jpg  \n",
      " extracting: val2017/000000109055.jpg  \n",
      " extracting: val2017/000000138979.jpg  \n",
      " extracting: val2017/000000220584.jpg  \n",
      " extracting: val2017/000000006894.jpg  \n",
      " extracting: val2017/000000416991.jpg  \n",
      " extracting: val2017/000000368961.jpg  \n",
      " extracting: val2017/000000395575.jpg  \n",
      " extracting: val2017/000000384527.jpg  \n",
      " extracting: val2017/000000078032.jpg  \n",
      " extracting: val2017/000000032610.jpg  \n",
      " extracting: val2017/000000563758.jpg  \n",
      " extracting: val2017/000000050326.jpg  \n",
      " extracting: val2017/000000157046.jpg  \n",
      " extracting: val2017/000000140929.jpg  \n",
      " extracting: val2017/000000489611.jpg  \n",
      " extracting: val2017/000000017714.jpg  \n",
      " extracting: val2017/000000506310.jpg  \n",
      " extracting: val2017/000000065288.jpg  \n",
      " extracting: val2017/000000061333.jpg  \n",
      " extracting: val2017/000000465430.jpg  \n",
      " extracting: val2017/000000316404.jpg  \n",
      " extracting: val2017/000000037751.jpg  \n",
      " extracting: val2017/000000189436.jpg  \n",
      " extracting: val2017/000000193884.jpg  \n",
      " extracting: val2017/000000552775.jpg  \n",
      " extracting: val2017/000000387916.jpg  \n",
      " extracting: val2017/000000402774.jpg  \n",
      " extracting: val2017/000000327601.jpg  \n",
      " extracting: val2017/000000532690.jpg  \n",
      " extracting: val2017/000000162366.jpg  \n",
      " extracting: val2017/000000286503.jpg  \n",
      " extracting: val2017/000000102411.jpg  \n",
      " extracting: val2017/000000378139.jpg  \n",
      " extracting: val2017/000000032081.jpg  \n",
      " extracting: val2017/000000138241.jpg  \n",
      " extracting: val2017/000000417085.jpg  \n",
      " extracting: val2017/000000047828.jpg  \n",
      " extracting: val2017/000000527784.jpg  \n",
      " extracting: val2017/000000578489.jpg  \n",
      " extracting: val2017/000000011122.jpg  \n",
      " extracting: val2017/000000484351.jpg  \n",
      " extracting: val2017/000000039480.jpg  \n",
      " extracting: val2017/000000243495.jpg  \n",
      " extracting: val2017/000000324614.jpg  \n",
      " extracting: val2017/000000505573.jpg  \n",
      " extracting: val2017/000000525083.jpg  \n",
      " extracting: val2017/000000453860.jpg  \n",
      " extracting: val2017/000000370813.jpg  \n",
      " extracting: val2017/000000470779.jpg  \n",
      " extracting: val2017/000000578500.jpg  \n",
      " extracting: val2017/000000286908.jpg  \n",
      " extracting: val2017/000000337987.jpg  \n",
      " extracting: val2017/000000498747.jpg  \n",
      " extracting: val2017/000000403385.jpg  \n",
      " extracting: val2017/000000400815.jpg  \n",
      " extracting: val2017/000000211069.jpg  \n",
      " extracting: val2017/000000082180.jpg  \n",
      " extracting: val2017/000000361506.jpg  \n",
      " extracting: val2017/000000281754.jpg  \n",
      " extracting: val2017/000000508312.jpg  \n",
      " extracting: val2017/000000166426.jpg  \n",
      " extracting: val2017/000000015597.jpg  \n",
      " extracting: val2017/000000371552.jpg  \n",
      " extracting: val2017/000000136600.jpg  \n",
      " extracting: val2017/000000446574.jpg  \n",
      " extracting: val2017/000000575243.jpg  \n",
      " extracting: val2017/000000193494.jpg  \n",
      " extracting: val2017/000000066523.jpg  \n",
      " extracting: val2017/000000331569.jpg  \n",
      " extracting: val2017/000000475572.jpg  \n",
      " extracting: val2017/000000149222.jpg  \n",
      " extracting: val2017/000000557258.jpg  \n",
      " extracting: val2017/000000200839.jpg  \n",
      " extracting: val2017/000000369751.jpg  \n",
      " extracting: val2017/000000561366.jpg  \n",
      " extracting: val2017/000000426253.jpg  \n",
      " extracting: val2017/000000244750.jpg  \n",
      " extracting: val2017/000000514376.jpg  \n",
      " extracting: val2017/000000019221.jpg  \n",
      " extracting: val2017/000000460682.jpg  \n",
      " extracting: val2017/000000453841.jpg  \n",
      " extracting: val2017/000000497628.jpg  \n",
      " extracting: val2017/000000215778.jpg  \n",
      " extracting: val2017/000000523033.jpg  \n",
      " extracting: val2017/000000144003.jpg  \n",
      " extracting: val2017/000000507081.jpg  \n",
      " extracting: val2017/000000293200.jpg  \n",
      " extracting: val2017/000000032334.jpg  \n",
      " extracting: val2017/000000393115.jpg  \n",
      " extracting: val2017/000000010977.jpg  \n",
      " extracting: val2017/000000492284.jpg  \n",
      " extracting: val2017/000000409867.jpg  \n",
      " extracting: val2017/000000251572.jpg  \n",
      " extracting: val2017/000000441491.jpg  \n",
      " extracting: val2017/000000309678.jpg  \n",
      " extracting: val2017/000000232563.jpg  \n",
      " extracting: val2017/000000373705.jpg  \n",
      " extracting: val2017/000000327890.jpg  \n",
      " extracting: val2017/000000269314.jpg  \n",
      " extracting: val2017/000000562121.jpg  \n",
      " extracting: val2017/000000530470.jpg  \n",
      " extracting: val2017/000000108503.jpg  \n",
      " extracting: val2017/000000410428.jpg  \n",
      " extracting: val2017/000000369771.jpg  \n",
      " extracting: val2017/000000207844.jpg  \n",
      " extracting: val2017/000000509699.jpg  \n",
      " extracting: val2017/000000393014.jpg  \n",
      " extracting: val2017/000000560911.jpg  \n",
      " extracting: val2017/000000570471.jpg  \n",
      " extracting: val2017/000000384350.jpg  \n",
      " extracting: val2017/000000410880.jpg  \n",
      " extracting: val2017/000000325031.jpg  \n",
      " extracting: val2017/000000031620.jpg  \n",
      " extracting: val2017/000000464522.jpg  \n",
      " extracting: val2017/000000547502.jpg  \n",
      " extracting: val2017/000000320706.jpg  \n",
      " extracting: val2017/000000501243.jpg  \n",
      " extracting: val2017/000000417285.jpg  \n",
      " extracting: val2017/000000165039.jpg  \n",
      " extracting: val2017/000000078420.jpg  \n",
      " extracting: val2017/000000322944.jpg  \n",
      " extracting: val2017/000000468501.jpg  \n",
      " extracting: val2017/000000068765.jpg  \n",
      " extracting: val2017/000000570456.jpg  \n",
      " extracting: val2017/000000468577.jpg  \n",
      " extracting: val2017/000000072281.jpg  \n",
      " extracting: val2017/000000322429.jpg  \n",
      " extracting: val2017/000000075456.jpg  \n",
      " extracting: val2017/000000159684.jpg  \n",
      " extracting: val2017/000000361268.jpg  \n",
      " extracting: val2017/000000404923.jpg  \n",
      " extracting: val2017/000000205401.jpg  \n",
      " extracting: val2017/000000225757.jpg  \n",
      " extracting: val2017/000000199977.jpg  \n",
      " extracting: val2017/000000161128.jpg  \n",
      " extracting: val2017/000000086582.jpg  \n",
      " extracting: val2017/000000426203.jpg  \n",
      " extracting: val2017/000000266082.jpg  \n",
      " extracting: val2017/000000229553.jpg  \n",
      " extracting: val2017/000000224807.jpg  \n",
      " extracting: val2017/000000133418.jpg  \n",
      " extracting: val2017/000000261712.jpg  \n",
      " extracting: val2017/000000442161.jpg  \n",
      " extracting: val2017/000000477118.jpg  \n",
      " extracting: val2017/000000525247.jpg  \n",
      " extracting: val2017/000000227765.jpg  \n",
      " extracting: val2017/000000537672.jpg  \n",
      " extracting: val2017/000000065350.jpg  \n",
      " extracting: val2017/000000126216.jpg  \n",
      " extracting: val2017/000000125129.jpg  \n",
      " extracting: val2017/000000347930.jpg  \n",
      " extracting: val2017/000000560474.jpg  \n",
      " extracting: val2017/000000112298.jpg  \n",
      " extracting: val2017/000000012670.jpg  \n",
      " extracting: val2017/000000039484.jpg  \n",
      " extracting: val2017/000000389316.jpg  \n",
      " extracting: val2017/000000435003.jpg  \n",
      " extracting: val2017/000000130386.jpg  \n",
      " extracting: val2017/000000231831.jpg  \n",
      " extracting: val2017/000000057238.jpg  \n",
      " extracting: val2017/000000148707.jpg  \n",
      " extracting: val2017/000000074860.jpg  \n",
      " extracting: val2017/000000409630.jpg  \n",
      " extracting: val2017/000000463174.jpg  \n",
      " extracting: val2017/000000453040.jpg  \n",
      " extracting: val2017/000000149406.jpg  \n",
      " extracting: val2017/000000101420.jpg  \n",
      " extracting: val2017/000000224200.jpg  \n",
      " extracting: val2017/000000377575.jpg  \n",
      " extracting: val2017/000000278353.jpg  \n",
      " extracting: val2017/000000200252.jpg  \n",
      " extracting: val2017/000000239857.jpg  \n",
      " extracting: val2017/000000286708.jpg  \n",
      " extracting: val2017/000000440507.jpg  \n",
      " extracting: val2017/000000347163.jpg  \n",
      " extracting: val2017/000000493864.jpg  \n",
      " extracting: val2017/000000238013.jpg  \n",
      " extracting: val2017/000000290768.jpg  \n",
      " extracting: val2017/000000151820.jpg  \n",
      " extracting: val2017/000000087144.jpg  \n",
      " extracting: val2017/000000513283.jpg  \n",
      " extracting: val2017/000000018575.jpg  \n",
      " extracting: val2017/000000070739.jpg  \n",
      " extracting: val2017/000000292456.jpg  \n",
      " extracting: val2017/000000042628.jpg  \n",
      " extracting: val2017/000000047121.jpg  \n",
      " extracting: val2017/000000323751.jpg  \n",
      " extracting: val2017/000000479099.jpg  \n",
      " extracting: val2017/000000397327.jpg  \n",
      " extracting: val2017/000000356612.jpg  \n",
      " extracting: val2017/000000366711.jpg  \n",
      " extracting: val2017/000000163314.jpg  \n",
      " extracting: val2017/000000005503.jpg  \n",
      " extracting: val2017/000000066038.jpg  \n",
      " extracting: val2017/000000392481.jpg  \n",
      " extracting: val2017/000000125778.jpg  \n",
      " extracting: val2017/000000562843.jpg  \n",
      " extracting: val2017/000000393569.jpg  \n",
      " extracting: val2017/000000428111.jpg  \n",
      " extracting: val2017/000000099054.jpg  \n",
      " extracting: val2017/000000484404.jpg  \n",
      " extracting: val2017/000000205776.jpg  \n",
      " extracting: val2017/000000210708.jpg  \n",
      " extracting: val2017/000000049091.jpg  \n",
      " extracting: val2017/000000013004.jpg  \n",
      " extracting: val2017/000000134722.jpg  \n",
      " extracting: val2017/000000174018.jpg  \n",
      " extracting: val2017/000000142238.jpg  \n",
      " extracting: val2017/000000140658.jpg  \n",
      " extracting: val2017/000000521282.jpg  \n",
      " extracting: val2017/000000344909.jpg  \n",
      " extracting: val2017/000000181303.jpg  \n",
      " extracting: val2017/000000037988.jpg  \n",
      " extracting: val2017/000000537991.jpg  \n",
      " extracting: val2017/000000174371.jpg  \n",
      " extracting: val2017/000000001532.jpg  \n",
      " extracting: val2017/000000344795.jpg  \n",
      " extracting: val2017/000000131138.jpg  \n",
      " extracting: val2017/000000429690.jpg  \n",
      " extracting: val2017/000000263299.jpg  \n",
      " extracting: val2017/000000135561.jpg  \n",
      " extracting: val2017/000000016958.jpg  \n",
      " extracting: val2017/000000367095.jpg  \n",
      " extracting: val2017/000000082715.jpg  \n",
      " extracting: val2017/000000516038.jpg  \n",
      " extracting: val2017/000000243148.jpg  \n",
      " extracting: val2017/000000390826.jpg  \n",
      " extracting: val2017/000000262631.jpg  \n",
      " extracting: val2017/000000498807.jpg  \n",
      " extracting: val2017/000000483050.jpg  \n",
      " extracting: val2017/000000451308.jpg  \n",
      " extracting: val2017/000000058539.jpg  \n",
      " extracting: val2017/000000047112.jpg  \n",
      " extracting: val2017/000000406129.jpg  \n",
      " extracting: val2017/000000545407.jpg  \n",
      " extracting: val2017/000000565853.jpg  \n",
      " extracting: val2017/000000326082.jpg  \n",
      " extracting: val2017/000000272416.jpg  \n",
      " extracting: val2017/000000071756.jpg  \n",
      " extracting: val2017/000000577864.jpg  \n",
      " extracting: val2017/000000481386.jpg  \n",
      " extracting: val2017/000000007574.jpg  \n",
      " extracting: val2017/000000039551.jpg  \n",
      " extracting: val2017/000000264441.jpg  \n",
      " extracting: val2017/000000146831.jpg  \n",
      " extracting: val2017/000000366884.jpg  \n",
      " extracting: val2017/000000416758.jpg  \n",
      " extracting: val2017/000000153229.jpg  \n",
      " extracting: val2017/000000061747.jpg  \n",
      " extracting: val2017/000000021503.jpg  \n",
      " extracting: val2017/000000179487.jpg  \n",
      " extracting: val2017/000000526728.jpg  \n",
      " extracting: val2017/000000252219.jpg  \n",
      " extracting: val2017/000000190841.jpg  \n",
      " extracting: val2017/000000073153.jpg  \n",
      " extracting: val2017/000000129812.jpg  \n",
      " extracting: val2017/000000488166.jpg  \n",
      " extracting: val2017/000000258883.jpg  \n",
      " extracting: val2017/000000206838.jpg  \n",
      " extracting: val2017/000000013177.jpg  \n",
      " extracting: val2017/000000094185.jpg  \n",
      " extracting: val2017/000000460967.jpg  \n",
      " extracting: val2017/000000342128.jpg  \n",
      " extracting: val2017/000000284296.jpg  \n",
      " extracting: val2017/000000538458.jpg  \n",
      " extracting: val2017/000000032887.jpg  \n",
      " extracting: val2017/000000529122.jpg  \n",
      " extracting: val2017/000000481573.jpg  \n",
      " extracting: val2017/000000442009.jpg  \n",
      " extracting: val2017/000000574702.jpg  \n",
      " extracting: val2017/000000177383.jpg  \n",
      " extracting: val2017/000000416745.jpg  \n",
      " extracting: val2017/000000008021.jpg  \n",
      " extracting: val2017/000000478862.jpg  \n",
      " extracting: val2017/000000190140.jpg  \n",
      " extracting: val2017/000000468632.jpg  \n",
      " extracting: val2017/000000109118.jpg  \n",
      " extracting: val2017/000000011149.jpg  \n",
      " extracting: val2017/000000083531.jpg  \n",
      " extracting: val2017/000000372577.jpg  \n",
      " extracting: val2017/000000102331.jpg  \n",
      " extracting: val2017/000000227898.jpg  \n",
      " extracting: val2017/000000419601.jpg  \n",
      " extracting: val2017/000000157390.jpg  \n",
      " extracting: val2017/000000025424.jpg  \n",
      " extracting: val2017/000000024919.jpg  \n",
      " extracting: val2017/000000537241.jpg  \n",
      " extracting: val2017/000000255749.jpg  \n",
      " extracting: val2017/000000377723.jpg  \n",
      " extracting: val2017/000000486112.jpg  \n",
      " extracting: val2017/000000325991.jpg  \n",
      " extracting: val2017/000000369323.jpg  \n",
      " extracting: val2017/000000563648.jpg  \n",
      " extracting: val2017/000000163746.jpg  \n",
      " extracting: val2017/000000458755.jpg  \n",
      " extracting: val2017/000000399655.jpg  \n",
      " extracting: val2017/000000265518.jpg  \n",
      " extracting: val2017/000000302165.jpg  \n",
      " extracting: val2017/000000021465.jpg  \n",
      " extracting: val2017/000000063154.jpg  \n",
      " extracting: val2017/000000279769.jpg  \n",
      " extracting: val2017/000000248111.jpg  \n",
      " extracting: val2017/000000485844.jpg  \n",
      " extracting: val2017/000000289702.jpg  \n",
      " extracting: val2017/000000123131.jpg  \n",
      " extracting: val2017/000000581482.jpg  \n",
      " extracting: val2017/000000579902.jpg  \n",
      " extracting: val2017/000000230993.jpg  \n",
      " extracting: val2017/000000165831.jpg  \n",
      " extracting: val2017/000000479248.jpg  \n",
      " extracting: val2017/000000051961.jpg  \n",
      " extracting: val2017/000000136033.jpg  \n",
      " extracting: val2017/000000458768.jpg  \n",
      " extracting: val2017/000000111951.jpg  \n",
      " extracting: val2017/000000450686.jpg  \n",
      " extracting: val2017/000000460333.jpg  \n",
      " extracting: val2017/000000407083.jpg  \n",
      " extracting: val2017/000000277689.jpg  \n",
      " extracting: val2017/000000403817.jpg  \n",
      " extracting: val2017/000000480842.jpg  \n",
      " extracting: val2017/000000119452.jpg  \n",
      " extracting: val2017/000000173091.jpg  \n",
      " extracting: val2017/000000125806.jpg  \n",
      " extracting: val2017/000000321790.jpg  \n",
      " extracting: val2017/000000450758.jpg  \n",
      " extracting: val2017/000000224724.jpg  \n",
      " extracting: val2017/000000287874.jpg  \n",
      " extracting: val2017/000000361142.jpg  \n",
      " extracting: val2017/000000439180.jpg  \n",
      " extracting: val2017/000000177539.jpg  \n",
      " extracting: val2017/000000228981.jpg  \n",
      " extracting: val2017/000000509719.jpg  \n",
      " extracting: val2017/000000071938.jpg  \n",
      " extracting: val2017/000000016502.jpg  \n",
      " extracting: val2017/000000098853.jpg  \n",
      " extracting: val2017/000000094944.jpg  \n",
      " extracting: val2017/000000168883.jpg  \n",
      " extracting: val2017/000000267169.jpg  \n",
      " extracting: val2017/000000422670.jpg  \n",
      " extracting: val2017/000000269866.jpg  \n",
      " extracting: val2017/000000135604.jpg  \n",
      " extracting: val2017/000000009772.jpg  \n",
      " extracting: val2017/000000050380.jpg  \n",
      " extracting: val2017/000000404484.jpg  \n",
      " extracting: val2017/000000009483.jpg  \n",
      " extracting: val2017/000000413552.jpg  \n",
      " extracting: val2017/000000131938.jpg  \n",
      " extracting: val2017/000000348216.jpg  \n",
      " extracting: val2017/000000460160.jpg  \n",
      " extracting: val2017/000000109827.jpg  \n",
      " extracting: val2017/000000009590.jpg  \n",
      " extracting: val2017/000000271457.jpg  \n",
      " extracting: val2017/000000260470.jpg  \n",
      " extracting: val2017/000000570448.jpg  \n",
      " extracting: val2017/000000167240.jpg  \n",
      " extracting: val2017/000000009914.jpg  \n",
      " extracting: val2017/000000495146.jpg  \n",
      " extracting: val2017/000000112378.jpg  \n",
      " extracting: val2017/000000104424.jpg  \n",
      " extracting: val2017/000000420916.jpg  \n",
      " extracting: val2017/000000110042.jpg  \n",
      " extracting: val2017/000000051314.jpg  \n",
      " extracting: val2017/000000457078.jpg  \n",
      " extracting: val2017/000000405249.jpg  \n",
      " extracting: val2017/000000476491.jpg  \n",
      " extracting: val2017/000000367228.jpg  \n",
      " extracting: val2017/000000187249.jpg  \n",
      " extracting: val2017/000000472623.jpg  \n",
      " extracting: val2017/000000555972.jpg  \n",
      " extracting: val2017/000000304817.jpg  \n",
      " extracting: val2017/000000397133.jpg  \n",
      " extracting: val2017/000000578236.jpg  \n",
      " extracting: val2017/000000214192.jpg  \n",
      " extracting: val2017/000000478393.jpg  \n",
      " extracting: val2017/000000573094.jpg  \n",
      " extracting: val2017/000000560256.jpg  \n",
      " extracting: val2017/000000047801.jpg  \n",
      " extracting: val2017/000000325306.jpg  \n",
      " extracting: val2017/000000434548.jpg  \n",
      " extracting: val2017/000000215723.jpg  \n",
      " extracting: val2017/000000130566.jpg  \n",
      " extracting: val2017/000000308165.jpg  \n",
      " extracting: val2017/000000463522.jpg  \n",
      " extracting: val2017/000000099039.jpg  \n",
      " extracting: val2017/000000037689.jpg  \n",
      " extracting: val2017/000000066926.jpg  \n",
      " extracting: val2017/000000036678.jpg  \n",
      " extracting: val2017/000000384651.jpg  \n",
      " extracting: val2017/000000458109.jpg  \n",
      " extracting: val2017/000000191288.jpg  \n",
      " extracting: val2017/000000488251.jpg  \n",
      " extracting: val2017/000000453981.jpg  \n",
      " extracting: val2017/000000225405.jpg  \n",
      " extracting: val2017/000000091495.jpg  \n",
      " extracting: val2017/000000569273.jpg  \n",
      " extracting: val2017/000000295809.jpg  \n",
      " extracting: val2017/000000193181.jpg  \n",
      " extracting: val2017/000000439593.jpg  \n",
      " extracting: val2017/000000366199.jpg  \n",
      " extracting: val2017/000000303305.jpg  \n",
      " extracting: val2017/000000562229.jpg  \n",
      " extracting: val2017/000000283070.jpg  \n",
      " extracting: val2017/000000245448.jpg  \n",
      " extracting: val2017/000000123585.jpg  \n",
      " extracting: val2017/000000251119.jpg  \n",
      " extracting: val2017/000000513567.jpg  \n",
      " extracting: val2017/000000572678.jpg  \n",
      " extracting: val2017/000000163611.jpg  \n",
      " extracting: val2017/000000083113.jpg  \n",
      " extracting: val2017/000000321214.jpg  \n",
      " extracting: val2017/000000292236.jpg  \n",
      " extracting: val2017/000000172877.jpg  \n",
      " extracting: val2017/000000412240.jpg  \n",
      " extracting: val2017/000000493772.jpg  \n",
      " extracting: val2017/000000368212.jpg  \n",
      " extracting: val2017/000000424551.jpg  \n",
      " extracting: val2017/000000305317.jpg  \n",
      " extracting: val2017/000000466256.jpg  \n",
      " extracting: val2017/000000383676.jpg  \n",
      " extracting: val2017/000000580197.jpg  \n",
      " extracting: val2017/000000395801.jpg  \n",
      " extracting: val2017/000000530836.jpg  \n",
      " extracting: val2017/000000530975.jpg  \n",
      " extracting: val2017/000000569917.jpg  \n",
      " extracting: val2017/000000127135.jpg  \n",
      " extracting: val2017/000000304984.jpg  \n",
      " extracting: val2017/000000121497.jpg  \n",
      " extracting: val2017/000000159977.jpg  \n",
      " extracting: val2017/000000102820.jpg  \n",
      " extracting: val2017/000000275749.jpg  \n",
      " extracting: val2017/000000029984.jpg  \n",
      " extracting: val2017/000000486573.jpg  \n",
      " extracting: val2017/000000013348.jpg  \n",
      " extracting: val2017/000000539143.jpg  \n",
      " extracting: val2017/000000031735.jpg  \n",
      " extracting: val2017/000000210230.jpg  \n",
      " extracting: val2017/000000025603.jpg  \n",
      " extracting: val2017/000000114884.jpg  \n",
      " extracting: val2017/000000036861.jpg  \n",
      " extracting: val2017/000000232088.jpg  \n",
      " extracting: val2017/000000473118.jpg  \n",
      " extracting: val2017/000000008532.jpg  \n",
      " extracting: val2017/000000382111.jpg  \n",
      " extracting: val2017/000000217060.jpg  \n",
      " extracting: val2017/000000237864.jpg  \n",
      " extracting: val2017/000000198641.jpg  \n",
      " extracting: val2017/000000327701.jpg  \n",
      " extracting: val2017/000000072795.jpg  \n",
      " extracting: val2017/000000118921.jpg  \n",
      " extracting: val2017/000000196009.jpg  \n",
      " extracting: val2017/000000286458.jpg  \n",
      " extracting: val2017/000000533958.jpg  \n",
      " extracting: val2017/000000002261.jpg  \n",
      " extracting: val2017/000000522751.jpg  \n",
      " extracting: val2017/000000509260.jpg  \n",
      " extracting: val2017/000000440508.jpg  \n",
      " extracting: val2017/000000536073.jpg  \n",
      " extracting: val2017/000000207728.jpg  \n",
      " extracting: val2017/000000378454.jpg  \n",
      " extracting: val2017/000000068409.jpg  \n",
      " extracting: val2017/000000140076.jpg  \n",
      " extracting: val2017/000000454067.jpg  \n",
      " extracting: val2017/000000483999.jpg  \n",
      " extracting: val2017/000000570736.jpg  \n",
      " extracting: val2017/000000475904.jpg  \n",
      " extracting: val2017/000000292060.jpg  \n",
      " extracting: val2017/000000549738.jpg  \n",
      " extracting: val2017/000000216636.jpg  \n",
      " extracting: val2017/000000297427.jpg  \n",
      " extracting: val2017/000000541773.jpg  \n",
      " extracting: val2017/000000269113.jpg  \n",
      " extracting: val2017/000000207306.jpg  \n",
      " extracting: val2017/000000475191.jpg  \n",
      " extracting: val2017/000000519611.jpg  \n",
      " extracting: val2017/000000138954.jpg  \n",
      " extracting: val2017/000000214539.jpg  \n",
      " extracting: val2017/000000376322.jpg  \n",
      " extracting: val2017/000000176606.jpg  \n",
      " extracting: val2017/000000165500.jpg  \n",
      " extracting: val2017/000000289393.jpg  \n",
      " extracting: val2017/000000164883.jpg  \n",
      " extracting: val2017/000000565563.jpg  \n",
      " extracting: val2017/000000389933.jpg  \n",
      " extracting: val2017/000000343076.jpg  \n",
      " extracting: val2017/000000287649.jpg  \n",
      " extracting: val2017/000000180560.jpg  \n",
      " extracting: val2017/000000047819.jpg  \n",
      " extracting: val2017/000000289992.jpg  \n",
      " extracting: val2017/000000189752.jpg  \n",
      " extracting: val2017/000000550797.jpg  \n",
      " extracting: val2017/000000152686.jpg  \n",
      " extracting: val2017/000000184384.jpg  \n",
      " extracting: val2017/000000039785.jpg  \n",
      " extracting: val2017/000000148719.jpg  \n",
      " extracting: val2017/000000185472.jpg  \n",
      " extracting: val2017/000000568584.jpg  \n",
      " extracting: val2017/000000545007.jpg  \n",
      " extracting: val2017/000000002157.jpg  \n",
      " extracting: val2017/000000008629.jpg  \n",
      " extracting: val2017/000000089670.jpg  \n",
      " extracting: val2017/000000577539.jpg  \n",
      " extracting: val2017/000000060052.jpg  \n",
      " extracting: val2017/000000334006.jpg  \n",
      " extracting: val2017/000000167122.jpg  \n",
      " extracting: val2017/000000416343.jpg  \n",
      " extracting: val2017/000000055299.jpg  \n",
      " extracting: val2017/000000202228.jpg  \n",
      " extracting: val2017/000000478286.jpg  \n",
      " extracting: val2017/000000197388.jpg  \n",
      " extracting: val2017/000000013923.jpg  \n",
      " extracting: val2017/000000026941.jpg  \n",
      " extracting: val2017/000000239041.jpg  \n",
      " extracting: val2017/000000302452.jpg  \n",
      " extracting: val2017/000000018737.jpg  \n",
      " extracting: val2017/000000127494.jpg  \n",
      " extracting: val2017/000000179174.jpg  \n",
      " extracting: val2017/000000419974.jpg  \n",
      " extracting: val2017/000000300276.jpg  \n",
      " extracting: val2017/000000393838.jpg  \n",
      " extracting: val2017/000000455267.jpg  \n",
      " extracting: val2017/000000007278.jpg  \n",
      " extracting: val2017/000000209747.jpg  \n",
      " extracting: val2017/000000311180.jpg  \n",
      " extracting: val2017/000000224051.jpg  \n",
      " extracting: val2017/000000092839.jpg  \n",
      " extracting: val2017/000000460927.jpg  \n",
      " extracting: val2017/000000268375.jpg  \n",
      " extracting: val2017/000000135902.jpg  \n",
      " extracting: val2017/000000162415.jpg  \n",
      " extracting: val2017/000000140840.jpg  \n",
      " extracting: val2017/000000395388.jpg  \n",
      " extracting: val2017/000000208423.jpg  \n",
      " extracting: val2017/000000180296.jpg  \n",
      " extracting: val2017/000000535523.jpg  \n",
      " extracting: val2017/000000348488.jpg  \n",
      " extracting: val2017/000000196759.jpg  \n",
      " extracting: val2017/000000023751.jpg  \n",
      " extracting: val2017/000000041888.jpg  \n",
      " extracting: val2017/000000039477.jpg  \n",
      " extracting: val2017/000000014831.jpg  \n",
      " extracting: val2017/000000007888.jpg  \n",
      " extracting: val2017/000000531771.jpg  \n",
      " extracting: val2017/000000016249.jpg  \n",
      " extracting: val2017/000000458054.jpg  \n",
      " extracting: val2017/000000183675.jpg  \n",
      " extracting: val2017/000000424135.jpg  \n",
      " extracting: val2017/000000139260.jpg  \n",
      " extracting: val2017/000000079565.jpg  \n",
      " extracting: val2017/000000482735.jpg  \n",
      " extracting: val2017/000000133969.jpg  \n",
      " extracting: val2017/000000060886.jpg  \n",
      " extracting: val2017/000000578545.jpg  \n",
      " extracting: val2017/000000554291.jpg  \n",
      " extracting: val2017/000000084270.jpg  \n",
      " extracting: val2017/000000233139.jpg  \n",
      " extracting: val2017/000000222559.jpg  \n",
      " extracting: val2017/000000415741.jpg  \n",
      " extracting: val2017/000000241668.jpg  \n",
      " extracting: val2017/000000220858.jpg  \n",
      " extracting: val2017/000000180878.jpg  \n",
      " extracting: val2017/000000316015.jpg  \n",
      " extracting: val2017/000000286507.jpg  \n",
      " extracting: val2017/000000226417.jpg  \n",
      " extracting: val2017/000000133233.jpg  \n",
      " extracting: val2017/000000253742.jpg  \n",
      " extracting: val2017/000000317433.jpg  \n",
      " extracting: val2017/000000110999.jpg  \n",
      " extracting: val2017/000000438876.jpg  \n",
      " extracting: val2017/000000372260.jpg  \n",
      " extracting: val2017/000000024021.jpg  \n",
      " extracting: val2017/000000491757.jpg  \n",
      " extracting: val2017/000000377882.jpg  \n",
      " extracting: val2017/000000094751.jpg  \n",
      " extracting: val2017/000000104572.jpg  \n",
      " extracting: val2017/000000141328.jpg  \n",
      " extracting: val2017/000000247838.jpg  \n",
      " extracting: val2017/000000377393.jpg  \n",
      " extracting: val2017/000000318114.jpg  \n",
      " extracting: val2017/000000229216.jpg  \n",
      " extracting: val2017/000000448076.jpg  \n",
      " extracting: val2017/000000248752.jpg  \n",
      " extracting: val2017/000000502168.jpg  \n",
      " extracting: val2017/000000463802.jpg  \n",
      " extracting: val2017/000000129054.jpg  \n",
      " extracting: val2017/000000288430.jpg  \n",
      " extracting: val2017/000000049060.jpg  \n",
      " extracting: val2017/000000195754.jpg  \n",
      " extracting: val2017/000000115898.jpg  \n",
      " extracting: val2017/000000349480.jpg  \n",
      " extracting: val2017/000000186929.jpg  \n",
      " extracting: val2017/000000069138.jpg  \n",
      " extracting: val2017/000000551350.jpg  \n",
      " extracting: val2017/000000256868.jpg  \n",
      " extracting: val2017/000000191013.jpg  \n",
      " extracting: val2017/000000276434.jpg  \n",
      " extracting: val2017/000000289059.jpg  \n",
      " extracting: val2017/000000311518.jpg  \n",
      " extracting: val2017/000000507975.jpg  \n",
      " extracting: val2017/000000383842.jpg  \n",
      " extracting: val2017/000000410496.jpg  \n",
      " extracting: val2017/000000497344.jpg  \n",
      " extracting: val2017/000000561223.jpg  \n",
      " extracting: val2017/000000235399.jpg  \n",
      " extracting: val2017/000000321557.jpg  \n",
      " extracting: val2017/000000355817.jpg  \n",
      " extracting: val2017/000000356424.jpg  \n",
      " extracting: val2017/000000068833.jpg  \n",
      " extracting: val2017/000000297562.jpg  \n",
      " extracting: val2017/000000394611.jpg  \n",
      " extracting: val2017/000000549167.jpg  \n",
      " extracting: val2017/000000512985.jpg  \n",
      " extracting: val2017/000000347664.jpg  \n",
      " extracting: val2017/000000333745.jpg  \n",
      " extracting: val2017/000000147205.jpg  \n",
      " extracting: val2017/000000099114.jpg  \n",
      " extracting: val2017/000000368294.jpg  \n",
      " extracting: val2017/000000001490.jpg  \n",
      " extracting: val2017/000000556000.jpg  \n",
      " extracting: val2017/000000345361.jpg  \n",
      " extracting: val2017/000000471869.jpg  \n",
      " extracting: val2017/000000271116.jpg  \n",
      " extracting: val2017/000000050145.jpg  \n",
      " extracting: val2017/000000565597.jpg  \n",
      " extracting: val2017/000000473237.jpg  \n",
      " extracting: val2017/000000311789.jpg  \n",
      " extracting: val2017/000000241326.jpg  \n",
      " extracting: val2017/000000549930.jpg  \n",
      " extracting: val2017/000000507223.jpg  \n",
      " extracting: val2017/000000204186.jpg  \n",
      " extracting: val2017/000000562443.jpg  \n",
      " extracting: val2017/000000546964.jpg  \n",
      " extracting: val2017/000000155145.jpg  \n",
      " extracting: val2017/000000206135.jpg  \n",
      " extracting: val2017/000000508101.jpg  \n",
      " extracting: val2017/000000212072.jpg  \n",
      " extracting: val2017/000000249786.jpg  \n",
      " extracting: val2017/000000163258.jpg  \n",
      " extracting: val2017/000000052017.jpg  \n",
      " extracting: val2017/000000095707.jpg  \n",
      " extracting: val2017/000000295713.jpg  \n",
      " extracting: val2017/000000007816.jpg  \n",
      " extracting: val2017/000000034257.jpg  \n",
      " extracting: val2017/000000267903.jpg  \n",
      " extracting: val2017/000000381639.jpg  \n",
      " extracting: val2017/000000479953.jpg  \n",
      " extracting: val2017/000000025139.jpg  \n",
      " extracting: val2017/000000350023.jpg  \n",
      " extracting: val2017/000000026690.jpg  \n",
      " extracting: val2017/000000393469.jpg  \n",
      " extracting: val2017/000000578871.jpg  \n",
      " extracting: val2017/000000044877.jpg  \n",
      " extracting: val2017/000000157756.jpg  \n",
      " extracting: val2017/000000274411.jpg  \n",
      " extracting: val2017/000000261116.jpg  \n",
      " extracting: val2017/000000097988.jpg  \n",
      " extracting: val2017/000000154213.jpg  \n",
      " extracting: val2017/000000205333.jpg  \n",
      " extracting: val2017/000000502737.jpg  \n",
      " extracting: val2017/000000529568.jpg  \n",
      " extracting: val2017/000000496597.jpg  \n",
      " extracting: val2017/000000263474.jpg  \n",
      " extracting: val2017/000000399462.jpg  \n",
      " extracting: val2017/000000445248.jpg  \n",
      " extracting: val2017/000000292024.jpg  \n",
      " extracting: val2017/000000405972.jpg  \n",
      " extracting: val2017/000000233238.jpg  \n",
      " extracting: val2017/000000383443.jpg  \n",
      " extracting: val2017/000000474293.jpg  \n",
      " extracting: val2017/000000127660.jpg  \n",
      " extracting: val2017/000000357567.jpg  \n",
      " extracting: val2017/000000303893.jpg  \n",
      " extracting: val2017/000000166918.jpg  \n",
      " extracting: val2017/000000193429.jpg  \n",
      " extracting: val2017/000000445722.jpg  \n",
      " extracting: val2017/000000479126.jpg  \n",
      " extracting: val2017/000000550426.jpg  \n",
      " extracting: val2017/000000463542.jpg  \n",
      " extracting: val2017/000000339823.jpg  \n",
      " extracting: val2017/000000447200.jpg  \n",
      " extracting: val2017/000000472678.jpg  \n",
      " extracting: val2017/000000263463.jpg  \n",
      " extracting: val2017/000000201418.jpg  \n",
      " extracting: val2017/000000480275.jpg  \n",
      " extracting: val2017/000000031817.jpg  \n",
      " extracting: val2017/000000163257.jpg  \n",
      " extracting: val2017/000000035279.jpg  \n",
      " extracting: val2017/000000019402.jpg  \n",
      " extracting: val2017/000000411953.jpg  \n",
      " extracting: val2017/000000123321.jpg  \n",
      " extracting: val2017/000000571264.jpg  \n",
      " extracting: val2017/000000263594.jpg  \n",
      " extracting: val2017/000000043581.jpg  \n",
      " extracting: val2017/000000211042.jpg  \n",
      " extracting: val2017/000000231088.jpg  \n",
      " extracting: val2017/000000167572.jpg  \n",
      " extracting: val2017/000000244833.jpg  \n",
      " extracting: val2017/000000235857.jpg  \n",
      " extracting: val2017/000000542073.jpg  \n",
      " extracting: val2017/000000224337.jpg  \n",
      " extracting: val2017/000000453341.jpg  \n",
      " extracting: val2017/000000379842.jpg  \n",
      " extracting: val2017/000000161609.jpg  \n",
      " extracting: val2017/000000440184.jpg  \n",
      " extracting: val2017/000000281693.jpg  \n",
      " extracting: val2017/000000253002.jpg  \n",
      " extracting: val2017/000000476119.jpg  \n",
      " extracting: val2017/000000574425.jpg  \n",
      " extracting: val2017/000000482800.jpg  \n",
      " extracting: val2017/000000458663.jpg  \n",
      " extracting: val2017/000000159112.jpg  \n",
      " extracting: val2017/000000199771.jpg  \n",
      " extracting: val2017/000000142092.jpg  \n",
      " extracting: val2017/000000550349.jpg  \n",
      " extracting: val2017/000000463199.jpg  \n",
      " extracting: val2017/000000332318.jpg  \n",
      " extracting: val2017/000000231169.jpg  \n",
      " extracting: val2017/000000517687.jpg  \n",
      " extracting: val2017/000000118209.jpg  \n",
      " extracting: val2017/000000455624.jpg  \n",
      " extracting: val2017/000000534394.jpg  \n",
      " extracting: val2017/000000110884.jpg  \n",
      " extracting: val2017/000000065798.jpg  \n",
      " extracting: val2017/000000438774.jpg  \n",
      " extracting: val2017/000000090062.jpg  \n",
      " extracting: val2017/000000285788.jpg  \n",
      " extracting: val2017/000000004765.jpg  \n",
      " extracting: val2017/000000482970.jpg  \n",
      " extracting: val2017/000000284279.jpg  \n",
      " extracting: val2017/000000187236.jpg  \n",
      " extracting: val2017/000000564336.jpg  \n",
      " extracting: val2017/000000290833.jpg  \n",
      " extracting: val2017/000000082812.jpg  \n",
      " extracting: val2017/000000433103.jpg  \n",
      " extracting: val2017/000000421834.jpg  \n",
      " extracting: val2017/000000211120.jpg  \n",
      " extracting: val2017/000000415727.jpg  \n",
      " extracting: val2017/000000340894.jpg  \n",
      " extracting: val2017/000000542423.jpg  \n",
      " extracting: val2017/000000434204.jpg  \n",
      " extracting: val2017/000000022755.jpg  \n",
      " extracting: val2017/000000367386.jpg  \n",
      " extracting: val2017/000000146363.jpg  \n",
      " extracting: val2017/000000346703.jpg  \n",
      " extracting: val2017/000000125850.jpg  \n",
      " extracting: val2017/000000229858.jpg  \n",
      " extracting: val2017/000000017178.jpg  \n",
      " extracting: val2017/000000080932.jpg  \n",
      " extracting: val2017/000000113589.jpg  \n",
      " extracting: val2017/000000491090.jpg  \n",
      " extracting: val2017/000000257896.jpg  \n",
      " extracting: val2017/000000389315.jpg  \n",
      " extracting: val2017/000000575970.jpg  \n",
      " extracting: val2017/000000331280.jpg  \n",
      " extracting: val2017/000000102644.jpg  \n",
      " extracting: val2017/000000511760.jpg  \n",
      " extracting: val2017/000000256775.jpg  \n",
      " extracting: val2017/000000237118.jpg  \n",
      " extracting: val2017/000000182417.jpg  \n",
      " extracting: val2017/000000527427.jpg  \n",
      " extracting: val2017/000000273551.jpg  \n",
      " extracting: val2017/000000078915.jpg  \n",
      " extracting: val2017/000000283412.jpg  \n",
      " extracting: val2017/000000021604.jpg  \n",
      " extracting: val2017/000000091779.jpg  \n",
      " extracting: val2017/000000212453.jpg  \n",
      " extracting: val2017/000000559099.jpg  \n",
      " extracting: val2017/000000137727.jpg  \n",
      " extracting: val2017/000000233825.jpg  \n",
      " extracting: val2017/000000184611.jpg  \n",
      " extracting: val2017/000000511647.jpg  \n",
      " extracting: val2017/000000342186.jpg  \n",
      " extracting: val2017/000000558558.jpg  \n",
      " extracting: val2017/000000479596.jpg  \n",
      " extracting: val2017/000000290771.jpg  \n",
      " extracting: val2017/000000061960.jpg  \n",
      " extracting: val2017/000000436617.jpg  \n",
      " extracting: val2017/000000109900.jpg  \n",
      " extracting: val2017/000000138856.jpg  \n",
      " extracting: val2017/000000087038.jpg  \n",
      " extracting: val2017/000000273760.jpg  \n",
      " extracting: val2017/000000276921.jpg  \n",
      " extracting: val2017/000000360097.jpg  \n",
      " extracting: val2017/000000299609.jpg  \n",
      " extracting: val2017/000000309391.jpg  \n",
      " extracting: val2017/000000138819.jpg  \n",
      " extracting: val2017/000000407650.jpg  \n",
      " extracting: val2017/000000465822.jpg  \n",
      " extracting: val2017/000000264535.jpg  \n",
      " extracting: val2017/000000201025.jpg  \n",
      " extracting: val2017/000000531134.jpg  \n",
      " extracting: val2017/000000396274.jpg  \n",
      " extracting: val2017/000000023359.jpg  \n",
      " extracting: val2017/000000266400.jpg  \n",
      " extracting: val2017/000000400161.jpg  \n",
      " extracting: val2017/000000504635.jpg  \n",
      " extracting: val2017/000000129756.jpg  \n",
      " extracting: val2017/000000129113.jpg  \n",
      " extracting: val2017/000000170191.jpg  \n",
      " extracting: val2017/000000058350.jpg  \n",
      " extracting: val2017/000000109798.jpg  \n",
      " extracting: val2017/000000464358.jpg  \n",
      " extracting: val2017/000000239843.jpg  \n",
      " extracting: val2017/000000385719.jpg  \n",
      " extracting: val2017/000000341469.jpg  \n",
      " extracting: val2017/000000094871.jpg  \n",
      " extracting: val2017/000000404678.jpg  \n",
      " extracting: val2017/000000001818.jpg  \n",
      " extracting: val2017/000000161799.jpg  \n",
      " extracting: val2017/000000287667.jpg  \n",
      " extracting: val2017/000000556498.jpg  \n",
      " extracting: val2017/000000334309.jpg  \n",
      " extracting: val2017/000000097679.jpg  \n",
      " extracting: val2017/000000384616.jpg  \n",
      " extracting: val2017/000000222991.jpg  \n",
      " extracting: val2017/000000507037.jpg  \n",
      " extracting: val2017/000000166664.jpg  \n",
      " extracting: val2017/000000536947.jpg  \n",
      " extracting: val2017/000000090003.jpg  \n",
      " extracting: val2017/000000545594.jpg  \n",
      " extracting: val2017/000000397351.jpg  \n",
      " extracting: val2017/000000399205.jpg  \n",
      " extracting: val2017/000000376264.jpg  \n",
      " extracting: val2017/000000463849.jpg  \n",
      " extracting: val2017/000000492282.jpg  \n",
      " extracting: val2017/000000101022.jpg  \n",
      " extracting: val2017/000000202339.jpg  \n",
      " extracting: val2017/000000292488.jpg  \n",
      " extracting: val2017/000000057150.jpg  \n",
      " extracting: val2017/000000031050.jpg  \n",
      " extracting: val2017/000000501005.jpg  \n",
      " extracting: val2017/000000576566.jpg  \n",
      " extracting: val2017/000000064574.jpg  \n",
      " extracting: val2017/000000423971.jpg  \n",
      " extracting: val2017/000000291634.jpg  \n",
      " extracting: val2017/000000022589.jpg  \n",
      " extracting: val2017/000000511384.jpg  \n",
      " extracting: val2017/000000013774.jpg  \n",
      " extracting: val2017/000000491725.jpg  \n",
      " extracting: val2017/000000361621.jpg  \n",
      " extracting: val2017/000000567640.jpg  \n",
      " extracting: val2017/000000507667.jpg  \n",
      " extracting: val2017/000000567886.jpg  \n",
      " extracting: val2017/000000451714.jpg  \n",
      " extracting: val2017/000000314264.jpg  \n",
      " extracting: val2017/000000246522.jpg  \n",
      " extracting: val2017/000000497867.jpg  \n",
      " extracting: val2017/000000500270.jpg  \n",
      " extracting: val2017/000000351559.jpg  \n",
      " extracting: val2017/000000116479.jpg  \n",
      " extracting: val2017/000000129135.jpg  \n",
      " extracting: val2017/000000087470.jpg  \n",
      " extracting: val2017/000000019109.jpg  \n",
      " extracting: val2017/000000035326.jpg  \n",
      " extracting: val2017/000000054605.jpg  \n",
      " extracting: val2017/000000045596.jpg  \n",
      " extracting: val2017/000000067315.jpg  \n",
      " extracting: val2017/000000506656.jpg  \n",
      " extracting: val2017/000000275727.jpg  \n",
      " extracting: val2017/000000148739.jpg  \n",
      " extracting: val2017/000000441543.jpg  \n",
      " extracting: val2017/000000353096.jpg  \n",
      " extracting: val2017/000000226111.jpg  \n",
      " extracting: val2017/000000419379.jpg  \n",
      " extracting: val2017/000000544444.jpg  \n",
      " extracting: val2017/000000203389.jpg  \n",
      " extracting: val2017/000000206027.jpg  \n",
      " extracting: val2017/000000469652.jpg  \n",
      " extracting: val2017/000000283318.jpg  \n",
      " extracting: val2017/000000255483.jpg  \n",
      " extracting: val2017/000000042070.jpg  \n",
      " extracting: val2017/000000452793.jpg  \n",
      " extracting: val2017/000000491216.jpg  \n",
      " extracting: val2017/000000369442.jpg  \n",
      " extracting: val2017/000000310200.jpg  \n",
      " extracting: val2017/000000455352.jpg  \n",
      " extracting: val2017/000000294783.jpg  \n",
      " extracting: val2017/000000079651.jpg  \n",
      " extracting: val2017/000000239717.jpg  \n",
      " extracting: val2017/000000231125.jpg  \n",
      " extracting: val2017/000000505638.jpg  \n",
      " extracting: val2017/000000293071.jpg  \n",
      " extracting: val2017/000000299553.jpg  \n",
      " extracting: val2017/000000365766.jpg  \n",
      " extracting: val2017/000000166563.jpg  \n",
      " extracting: val2017/000000019742.jpg  \n",
      " extracting: val2017/000000088485.jpg  \n",
      " extracting: val2017/000000245320.jpg  \n",
      " extracting: val2017/000000134322.jpg  \n",
      " extracting: val2017/000000564023.jpg  \n",
      " extracting: val2017/000000383606.jpg  \n",
      " extracting: val2017/000000179392.jpg  \n",
      " extracting: val2017/000000353027.jpg  \n",
      " extracting: val2017/000000028452.jpg  \n",
      " extracting: val2017/000000530099.jpg  \n",
      " extracting: val2017/000000125936.jpg  \n",
      " extracting: val2017/000000446206.jpg  \n",
      " extracting: val2017/000000234366.jpg  \n",
      " extracting: val2017/000000053994.jpg  \n",
      " extracting: val2017/000000031269.jpg  \n",
      " extracting: val2017/000000260657.jpg  \n",
      " extracting: val2017/000000053626.jpg  \n",
      " extracting: val2017/000000456015.jpg  \n",
      " extracting: val2017/000000326542.jpg  \n",
      " extracting: val2017/000000100428.jpg  \n",
      " extracting: val2017/000000104669.jpg  \n",
      " extracting: val2017/000000349302.jpg  \n",
      " extracting: val2017/000000116206.jpg  \n",
      " extracting: val2017/000000400803.jpg  \n",
      " extracting: val2017/000000444142.jpg  \n",
      " extracting: val2017/000000047740.jpg  \n",
      " extracting: val2017/000000039951.jpg  \n",
      " extracting: val2017/000000566436.jpg  \n",
      " extracting: val2017/000000312213.jpg  \n",
      " extracting: val2017/000000039914.jpg  \n",
      " extracting: val2017/000000411754.jpg  \n",
      " extracting: val2017/000000462728.jpg  \n",
      " extracting: val2017/000000296284.jpg  \n",
      " extracting: val2017/000000349152.jpg  \n",
      " extracting: val2017/000000538236.jpg  \n",
      " extracting: val2017/000000035062.jpg  \n",
      " extracting: val2017/000000549390.jpg  \n",
      " extracting: val2017/000000267670.jpg  \n",
      " extracting: val2017/000000153343.jpg  \n",
      " extracting: val2017/000000005600.jpg  \n",
      " extracting: val2017/000000533493.jpg  \n",
      " extracting: val2017/000000279541.jpg  \n",
      " extracting: val2017/000000208208.jpg  \n",
      " extracting: val2017/000000363188.jpg  \n",
      " extracting: val2017/000000063740.jpg  \n",
      " extracting: val2017/000000262895.jpg  \n",
      " extracting: val2017/000000494427.jpg  \n",
      " extracting: val2017/000000002431.jpg  \n",
      " extracting: val2017/000000013729.jpg  \n",
      " extracting: val2017/000000022935.jpg  \n",
      " extracting: val2017/000000358427.jpg  \n",
      " extracting: val2017/000000423229.jpg  \n",
      " extracting: val2017/000000270122.jpg  \n",
      " extracting: val2017/000000521141.jpg  \n",
      " extracting: val2017/000000060102.jpg  \n",
      " extracting: val2017/000000451090.jpg  \n",
      " extracting: val2017/000000479155.jpg  \n",
      " extracting: val2017/000000529105.jpg  \n",
      " extracting: val2017/000000460929.jpg  \n",
      " extracting: val2017/000000344029.jpg  \n",
      " extracting: val2017/000000240754.jpg  \n",
      " extracting: val2017/000000236166.jpg  \n",
      " extracting: val2017/000000187734.jpg  \n",
      " extracting: val2017/000000424349.jpg  \n",
      " extracting: val2017/000000229849.jpg  \n",
      " extracting: val2017/000000433243.jpg  \n",
      " extracting: val2017/000000459634.jpg  \n",
      " extracting: val2017/000000154339.jpg  \n",
      " extracting: val2017/000000386134.jpg  \n",
      " extracting: val2017/000000542089.jpg  \n",
      " extracting: val2017/000000093965.jpg  \n",
      " extracting: val2017/000000222317.jpg  \n",
      " extracting: val2017/000000499181.jpg  \n",
      " extracting: val2017/000000414676.jpg  \n",
      " extracting: val2017/000000527029.jpg  \n",
      " extracting: val2017/000000230983.jpg  \n",
      " extracting: val2017/000000176857.jpg  \n",
      " extracting: val2017/000000139883.jpg  \n",
      " extracting: val2017/000000326128.jpg  \n",
      " extracting: val2017/000000073946.jpg  \n",
      " extracting: val2017/000000160864.jpg  \n",
      " extracting: val2017/000000099024.jpg  \n",
      " extracting: val2017/000000369081.jpg  \n",
      " extracting: val2017/000000273715.jpg  \n",
      " extracting: val2017/000000329080.jpg  \n",
      " extracting: val2017/000000227686.jpg  \n",
      " extracting: val2017/000000514914.jpg  \n",
      " extracting: val2017/000000336309.jpg  \n",
      " extracting: val2017/000000177714.jpg  \n",
      " extracting: val2017/000000027982.jpg  \n",
      " extracting: val2017/000000312192.jpg  \n",
      " extracting: val2017/000000123213.jpg  \n",
      " extracting: val2017/000000125952.jpg  \n",
      " extracting: val2017/000000125245.jpg  \n",
      " extracting: val2017/000000146489.jpg  \n",
      " extracting: val2017/000000419408.jpg  \n",
      " extracting: val2017/000000469192.jpg  \n",
      " extracting: val2017/000000233727.jpg  \n",
      " extracting: val2017/000000468124.jpg  \n",
      " extracting: val2017/000000355240.jpg  \n",
      " extracting: val2017/000000336356.jpg  \n",
      " extracting: val2017/000000328337.jpg  \n",
      " extracting: val2017/000000377670.jpg  \n",
      " extracting: val2017/000000097924.jpg  \n",
      " extracting: val2017/000000091615.jpg  \n",
      " extracting: val2017/000000548246.jpg  \n",
      " extracting: val2017/000000554328.jpg  \n",
      " extracting: val2017/000000475678.jpg  \n",
      " extracting: val2017/000000110449.jpg  \n",
      " extracting: val2017/000000064898.jpg  \n",
      " extracting: val2017/000000119911.jpg  \n",
      " extracting: val2017/000000230008.jpg  \n",
      " extracting: val2017/000000092416.jpg  \n",
      " extracting: val2017/000000097994.jpg  \n",
      " extracting: val2017/000000563349.jpg  \n",
      " extracting: val2017/000000572956.jpg  \n",
      " extracting: val2017/000000048924.jpg  \n",
      " extracting: val2017/000000287714.jpg  \n",
      " extracting: val2017/000000568710.jpg  \n",
      " extracting: val2017/000000161879.jpg  \n",
      " extracting: val2017/000000532575.jpg  \n",
      " extracting: val2017/000000443498.jpg  \n",
      " extracting: val2017/000000197796.jpg  \n",
      " extracting: val2017/000000289417.jpg  \n",
      " extracting: val2017/000000466602.jpg  \n",
      " extracting: val2017/000000579091.jpg  \n",
      " extracting: val2017/000000369310.jpg  \n",
      " extracting: val2017/000000259830.jpg  \n",
      " extracting: val2017/000000189806.jpg  \n",
      " extracting: val2017/000000249550.jpg  \n",
      " extracting: val2017/000000154644.jpg  \n",
      " extracting: val2017/000000343934.jpg  \n",
      " extracting: val2017/000000273132.jpg  \n",
      " extracting: val2017/000000407524.jpg  \n",
      " extracting: val2017/000000407403.jpg  \n",
      " extracting: val2017/000000173383.jpg  \n",
      " extracting: val2017/000000283268.jpg  \n",
      " extracting: val2017/000000398203.jpg  \n",
      " extracting: val2017/000000017627.jpg  \n",
      " extracting: val2017/000000324715.jpg  \n",
      " extracting: val2017/000000461275.jpg  \n",
      " extracting: val2017/000000011197.jpg  \n",
      " extracting: val2017/000000480944.jpg  \n",
      " extracting: val2017/000000121031.jpg  \n",
      " extracting: val2017/000000195842.jpg  \n",
      " extracting: val2017/000000270066.jpg  \n",
      " extracting: val2017/000000329447.jpg  \n",
      " extracting: val2017/000000059598.jpg  \n",
      " extracting: val2017/000000183104.jpg  \n",
      " extracting: val2017/000000055002.jpg  \n",
      " extracting: val2017/000000350607.jpg  \n",
      " extracting: val2017/000000546475.jpg  \n",
      " extracting: val2017/000000431727.jpg  \n",
      " extracting: val2017/000000303818.jpg  \n",
      " extracting: val2017/000000353970.jpg  \n",
      " extracting: val2017/000000540414.jpg  \n",
      " extracting: val2017/000000452515.jpg  \n",
      " extracting: val2017/000000494634.jpg  \n",
      " extracting: val2017/000000083172.jpg  \n",
      " extracting: val2017/000000062355.jpg  \n",
      " extracting: val2017/000000018837.jpg  \n",
      " extracting: val2017/000000023781.jpg  \n",
      " extracting: val2017/000000490171.jpg  \n",
      " extracting: val2017/000000104666.jpg  \n",
      " extracting: val2017/000000455597.jpg  \n",
      " extracting: val2017/000000419096.jpg  \n",
      " extracting: val2017/000000240049.jpg  \n",
      " extracting: val2017/000000464824.jpg  \n",
      " extracting: val2017/000000343976.jpg  \n",
      " extracting: val2017/000000274219.jpg  \n",
      " extracting: val2017/000000231580.jpg  \n",
      " extracting: val2017/000000065736.jpg  \n",
      " extracting: val2017/000000352684.jpg  \n",
      " extracting: val2017/000000324258.jpg  \n",
      " extracting: val2017/000000113051.jpg  \n",
      " extracting: val2017/000000370900.jpg  \n",
      " extracting: val2017/000000040471.jpg  \n",
      " extracting: val2017/000000226662.jpg  \n",
      " extracting: val2017/000000002153.jpg  \n",
      " extracting: val2017/000000350488.jpg  \n",
      " extracting: val2017/000000151629.jpg  \n",
      " extracting: val2017/000000469067.jpg  \n",
      " extracting: val2017/000000494759.jpg  \n",
      " extracting: val2017/000000360564.jpg  \n",
      " extracting: val2017/000000097585.jpg  \n",
      " extracting: val2017/000000088970.jpg  \n",
      " extracting: val2017/000000481390.jpg  \n",
      " extracting: val2017/000000185802.jpg  \n",
      " extracting: val2017/000000579893.jpg  \n",
      " extracting: val2017/000000556765.jpg  \n",
      " extracting: val2017/000000301867.jpg  \n",
      " extracting: val2017/000000397639.jpg  \n",
      " extracting: val2017/000000142790.jpg  \n",
      " extracting: val2017/000000466567.jpg  \n",
      " extracting: val2017/000000080671.jpg  \n",
      " extracting: val2017/000000106281.jpg  \n",
      " extracting: val2017/000000547519.jpg  \n",
      " extracting: val2017/000000333237.jpg  \n",
      " extracting: val2017/000000261036.jpg  \n",
      " extracting: val2017/000000014007.jpg  \n",
      " extracting: val2017/000000331817.jpg  \n",
      " extracting: val2017/000000427997.jpg  \n",
      " extracting: val2017/000000459396.jpg  \n",
      " extracting: val2017/000000102805.jpg  \n",
      " extracting: val2017/000000227399.jpg  \n",
      " extracting: val2017/000000389381.jpg  \n",
      " extracting: val2017/000000095786.jpg  \n",
      " extracting: val2017/000000402346.jpg  \n",
      " extracting: val2017/000000358195.jpg  \n",
      " extracting: val2017/000000214200.jpg  \n",
      " extracting: val2017/000000476258.jpg  \n",
      " extracting: val2017/000000410221.jpg  \n",
      " extracting: val2017/000000310072.jpg  \n",
      " extracting: val2017/000000012120.jpg  \n",
      " extracting: val2017/000000105335.jpg  \n",
      " extracting: val2017/000000289938.jpg  \n",
      " extracting: val2017/000000377588.jpg  \n",
      " extracting: val2017/000000031248.jpg  \n",
      " extracting: val2017/000000206218.jpg  \n",
      " extracting: val2017/000000245173.jpg  \n",
      " extracting: val2017/000000340015.jpg  \n",
      " extracting: val2017/000000099428.jpg  \n",
      " extracting: val2017/000000207585.jpg  \n",
      " extracting: val2017/000000570688.jpg  \n",
      " extracting: val2017/000000396518.jpg  \n",
      " extracting: val2017/000000269682.jpg  \n",
      " extracting: val2017/000000213224.jpg  \n",
      " extracting: val2017/000000304812.jpg  \n",
      " extracting: val2017/000000032817.jpg  \n",
      " extracting: val2017/000000166259.jpg  \n",
      " extracting: val2017/000000046031.jpg  \n",
      " extracting: val2017/000000267940.jpg  \n",
      " extracting: val2017/000000493566.jpg  \n",
      " extracting: val2017/000000391722.jpg  \n",
      " extracting: val2017/000000260106.jpg  \n",
      " extracting: val2017/000000292155.jpg  \n",
      " extracting: val2017/000000360943.jpg  \n",
      " extracting: val2017/000000503823.jpg  \n",
      " extracting: val2017/000000106235.jpg  \n",
      " extracting: val2017/000000530854.jpg  \n",
      " extracting: val2017/000000433134.jpg  \n",
      " extracting: val2017/000000270386.jpg  \n",
      " extracting: val2017/000000146155.jpg  \n",
      " extracting: val2017/000000444275.jpg  \n",
      " extracting: val2017/000000178618.jpg  \n",
      " extracting: val2017/000000414261.jpg  \n",
      " extracting: val2017/000000092053.jpg  \n",
      " extracting: val2017/000000218362.jpg  \n",
      " extracting: val2017/000000054931.jpg  \n",
      " extracting: val2017/000000471893.jpg  \n",
      " extracting: val2017/000000081766.jpg  \n",
      " extracting: val2017/000000381971.jpg  \n",
      " extracting: val2017/000000203095.jpg  \n",
      " extracting: val2017/000000090631.jpg  \n",
      " extracting: val2017/000000425221.jpg  \n",
      " extracting: val2017/000000545100.jpg  \n",
      " extracting: val2017/000000198805.jpg  \n",
      " extracting: val2017/000000157124.jpg  \n",
      " extracting: val2017/000000052412.jpg  \n",
      " extracting: val2017/000000017029.jpg  \n",
      " extracting: val2017/000000073702.jpg  \n",
      " extracting: val2017/000000181859.jpg  \n",
      " extracting: val2017/000000011615.jpg  \n",
      " extracting: val2017/000000155443.jpg  \n",
      " extracting: val2017/000000369675.jpg  \n",
      " extracting: val2017/000000553339.jpg  \n",
      " extracting: val2017/000000449190.jpg  \n",
      " extracting: val2017/000000250127.jpg  \n",
      " extracting: val2017/000000270297.jpg  \n",
      " extracting: val2017/000000347693.jpg  \n",
      " extracting: val2017/000000288042.jpg  \n",
      " extracting: val2017/000000089761.jpg  \n",
      " extracting: val2017/000000000802.jpg  \n",
      " extracting: val2017/000000404249.jpg  \n",
      " extracting: val2017/000000319935.jpg  \n",
      " extracting: val2017/000000500565.jpg  \n",
      " extracting: val2017/000000323709.jpg  \n",
      " extracting: val2017/000000376856.jpg  \n",
      " extracting: val2017/000000126110.jpg  \n",
      " extracting: val2017/000000151051.jpg  \n",
      " extracting: val2017/000000218439.jpg  \n",
      " extracting: val2017/000000085772.jpg  \n",
      " extracting: val2017/000000342295.jpg  \n",
      " extracting: val2017/000000419653.jpg  \n",
      " extracting: val2017/000000554266.jpg  \n",
      " extracting: val2017/000000507575.jpg  \n",
      " extracting: val2017/000000498709.jpg  \n",
      " extracting: val2017/000000096825.jpg  \n",
      " extracting: val2017/000000015440.jpg  \n",
      " extracting: val2017/000000464089.jpg  \n",
      " extracting: val2017/000000239773.jpg  \n",
      " extracting: val2017/000000343466.jpg  \n",
      " extracting: val2017/000000565624.jpg  \n",
      " extracting: val2017/000000210388.jpg  \n",
      " extracting: val2017/000000180188.jpg  \n",
      " extracting: val2017/000000289586.jpg  \n",
      " extracting: val2017/000000363784.jpg  \n",
      " extracting: val2017/000000224675.jpg  \n",
      " extracting: val2017/000000128112.jpg  \n",
      " extracting: val2017/000000536038.jpg  \n",
      " extracting: val2017/000000128658.jpg  \n",
      " extracting: val2017/000000111609.jpg  \n",
      " extracting: val2017/000000109313.jpg  \n",
      " extracting: val2017/000000091500.jpg  \n",
      " extracting: val2017/000000443969.jpg  \n",
      " extracting: val2017/000000234413.jpg  \n",
      " extracting: val2017/000000512403.jpg  \n",
      " extracting: val2017/000000445675.jpg  \n",
      " extracting: val2017/000000294350.jpg  \n",
      " extracting: val2017/000000098392.jpg  \n",
      " extracting: val2017/000000028449.jpg  \n",
      " extracting: val2017/000000015746.jpg  \n",
      " extracting: val2017/000000257624.jpg  \n",
      " extracting: val2017/000000474095.jpg  \n",
      " extracting: val2017/000000296222.jpg  \n",
      " extracting: val2017/000000564133.jpg  \n",
      " extracting: val2017/000000435880.jpg  \n",
      " extracting: val2017/000000296231.jpg  \n",
      " extracting: val2017/000000485237.jpg  \n",
      " extracting: val2017/000000328601.jpg  \n",
      " extracting: val2017/000000355169.jpg  \n",
      " extracting: val2017/000000321887.jpg  \n",
      " extracting: val2017/000000168337.jpg  \n",
      " extracting: val2017/000000334719.jpg  \n",
      " extracting: val2017/000000155291.jpg  \n",
      " extracting: val2017/000000154358.jpg  \n",
      " extracting: val2017/000000559547.jpg  \n",
      " extracting: val2017/000000361571.jpg  \n",
      " extracting: val2017/000000389566.jpg  \n",
      " extracting: val2017/000000171298.jpg  \n",
      " extracting: val2017/000000452891.jpg  \n",
      " extracting: val2017/000000203317.jpg  \n",
      " extracting: val2017/000000338191.jpg  \n",
      " extracting: val2017/000000058111.jpg  \n",
      " extracting: val2017/000000471991.jpg  \n",
      " extracting: val2017/000000196442.jpg  \n",
      " extracting: val2017/000000294695.jpg  \n",
      " extracting: val2017/000000182611.jpg  \n",
      " extracting: val2017/000000222825.jpg  \n",
      " extracting: val2017/000000262682.jpg  \n",
      " extracting: val2017/000000364587.jpg  \n",
      " extracting: val2017/000000054654.jpg  \n",
      " extracting: val2017/000000492968.jpg  \n",
      " extracting: val2017/000000030494.jpg  \n",
      " extracting: val2017/000000038118.jpg  \n",
      " extracting: val2017/000000476415.jpg  \n",
      " extracting: val2017/000000145620.jpg  \n",
      " extracting: val2017/000000060507.jpg  \n",
      " extracting: val2017/000000263679.jpg  \n",
      " extracting: val2017/000000185950.jpg  \n",
      " extracting: val2017/000000148662.jpg  \n",
      " extracting: val2017/000000287291.jpg  \n",
      " extracting: val2017/000000062692.jpg  \n",
      " extracting: val2017/000000214703.jpg  \n",
      " extracting: val2017/000000213816.jpg  \n",
      " extracting: val2017/000000434297.jpg  \n",
      " extracting: val2017/000000476770.jpg  \n",
      " extracting: val2017/000000447187.jpg  \n",
      " extracting: val2017/000000134886.jpg  \n",
      " extracting: val2017/000000378873.jpg  \n",
      " extracting: val2017/000000067213.jpg  \n",
      " extracting: val2017/000000446207.jpg  \n",
      " extracting: val2017/000000165681.jpg  \n",
      " extracting: val2017/000000024144.jpg  \n",
      " extracting: val2017/000000439773.jpg  \n",
      " extracting: val2017/000000172595.jpg  \n",
      " extracting: val2017/000000118594.jpg  \n",
      " extracting: val2017/000000323151.jpg  \n",
      " extracting: val2017/000000571943.jpg  \n",
      " extracting: val2017/000000581100.jpg  \n",
      " extracting: val2017/000000151516.jpg  \n",
      " extracting: val2017/000000244181.jpg  \n",
      " extracting: val2017/000000273617.jpg  \n",
      " extracting: val2017/000000008762.jpg  \n",
      " extracting: val2017/000000088848.jpg  \n",
      " extracting: val2017/000000059044.jpg  \n",
      " extracting: val2017/000000050165.jpg  \n",
      " extracting: val2017/000000289343.jpg  \n",
      " extracting: val2017/000000416451.jpg  \n",
      " extracting: val2017/000000044652.jpg  \n",
      " extracting: val2017/000000314182.jpg  \n",
      " extracting: val2017/000000014439.jpg  \n",
      " extracting: val2017/000000053505.jpg  \n",
      " extracting: val2017/000000213171.jpg  \n",
      " extracting: val2017/000000502910.jpg  \n",
      " extracting: val2017/000000503755.jpg  \n",
      " extracting: val2017/000000371529.jpg  \n",
      " extracting: val2017/000000385029.jpg  \n",
      " extracting: val2017/000000515982.jpg  \n",
      " extracting: val2017/000000012280.jpg  \n",
      " extracting: val2017/000000521259.jpg  \n",
      " extracting: val2017/000000318238.jpg  \n",
      " extracting: val2017/000000544811.jpg  \n",
      " extracting: val2017/000000289229.jpg  \n",
      " extracting: val2017/000000280779.jpg  \n",
      " extracting: val2017/000000297147.jpg  \n",
      " extracting: val2017/000000239318.jpg  \n",
      " extracting: val2017/000000359833.jpg  \n",
      " extracting: val2017/000000452321.jpg  \n",
      " extracting: val2017/000000570756.jpg  \n",
      " extracting: val2017/000000080659.jpg  \n",
      " extracting: val2017/000000456143.jpg  \n",
      " extracting: val2017/000000014473.jpg  \n",
      " extracting: val2017/000000051326.jpg  \n",
      " extracting: val2017/000000054123.jpg  \n",
      " extracting: val2017/000000203546.jpg  \n",
      " extracting: val2017/000000350122.jpg  \n",
      " extracting: val2017/000000045229.jpg  \n",
      " extracting: val2017/000000560279.jpg  \n",
      " extracting: val2017/000000399764.jpg  \n",
      " extracting: val2017/000000190648.jpg  \n",
      " extracting: val2017/000000554735.jpg  \n",
      " extracting: val2017/000000248400.jpg  \n",
      " extracting: val2017/000000397681.jpg  \n",
      " extracting: val2017/000000296224.jpg  \n",
      " extracting: val2017/000000382122.jpg  \n",
      " extracting: val2017/000000223090.jpg  \n",
      " extracting: val2017/000000347254.jpg  \n",
      " extracting: val2017/000000547854.jpg  \n",
      " extracting: val2017/000000478474.jpg  \n",
      " extracting: val2017/000000529939.jpg  \n",
      " extracting: val2017/000000254516.jpg  \n",
      " extracting: val2017/000000320743.jpg  \n",
      " extracting: val2017/000000069213.jpg  \n",
      " extracting: val2017/000000187362.jpg  \n",
      " extracting: val2017/000000236784.jpg  \n",
      " extracting: val2017/000000500464.jpg  \n",
      " extracting: val2017/000000395343.jpg  \n",
      " extracting: val2017/000000180135.jpg  \n",
      " extracting: val2017/000000311883.jpg  \n",
      " extracting: val2017/000000084241.jpg  \n",
      " extracting: val2017/000000170613.jpg  \n",
      " extracting: val2017/000000063602.jpg  \n",
      " extracting: val2017/000000488592.jpg  \n",
      " extracting: val2017/000000436315.jpg  \n",
      " extracting: val2017/000000429109.jpg  \n",
      " extracting: val2017/000000409424.jpg  \n",
      " extracting: val2017/000000194506.jpg  \n",
      " extracting: val2017/000000437392.jpg  \n",
      " extracting: val2017/000000424642.jpg  \n",
      " extracting: val2017/000000465585.jpg  \n",
      " extracting: val2017/000000080022.jpg  \n",
      " extracting: val2017/000000186980.jpg  \n",
      " extracting: val2017/000000537802.jpg  \n",
      " extracting: val2017/000000302760.jpg  \n",
      " extracting: val2017/000000105249.jpg  \n",
      " extracting: val2017/000000345469.jpg  \n",
      " extracting: val2017/000000414034.jpg  \n",
      " extracting: val2017/000000289960.jpg  \n",
      " extracting: val2017/000000377368.jpg  \n",
      " extracting: val2017/000000305343.jpg  \n",
      " extracting: val2017/000000110211.jpg  \n",
      " extracting: val2017/000000560880.jpg  \n",
      " extracting: val2017/000000355610.jpg  \n",
      " extracting: val2017/000000527616.jpg  \n",
      " extracting: val2017/000000196185.jpg  \n",
      " extracting: val2017/000000546011.jpg  \n",
      " extracting: val2017/000000023272.jpg  \n",
      " extracting: val2017/000000293390.jpg  \n",
      " extracting: val2017/000000065485.jpg  \n",
      " extracting: val2017/000000013201.jpg  \n",
      " extracting: val2017/000000356531.jpg  \n",
      " extracting: val2017/000000278006.jpg  \n",
      " extracting: val2017/000000441247.jpg  \n",
      " extracting: val2017/000000329319.jpg  \n",
      " extracting: val2017/000000333697.jpg  \n",
      " extracting: val2017/000000089697.jpg  \n",
      " extracting: val2017/000000048564.jpg  \n",
      " extracting: val2017/000000540466.jpg  \n",
      " extracting: val2017/000000123633.jpg  \n",
      " extracting: val2017/000000441442.jpg  \n",
      " extracting: val2017/000000060855.jpg  \n",
      " extracting: val2017/000000183500.jpg  \n",
      " extracting: val2017/000000140987.jpg  \n",
      " extracting: val2017/000000417876.jpg  \n",
      " extracting: val2017/000000461036.jpg  \n",
      " extracting: val2017/000000130465.jpg  \n",
      " extracting: val2017/000000327306.jpg  \n",
      " extracting: val2017/000000153510.jpg  \n",
      " extracting: val2017/000000503841.jpg  \n",
      " extracting: val2017/000000493334.jpg  \n",
      " extracting: val2017/000000267933.jpg  \n",
      " extracting: val2017/000000370486.jpg  \n",
      " extracting: val2017/000000132622.jpg  \n",
      " extracting: val2017/000000530162.jpg  \n",
      " extracting: val2017/000000319696.jpg  \n",
      " extracting: val2017/000000553221.jpg  \n",
      " extracting: val2017/000000418961.jpg  \n",
      " extracting: val2017/000000359135.jpg  \n",
      " extracting: val2017/000000162543.jpg  \n",
      " extracting: val2017/000000468965.jpg  \n",
      " extracting: val2017/000000041635.jpg  \n",
      " extracting: val2017/000000404568.jpg  \n",
      " extracting: val2017/000000004495.jpg  \n",
      " extracting: val2017/000000555012.jpg  \n",
      " extracting: val2017/000000074209.jpg  \n",
      " extracting: val2017/000000476810.jpg  \n",
      " extracting: val2017/000000152771.jpg  \n",
      " extracting: val2017/000000005060.jpg  \n",
      " extracting: val2017/000000385205.jpg  \n",
      " extracting: val2017/000000210030.jpg  \n",
      " extracting: val2017/000000033109.jpg  \n",
      " extracting: val2017/000000104803.jpg  \n",
      " extracting: val2017/000000542856.jpg  \n",
      " extracting: val2017/000000120853.jpg  \n",
      " extracting: val2017/000000551304.jpg  \n",
      " extracting: val2017/000000490125.jpg  \n",
      " extracting: val2017/000000474344.jpg  \n",
      " extracting: val2017/000000217614.jpg  \n",
      " extracting: val2017/000000193717.jpg  \n",
      " extracting: val2017/000000374551.jpg  \n",
      " extracting: val2017/000000459809.jpg  \n",
      " extracting: val2017/000000567740.jpg  \n",
      " extracting: val2017/000000142971.jpg  \n",
      " extracting: val2017/000000425390.jpg  \n",
      " extracting: val2017/000000571718.jpg  \n",
      " extracting: val2017/000000450100.jpg  \n",
      " extracting: val2017/000000509008.jpg  \n",
      " extracting: val2017/000000442746.jpg  \n",
      " extracting: val2017/000000140286.jpg  \n",
      " extracting: val2017/000000306437.jpg  \n",
      " extracting: val2017/000000425925.jpg  \n",
      " extracting: val2017/000000451150.jpg  \n",
      " extracting: val2017/000000067616.jpg  \n",
      " extracting: val2017/000000127530.jpg  \n",
      " extracting: val2017/000000224119.jpg  \n",
      " extracting: val2017/000000323202.jpg  \n",
      " extracting: val2017/000000233033.jpg  \n",
      " extracting: val2017/000000283717.jpg  \n",
      " extracting: val2017/000000132931.jpg  \n",
      " extracting: val2017/000000170545.jpg  \n",
      " extracting: val2017/000000500613.jpg  \n",
      " extracting: val2017/000000386879.jpg  \n",
      " extracting: val2017/000000182202.jpg  \n",
      " extracting: val2017/000000227187.jpg  \n",
      " extracting: val2017/000000344816.jpg  \n",
      " extracting: val2017/000000435206.jpg  \n",
      " extracting: val2017/000000546659.jpg  \n",
      " extracting: val2017/000000296317.jpg  \n",
      " extracting: val2017/000000261706.jpg  \n",
      " extracting: val2017/000000408774.jpg  \n",
      " extracting: val2017/000000371042.jpg  \n",
      " extracting: val2017/000000506004.jpg  \n",
      " extracting: val2017/000000235252.jpg  \n",
      " extracting: val2017/000000562561.jpg  \n",
      " extracting: val2017/000000219271.jpg  \n",
      " extracting: val2017/000000125257.jpg  \n",
      " extracting: val2017/000000034873.jpg  \n",
      " extracting: val2017/000000053909.jpg  \n",
      " extracting: val2017/000000121673.jpg  \n",
      " extracting: val2017/000000033759.jpg  \n",
      " extracting: val2017/000000196843.jpg  \n",
      " extracting: val2017/000000502347.jpg  \n",
      " extracting: val2017/000000306582.jpg  \n",
      " extracting: val2017/000000129322.jpg  \n",
      " extracting: val2017/000000512194.jpg  \n",
      " extracting: val2017/000000192904.jpg  \n",
      " extracting: val2017/000000447522.jpg  \n",
      " extracting: val2017/000000315219.jpg  \n",
      " extracting: val2017/000000197658.jpg  \n",
      " extracting: val2017/000000089078.jpg  \n",
      " extracting: val2017/000000398652.jpg  \n",
      " extracting: val2017/000000500049.jpg  \n",
      " extracting: val2017/000000543300.jpg  \n",
      " extracting: val2017/000000148999.jpg  \n",
      " extracting: val2017/000000055022.jpg  \n",
      " extracting: val2017/000000090891.jpg  \n",
      " extracting: val2017/000000567898.jpg  \n",
      " extracting: val2017/000000002685.jpg  \n",
      " extracting: val2017/000000312720.jpg  \n",
      " extracting: val2017/000000465179.jpg  \n",
      " extracting: val2017/000000458325.jpg  \n",
      " extracting: val2017/000000540932.jpg  \n",
      " extracting: val2017/000000184321.jpg  \n",
      " extracting: val2017/000000068628.jpg  \n",
      " extracting: val2017/000000026204.jpg  \n",
      " extracting: val2017/000000170278.jpg  \n",
      " extracting: val2017/000000288062.jpg  \n",
      " extracting: val2017/000000201934.jpg  \n",
      " extracting: val2017/000000527220.jpg  \n",
      " extracting: val2017/000000318908.jpg  \n",
      " extracting: val2017/000000404128.jpg  \n",
      " extracting: val2017/000000019432.jpg  \n",
      " extracting: val2017/000000003845.jpg  \n",
      " extracting: val2017/000000323263.jpg  \n",
      " extracting: val2017/000000115870.jpg  \n",
      " extracting: val2017/000000338304.jpg  \n",
      " extracting: val2017/000000580294.jpg  \n",
      " extracting: val2017/000000201426.jpg  \n",
      " extracting: val2017/000000437239.jpg  \n",
      " extracting: val2017/000000265777.jpg  \n",
      " extracting: val2017/000000348481.jpg  \n",
      " extracting: val2017/000000443426.jpg  \n",
      " extracting: val2017/000000292225.jpg  \n",
      " extracting: val2017/000000553990.jpg  \n",
      " extracting: val2017/000000081594.jpg  \n",
      " extracting: val2017/000000082807.jpg  \n",
      " extracting: val2017/000000348708.jpg  \n",
      " extracting: val2017/000000500716.jpg  \n",
      " extracting: val2017/000000312549.jpg  \n",
      " extracting: val2017/000000000872.jpg  \n",
      " extracting: val2017/000000456865.jpg  \n",
      " extracting: val2017/000000442306.jpg  \n",
      " extracting: val2017/000000497568.jpg  \n",
      " extracting: val2017/000000091921.jpg  \n",
      " extracting: val2017/000000578093.jpg  \n",
      " extracting: val2017/000000014038.jpg  \n",
      " extracting: val2017/000000134112.jpg  \n",
      " extracting: val2017/000000358923.jpg  \n",
      " extracting: val2017/000000166287.jpg  \n",
      " extracting: val2017/000000179642.jpg  \n",
      " extracting: val2017/000000082821.jpg  \n",
      " extracting: val2017/000000124798.jpg  \n",
      " extracting: val2017/000000522393.jpg  \n",
      " extracting: val2017/000000007818.jpg  \n",
      " extracting: val2017/000000002149.jpg  \n",
      " extracting: val2017/000000562207.jpg  \n",
      " extracting: val2017/000000356347.jpg  \n",
      " extracting: val2017/000000466125.jpg  \n",
      " extracting: val2017/000000395903.jpg  \n",
      " extracting: val2017/000000420281.jpg  \n",
      " extracting: val2017/000000400367.jpg  \n",
      " extracting: val2017/000000175387.jpg  \n",
      " extracting: val2017/000000341681.jpg  \n",
      " extracting: val2017/000000329455.jpg  \n",
      " extracting: val2017/000000108253.jpg  \n",
      " extracting: val2017/000000226883.jpg  \n",
      " extracting: val2017/000000449406.jpg  \n",
      " extracting: val2017/000000007511.jpg  \n",
      " extracting: val2017/000000573943.jpg  \n",
      " extracting: val2017/000000001993.jpg  \n",
      " extracting: val2017/000000310980.jpg  \n",
      " extracting: val2017/000000107094.jpg  \n",
      " extracting: val2017/000000096001.jpg  \n",
      " extracting: val2017/000000502136.jpg  \n",
      " extracting: val2017/000000245026.jpg  \n",
      " extracting: val2017/000000186637.jpg  \n",
      " extracting: val2017/000000020333.jpg  \n",
      " extracting: val2017/000000127987.jpg  \n",
      " extracting: val2017/000000561679.jpg  \n",
      " extracting: val2017/000000033005.jpg  \n",
      " extracting: val2017/000000127394.jpg  \n",
      " extracting: val2017/000000009769.jpg  \n",
      " extracting: val2017/000000570664.jpg  \n",
      " extracting: val2017/000000188465.jpg  \n",
      " extracting: val2017/000000549136.jpg  \n",
      " extracting: val2017/000000042563.jpg  \n",
      " extracting: val2017/000000297343.jpg  \n",
      " extracting: val2017/000000209142.jpg  \n",
      " extracting: val2017/000000465129.jpg  \n",
      " extracting: val2017/000000116589.jpg  \n",
      " extracting: val2017/000000581781.jpg  \n",
      " extracting: val2017/000000027932.jpg  \n",
      " extracting: val2017/000000555412.jpg  \n",
      " extracting: val2017/000000389804.jpg  \n",
      " extracting: val2017/000000241297.jpg  \n",
      " extracting: val2017/000000052507.jpg  \n",
      " extracting: val2017/000000100238.jpg  \n",
      " extracting: val2017/000000261796.jpg  \n",
      " extracting: val2017/000000055072.jpg  \n",
      " extracting: val2017/000000476704.jpg  \n",
      " extracting: val2017/000000573008.jpg  \n",
      " extracting: val2017/000000304545.jpg  \n",
      " extracting: val2017/000000268729.jpg  \n",
      " extracting: val2017/000000508482.jpg  \n",
      " extracting: val2017/000000019786.jpg  \n",
      " extracting: val2017/000000384661.jpg  \n",
      " extracting: val2017/000000301061.jpg  \n",
      " extracting: val2017/000000427055.jpg  \n",
      " extracting: val2017/000000103723.jpg  \n",
      " extracting: val2017/000000254368.jpg  \n",
      " extracting: val2017/000000219283.jpg  \n",
      " extracting: val2017/000000576654.jpg  \n",
      " extracting: val2017/000000519764.jpg  \n",
      " extracting: val2017/000000302030.jpg  \n",
      " extracting: val2017/000000177213.jpg  \n",
      " extracting: val2017/000000183716.jpg  \n",
      " extracting: val2017/000000535858.jpg  \n",
      " extracting: val2017/000000116439.jpg  \n",
      " extracting: val2017/000000043314.jpg  \n",
      " extracting: val2017/000000479448.jpg  \n",
      " extracting: val2017/000000547144.jpg  \n",
      " extracting: val2017/000000221155.jpg  \n",
      " extracting: val2017/000000463730.jpg  \n",
      " extracting: val2017/000000207538.jpg  \n",
      " extracting: val2017/000000080273.jpg  \n",
      " extracting: val2017/000000407943.jpg  \n",
      " extracting: val2017/000000158227.jpg  \n",
      " extracting: val2017/000000407298.jpg  \n",
      " extracting: val2017/000000477441.jpg  \n",
      " extracting: val2017/000000128372.jpg  \n",
      " extracting: val2017/000000074200.jpg  \n",
      " extracting: val2017/000000322724.jpg  \n",
      " extracting: val2017/000000569976.jpg  \n",
      " extracting: val2017/000000191845.jpg  \n",
      " extracting: val2017/000000110359.jpg  \n",
      " extracting: val2017/000000299887.jpg  \n",
      " extracting: val2017/000000227491.jpg  \n",
      " extracting: val2017/000000187055.jpg  \n",
      " extracting: val2017/000000159399.jpg  \n",
      " extracting: val2017/000000369037.jpg  \n",
      " extracting: val2017/000000100582.jpg  \n",
      " extracting: val2017/000000549055.jpg  \n",
      " extracting: val2017/000000074058.jpg  \n",
      " extracting: val2017/000000429530.jpg  \n",
      " extracting: val2017/000000284282.jpg  \n",
      " extracting: val2017/000000076417.jpg  \n",
      " extracting: val2017/000000563267.jpg  \n",
      " extracting: val2017/000000453166.jpg  \n",
      " extracting: val2017/000000563281.jpg  \n",
      " extracting: val2017/000000205514.jpg  \n",
      " extracting: val2017/000000021903.jpg  \n",
      " extracting: val2017/000000109441.jpg  \n",
      " extracting: val2017/000000183246.jpg  \n",
      " extracting: val2017/000000064523.jpg  \n",
      " extracting: val2017/000000070774.jpg  \n",
      " extracting: val2017/000000499109.jpg  \n",
      " extracting: val2017/000000105014.jpg  \n",
      " extracting: val2017/000000515445.jpg  \n",
      " extracting: val2017/000000363207.jpg  \n",
      " extracting: val2017/000000169076.jpg  \n",
      " extracting: val2017/000000031296.jpg  \n",
      " extracting: val2017/000000521601.jpg  \n",
      " extracting: val2017/000000263644.jpg  \n",
      " extracting: val2017/000000523782.jpg  \n",
      " extracting: val2017/000000366611.jpg  \n",
      " extracting: val2017/000000271997.jpg  \n",
      " extracting: val2017/000000053624.jpg  \n",
      " extracting: val2017/000000407825.jpg  \n",
      " extracting: val2017/000000475223.jpg  \n",
      " extracting: val2017/000000482436.jpg  \n",
      " extracting: val2017/000000306733.jpg  \n",
      " extracting: val2017/000000412362.jpg  \n",
      " extracting: val2017/000000052565.jpg  \n",
      " extracting: val2017/000000189828.jpg  \n",
      " extracting: val2017/000000520707.jpg  \n",
      " extracting: val2017/000000449996.jpg  \n",
      " extracting: val2017/000000221213.jpg  \n",
      " extracting: val2017/000000374545.jpg  \n",
      " extracting: val2017/000000555705.jpg  \n",
      " extracting: val2017/000000426372.jpg  \n",
      " extracting: val2017/000000374369.jpg  \n",
      " extracting: val2017/000000404479.jpg  \n",
      " extracting: val2017/000000313783.jpg  \n",
      " extracting: val2017/000000243034.jpg  \n",
      " extracting: val2017/000000289594.jpg  \n",
      " extracting: val2017/000000521819.jpg  \n",
      " extracting: val2017/000000218424.jpg  \n",
      " extracting: val2017/000000431876.jpg  \n",
      " extracting: val2017/000000309655.jpg  \n",
      " extracting: val2017/000000469174.jpg  \n",
      " extracting: val2017/000000049259.jpg  \n",
      " extracting: val2017/000000438017.jpg  \n",
      " extracting: val2017/000000515025.jpg  \n",
      " extracting: val2017/000000402765.jpg  \n",
      " extracting: val2017/000000066231.jpg  \n",
      " extracting: val2017/000000154425.jpg  \n",
      " extracting: val2017/000000377000.jpg  \n",
      " extracting: val2017/000000520077.jpg  \n",
      " extracting: val2017/000000033221.jpg  \n",
      " extracting: val2017/000000519491.jpg  \n",
      " extracting: val2017/000000223959.jpg  \n",
      " extracting: val2017/000000188689.jpg  \n",
      " extracting: val2017/000000079969.jpg  \n",
      " extracting: val2017/000000221872.jpg  \n",
      " extracting: val2017/000000365385.jpg  \n",
      " extracting: val2017/000000140583.jpg  \n",
      " extracting: val2017/000000304560.jpg  \n",
      " extracting: val2017/000000323828.jpg  \n",
      " extracting: val2017/000000296634.jpg  \n",
      " extracting: val2017/000000170893.jpg  \n",
      " extracting: val2017/000000534270.jpg  \n",
      " extracting: val2017/000000049761.jpg  \n",
      " extracting: val2017/000000240940.jpg  \n",
      " extracting: val2017/000000471567.jpg  \n",
      " extracting: val2017/000000262440.jpg  \n",
      " extracting: val2017/000000304291.jpg  \n",
      " extracting: val2017/000000038048.jpg  \n",
      " extracting: val2017/000000515577.jpg  \n",
      " extracting: val2017/000000378116.jpg  \n",
      " extracting: val2017/000000371699.jpg  \n",
      " extracting: val2017/000000435081.jpg  \n",
      " extracting: val2017/000000155154.jpg  \n",
      " extracting: val2017/000000565012.jpg  \n",
      " extracting: val2017/000000284764.jpg  \n",
      " extracting: val2017/000000071711.jpg  \n",
      " extracting: val2017/000000565778.jpg  \n",
      " extracting: val2017/000000107851.jpg  \n",
      " extracting: val2017/000000516677.jpg  \n",
      " extracting: val2017/000000205105.jpg  \n",
      " extracting: val2017/000000144114.jpg  \n",
      " extracting: val2017/000000104612.jpg  \n",
      " extracting: val2017/000000037740.jpg  \n",
      " extracting: val2017/000000519338.jpg  \n",
      " extracting: val2017/000000240023.jpg  \n",
      " extracting: val2017/000000032941.jpg  \n",
      " extracting: val2017/000000500257.jpg  \n",
      " extracting: val2017/000000554838.jpg  \n",
      " extracting: val2017/000000292082.jpg  \n",
      " extracting: val2017/000000176634.jpg  \n",
      " extracting: val2017/000000212573.jpg  \n",
      " extracting: val2017/000000437898.jpg  \n",
      " extracting: val2017/000000328030.jpg  \n",
      " extracting: val2017/000000047010.jpg  \n",
      " extracting: val2017/000000199236.jpg  \n",
      " extracting: val2017/000000360137.jpg  \n",
      " extracting: val2017/000000157767.jpg  \n",
      " extracting: val2017/000000200667.jpg  \n",
      " extracting: val2017/000000053529.jpg  \n",
      " extracting: val2017/000000190676.jpg  \n",
      " extracting: val2017/000000154431.jpg  \n",
      " extracting: val2017/000000352582.jpg  \n",
      " extracting: val2017/000000367818.jpg  \n",
      " extracting: val2017/000000272212.jpg  \n",
      " extracting: val2017/000000531135.jpg  \n",
      " extracting: val2017/000000410487.jpg  \n",
      " extracting: val2017/000000090108.jpg  \n",
      " extracting: val2017/000000575500.jpg  \n",
      " extracting: val2017/000000082986.jpg  \n",
      " extracting: val2017/000000449661.jpg  \n",
      " extracting: val2017/000000384666.jpg  \n",
      " extracting: val2017/000000569700.jpg  \n",
      " extracting: val2017/000000264968.jpg  \n",
      " extracting: val2017/000000213593.jpg  \n",
      " extracting: val2017/000000293804.jpg  \n",
      " extracting: val2017/000000511076.jpg  \n",
      " extracting: val2017/000000061171.jpg  \n",
      " extracting: val2017/000000033707.jpg  \n",
      " extracting: val2017/000000424975.jpg  \n",
      " extracting: val2017/000000217219.jpg  \n",
      " extracting: val2017/000000427160.jpg  \n",
      " extracting: val2017/000000410934.jpg  \n",
      " extracting: val2017/000000214753.jpg  \n",
      " extracting: val2017/000000186422.jpg  \n",
      " extracting: val2017/000000034417.jpg  \n",
      " extracting: val2017/000000176232.jpg  \n",
      " extracting: val2017/000000176847.jpg  \n",
      " extracting: val2017/000000172547.jpg  \n",
      " extracting: val2017/000000423798.jpg  \n",
      " extracting: val2017/000000183437.jpg  \n",
      " extracting: val2017/000000501023.jpg  \n",
      " extracting: val2017/000000203639.jpg  \n",
      " extracting: val2017/000000376284.jpg  \n",
      " extracting: val2017/000000017905.jpg  \n",
      " extracting: val2017/000000078170.jpg  \n",
      " extracting: val2017/000000022969.jpg  \n",
      " extracting: val2017/000000270908.jpg  \n",
      " extracting: val2017/000000520531.jpg  \n",
      " extracting: val2017/000000114049.jpg  \n",
      " extracting: val2017/000000532058.jpg  \n",
      " extracting: val2017/000000427034.jpg  \n",
      " extracting: val2017/000000067534.jpg  \n",
      " extracting: val2017/000000184338.jpg  \n",
      " extracting: val2017/000000358525.jpg  \n",
      " extracting: val2017/000000365095.jpg  \n",
      " extracting: val2017/000000342397.jpg  \n",
      " extracting: val2017/000000168619.jpg  \n",
      " extracting: val2017/000000225184.jpg  \n",
      " extracting: val2017/000000094336.jpg  \n",
      " extracting: val2017/000000063047.jpg  \n",
      " extracting: val2017/000000133244.jpg  \n",
      " extracting: val2017/000000096549.jpg  \n",
      " extracting: val2017/000000266981.jpg  \n",
      " extracting: val2017/000000162035.jpg  \n",
      " extracting: val2017/000000408830.jpg  \n",
      " extracting: val2017/000000164637.jpg  \n",
      " extracting: val2017/000000215114.jpg  \n",
      " extracting: val2017/000000403122.jpg  \n",
      " extracting: val2017/000000580418.jpg  \n",
      " extracting: val2017/000000170739.jpg  \n",
      " extracting: val2017/000000451084.jpg  \n",
      " extracting: val2017/000000119828.jpg  \n",
      " extracting: val2017/000000223182.jpg  \n",
      " extracting: val2017/000000531495.jpg  \n",
      " extracting: val2017/000000317999.jpg  \n",
      " extracting: val2017/000000568690.jpg  \n",
      " extracting: val2017/000000516871.jpg  \n",
      " extracting: val2017/000000184324.jpg  \n",
      " extracting: val2017/000000228436.jpg  \n",
      " extracting: val2017/000000162581.jpg  \n",
      " extracting: val2017/000000426329.jpg  \n",
      " extracting: val2017/000000420840.jpg  \n",
      " extracting: val2017/000000473015.jpg  \n",
      " extracting: val2017/000000239627.jpg  \n",
      " extracting: val2017/000000541952.jpg  \n",
      " extracting: val2017/000000223747.jpg  \n",
      " extracting: val2017/000000481413.jpg  \n",
      " extracting: val2017/000000539445.jpg  \n",
      " extracting: val2017/000000357941.jpg  \n",
      " extracting: val2017/000000410456.jpg  \n",
      " extracting: val2017/000000222299.jpg  \n",
      " extracting: val2017/000000489924.jpg  \n",
      " extracting: val2017/000000058029.jpg  \n",
      " extracting: val2017/000000243075.jpg  \n",
      " extracting: val2017/000000137294.jpg  \n",
      " extracting: val2017/000000569059.jpg  \n",
      " extracting: val2017/000000370375.jpg  \n",
      " extracting: val2017/000000099810.jpg  \n",
      " extracting: val2017/000000122672.jpg  \n",
      " extracting: val2017/000000186449.jpg  \n",
      " extracting: val2017/000000445792.jpg  \n",
      " extracting: val2017/000000375493.jpg  \n",
      " extracting: val2017/000000183127.jpg  \n",
      " extracting: val2017/000000380711.jpg  \n",
      " extracting: val2017/000000442836.jpg  \n",
      " extracting: val2017/000000491071.jpg  \n",
      " extracting: val2017/000000026564.jpg  \n",
      " extracting: val2017/000000367082.jpg  \n",
      " extracting: val2017/000000464144.jpg  \n",
      " extracting: val2017/000000535306.jpg  \n",
      " extracting: val2017/000000463037.jpg  \n",
      " extracting: val2017/000000409198.jpg  \n",
      " extracting: val2017/000000445846.jpg  \n",
      " extracting: val2017/000000257865.jpg  \n",
      " extracting: val2017/000000166509.jpg  \n",
      " extracting: val2017/000000056344.jpg  \n",
      " extracting: val2017/000000069795.jpg  \n",
      " extracting: val2017/000000250619.jpg  \n",
      " extracting: val2017/000000173183.jpg  \n",
      " extracting: val2017/000000533855.jpg  \n",
      " extracting: val2017/000000364297.jpg  \n",
      " extracting: val2017/000000451571.jpg  \n",
      " extracting: val2017/000000025096.jpg  \n",
      " extracting: val2017/000000422836.jpg  \n",
      " extracting: val2017/000000078404.jpg  \n",
      " extracting: val2017/000000043816.jpg  \n",
      " extracting: val2017/000000528862.jpg  \n",
      " extracting: val2017/000000088462.jpg  \n",
      " extracting: val2017/000000253695.jpg  \n",
      " extracting: val2017/000000147729.jpg  \n",
      " extracting: val2017/000000079014.jpg  \n",
      " extracting: val2017/000000202001.jpg  \n",
      " extracting: val2017/000000244019.jpg  \n",
      " extracting: val2017/000000544306.jpg  \n",
      " extracting: val2017/000000259382.jpg  \n",
      " extracting: val2017/000000304365.jpg  \n",
      " extracting: val2017/000000301421.jpg  \n",
      " extracting: val2017/000000020571.jpg  \n",
      " extracting: val2017/000000157601.jpg  \n",
      " extracting: val2017/000000468505.jpg  \n",
      " extracting: val2017/000000088265.jpg  \n",
      " extracting: val2017/000000027696.jpg  \n",
      " extracting: val2017/000000234807.jpg  \n",
      " extracting: val2017/000000547383.jpg  \n",
      " extracting: val2017/000000499775.jpg  \n",
      " extracting: val2017/000000158660.jpg  \n",
      " extracting: val2017/000000173008.jpg  \n",
      " extracting: val2017/000000216516.jpg  \n",
      " extracting: val2017/000000071877.jpg  \n",
      " extracting: val2017/000000153669.jpg  \n",
      " extracting: val2017/000000520009.jpg  \n",
      " extracting: val2017/000000179112.jpg  \n",
      " extracting: val2017/000000378099.jpg  \n",
      " extracting: val2017/000000562197.jpg  \n",
      " extracting: val2017/000000130586.jpg  \n",
      " extracting: val2017/000000329456.jpg  \n",
      " extracting: val2017/000000314541.jpg  \n",
      " extracting: val2017/000000286907.jpg  \n",
      " extracting: val2017/000000000632.jpg  \n",
      " extracting: val2017/000000460147.jpg  \n",
      " extracting: val2017/000000249129.jpg  \n",
      " extracting: val2017/000000379800.jpg  \n",
      " extracting: val2017/000000029640.jpg  \n",
      " extracting: val2017/000000150638.jpg  \n",
      " extracting: val2017/000000480985.jpg  \n",
      " extracting: val2017/000000389532.jpg  \n",
      " extracting: val2017/000000351362.jpg  \n",
      " extracting: val2017/000000015338.jpg  \n",
      " extracting: val2017/000000492110.jpg  \n",
      " extracting: val2017/000000361103.jpg  \n",
      " extracting: val2017/000000375015.jpg  \n",
      " extracting: val2017/000000062025.jpg  \n",
      " extracting: val2017/000000370999.jpg  \n",
      " extracting: val2017/000000004134.jpg  \n",
      " extracting: val2017/000000057725.jpg  \n",
      " extracting: val2017/000000441286.jpg  \n",
      " extracting: val2017/000000377486.jpg  \n",
      " extracting: val2017/000000016451.jpg  \n",
      " extracting: val2017/000000347456.jpg  \n",
      " extracting: val2017/000000367195.jpg  \n",
      " extracting: val2017/000000269196.jpg  \n",
      " extracting: val2017/000000011699.jpg  \n",
      " extracting: val2017/000000309495.jpg  \n",
      " extracting: val2017/000000011813.jpg  \n",
      " extracting: val2017/000000237071.jpg  \n",
      " extracting: val2017/000000272566.jpg  \n",
      " extracting: val2017/000000132796.jpg  \n",
      " extracting: val2017/000000384949.jpg  \n",
      " extracting: val2017/000000276055.jpg  \n",
      " extracting: val2017/000000236721.jpg  \n",
      " extracting: val2017/000000286523.jpg  \n",
      " extracting: val2017/000000024027.jpg  \n",
      " extracting: val2017/000000462614.jpg  \n",
      " extracting: val2017/000000345261.jpg  \n",
      " extracting: val2017/000000295316.jpg  \n",
      " extracting: val2017/000000190637.jpg  \n",
      " extracting: val2017/000000172617.jpg  \n",
      " extracting: val2017/000000093717.jpg  \n",
      " extracting: val2017/000000425702.jpg  \n",
      " extracting: val2017/000000522889.jpg  \n",
      " extracting: val2017/000000160556.jpg  \n",
      " extracting: val2017/000000553511.jpg  \n",
      " extracting: val2017/000000170099.jpg  \n",
      " extracting: val2017/000000173799.jpg  \n",
      " extracting: val2017/000000488736.jpg  \n",
      " extracting: val2017/000000301135.jpg  \n",
      " extracting: val2017/000000018491.jpg  \n",
      " extracting: val2017/000000124277.jpg  \n",
      " extracting: val2017/000000488673.jpg  \n",
      " extracting: val2017/000000533816.jpg  \n",
      " extracting: val2017/000000172935.jpg  \n",
      " extracting: val2017/000000137576.jpg  \n",
      " extracting: val2017/000000520264.jpg  \n",
      " extracting: val2017/000000410650.jpg  \n",
      " extracting: val2017/000000117914.jpg  \n",
      " extracting: val2017/000000338901.jpg  \n",
      " extracting: val2017/000000223955.jpg  \n",
      " extracting: val2017/000000030675.jpg  \n",
      " extracting: val2017/000000530061.jpg  \n",
      " extracting: val2017/000000335954.jpg  \n",
      " extracting: val2017/000000428218.jpg  \n",
      " extracting: val2017/000000192670.jpg  \n",
      " extracting: val2017/000000447465.jpg  \n",
      " extracting: val2017/000000144984.jpg  \n",
      " extracting: val2017/000000212559.jpg  \n",
      " extracting: val2017/000000466339.jpg  \n",
      " extracting: val2017/000000015335.jpg  \n",
      " extracting: val2017/000000156924.jpg  \n",
      " extracting: val2017/000000211825.jpg  \n",
      " extracting: val2017/000000162732.jpg  \n",
      " extracting: val2017/000000118367.jpg  \n",
      " extracting: val2017/000000435208.jpg  \n",
      " extracting: val2017/000000341828.jpg  \n",
      " extracting: val2017/000000475365.jpg  \n",
      " extracting: val2017/000000493613.jpg  \n",
      " extracting: val2017/000000562581.jpg  \n",
      " extracting: val2017/000000047585.jpg  \n",
      " extracting: val2017/000000261535.jpg  \n",
      " extracting: val2017/000000306139.jpg  \n",
      " extracting: val2017/000000011051.jpg  \n",
      " extracting: val2017/000000086755.jpg  \n",
      " extracting: val2017/000000205289.jpg  \n",
      " extracting: val2017/000000149375.jpg  \n",
      " extracting: val2017/000000193245.jpg  \n",
      " extracting: val2017/000000216277.jpg  \n",
      " extracting: val2017/000000035197.jpg  \n",
      " extracting: val2017/000000048504.jpg  \n",
      " extracting: val2017/000000429011.jpg  \n",
      " extracting: val2017/000000217957.jpg  \n",
      " extracting: val2017/000000322895.jpg  \n",
      " extracting: val2017/000000015079.jpg  \n",
      " extracting: val2017/000000431140.jpg  \n",
      " extracting: val2017/000000169356.jpg  \n",
      " extracting: val2017/000000408696.jpg  \n",
      " extracting: val2017/000000338325.jpg  \n",
      " extracting: val2017/000000250137.jpg  \n",
      " extracting: val2017/000000454404.jpg  \n",
      " extracting: val2017/000000421060.jpg  \n",
      " extracting: val2017/000000073326.jpg  \n",
      " extracting: val2017/000000410878.jpg  \n",
      " extracting: val2017/000000292908.jpg  \n",
      " extracting: val2017/000000350679.jpg  \n",
      " extracting: val2017/000000390301.jpg  \n",
      " extracting: val2017/000000213547.jpg  \n",
      " extracting: val2017/000000087244.jpg  \n",
      " extracting: val2017/000000253819.jpg  \n",
      " extracting: val2017/000000192699.jpg  \n",
      " extracting: val2017/000000260261.jpg  \n",
      " extracting: val2017/000000044279.jpg  \n",
      " extracting: val2017/000000306136.jpg  \n",
      " extracting: val2017/000000066771.jpg  \n",
      " extracting: val2017/000000355257.jpg  \n",
      " extracting: val2017/000000548339.jpg  \n",
      " extracting: val2017/000000125062.jpg  \n",
      " extracting: val2017/000000078565.jpg  \n",
      " extracting: val2017/000000332845.jpg  \n",
      " extracting: val2017/000000298904.jpg  \n",
      " extracting: val2017/000000437351.jpg  \n",
      " extracting: val2017/000000232646.jpg  \n",
      " extracting: val2017/000000153217.jpg  \n",
      " extracting: val2017/000000377946.jpg  \n",
      " extracting: val2017/000000478136.jpg  \n",
      " extracting: val2017/000000458992.jpg  \n",
      " extracting: val2017/000000495448.jpg  \n",
      " extracting: val2017/000000221708.jpg  \n",
      " extracting: val2017/000000152214.jpg  \n",
      " extracting: val2017/000000493019.jpg  \n",
      " extracting: val2017/000000459195.jpg  \n",
      " extracting: val2017/000000135890.jpg  \n",
      " extracting: val2017/000000012062.jpg  \n",
      " extracting: val2017/000000349860.jpg  \n",
      " extracting: val2017/000000246436.jpg  \n",
      " extracting: val2017/000000474854.jpg  \n",
      " extracting: val2017/000000388903.jpg  \n",
      " extracting: val2017/000000156643.jpg  \n",
      " extracting: val2017/000000030828.jpg  \n",
      " extracting: val2017/000000318138.jpg  \n",
      " extracting: val2017/000000368456.jpg  \n",
      " extracting: val2017/000000156292.jpg  \n",
      " extracting: val2017/000000355905.jpg  \n",
      " extracting: val2017/000000016598.jpg  \n",
      " extracting: val2017/000000125472.jpg  \n",
      " extracting: val2017/000000037670.jpg  \n",
      " extracting: val2017/000000178744.jpg  \n",
      " extracting: val2017/000000382009.jpg  \n",
      " extracting: val2017/000000276024.jpg  \n",
      " extracting: val2017/000000345027.jpg  \n",
      " extracting: val2017/000000377113.jpg  \n",
      " extracting: val2017/000000140556.jpg  \n",
      " extracting: val2017/000000000139.jpg  \n",
      " extracting: val2017/000000525155.jpg  \n",
      " extracting: val2017/000000217753.jpg  \n",
      " extracting: val2017/000000215259.jpg  \n",
      " extracting: val2017/000000119365.jpg  \n",
      " extracting: val2017/000000276707.jpg  \n",
      " extracting: val2017/000000072852.jpg  \n",
      " extracting: val2017/000000377814.jpg  \n",
      " extracting: val2017/000000222118.jpg  \n",
      " extracting: val2017/000000404922.jpg  \n",
      " extracting: val2017/000000296649.jpg  \n",
      " extracting: val2017/000000161032.jpg  \n",
      " extracting: val2017/000000005529.jpg  \n",
      " extracting: val2017/000000322864.jpg  \n",
      " extracting: val2017/000000194716.jpg  \n",
      " extracting: val2017/000000175364.jpg  \n",
      " extracting: val2017/000000001268.jpg  \n",
      " extracting: val2017/000000018193.jpg  \n",
      " extracting: val2017/000000515266.jpg  \n",
      " extracting: val2017/000000335081.jpg  \n",
      " extracting: val2017/000000094614.jpg  \n",
      " extracting: val2017/000000128748.jpg  \n",
      " extracting: val2017/000000568439.jpg  \n",
      " extracting: val2017/000000104198.jpg  \n",
      " extracting: val2017/000000003501.jpg  \n",
      " extracting: val2017/000000138492.jpg  \n",
      " extracting: val2017/000000228942.jpg  \n",
      " extracting: val2017/000000516143.jpg  \n",
      " extracting: val2017/000000179214.jpg  \n",
      " extracting: val2017/000000531707.jpg  \n",
      " extracting: val2017/000000298994.jpg  \n",
      " extracting: val2017/000000020107.jpg  \n",
      " extracting: val2017/000000241677.jpg  \n",
      " extracting: val2017/000000284725.jpg  \n",
      " extracting: val2017/000000117908.jpg  \n",
      " extracting: val2017/000000226058.jpg  \n",
      " extracting: val2017/000000506454.jpg  \n",
      " extracting: val2017/000000042888.jpg  \n",
      " extracting: val2017/000000167486.jpg  \n",
      " extracting: val2017/000000279927.jpg  \n",
      " extracting: val2017/000000383289.jpg  \n",
      " extracting: val2017/000000190236.jpg  \n",
      " extracting: val2017/000000375078.jpg  \n",
      " extracting: val2017/000000472030.jpg  \n",
      " extracting: val2017/000000447789.jpg  \n",
      " extracting: val2017/000000496409.jpg  \n",
      " extracting: val2017/000000263969.jpg  \n",
      " extracting: val2017/000000293474.jpg  \n",
      " extracting: val2017/000000025386.jpg  \n",
      " extracting: val2017/000000112634.jpg  \n",
      " extracting: val2017/000000186624.jpg  \n",
      " extracting: val2017/000000515077.jpg  \n",
      " extracting: val2017/000000523194.jpg  \n",
      " extracting: val2017/000000204871.jpg  \n",
      " extracting: val2017/000000257084.jpg  \n",
      " extracting: val2017/000000311392.jpg  \n",
      " extracting: val2017/000000191761.jpg  \n",
      " extracting: val2017/000000394328.jpg  \n",
      " extracting: val2017/000000162092.jpg  \n",
      " extracting: val2017/000000355325.jpg  \n",
      " extracting: val2017/000000027620.jpg  \n",
      " extracting: val2017/000000378453.jpg  \n",
      " extracting: val2017/000000330554.jpg  \n",
      " extracting: val2017/000000372819.jpg  \n",
      " extracting: val2017/000000526706.jpg  \n",
      " extracting: val2017/000000338986.jpg  \n",
      " extracting: val2017/000000561009.jpg  \n",
      " extracting: val2017/000000571008.jpg  \n",
      " extracting: val2017/000000154705.jpg  \n",
      " extracting: val2017/000000328286.jpg  \n",
      " extracting: val2017/000000116208.jpg  \n",
      " extracting: val2017/000000263860.jpg  \n",
      " extracting: val2017/000000229221.jpg  \n",
      " extracting: val2017/000000007108.jpg  \n",
      " extracting: val2017/000000252507.jpg  \n",
      " extracting: val2017/000000281759.jpg  \n",
      " extracting: val2017/000000523100.jpg  \n",
      " extracting: val2017/000000165713.jpg  \n",
      " extracting: val2017/000000242724.jpg  \n",
      " extracting: val2017/000000234779.jpg  \n",
      " extracting: val2017/000000465675.jpg  \n",
      " extracting: val2017/000000504000.jpg  \n",
      " extracting: val2017/000000298251.jpg  \n",
      " extracting: val2017/000000015660.jpg  \n",
      " extracting: val2017/000000111086.jpg  \n",
      " extracting: val2017/000000279730.jpg  \n",
      " extracting: val2017/000000331075.jpg  \n",
      " extracting: val2017/000000336587.jpg  \n",
      " extracting: val2017/000000350002.jpg  \n",
      " extracting: val2017/000000390555.jpg  \n",
      " extracting: val2017/000000018380.jpg  \n",
      " extracting: val2017/000000114907.jpg  \n",
      " extracting: val2017/000000357978.jpg  \n",
      " extracting: val2017/000000133819.jpg  \n",
      " extracting: val2017/000000487583.jpg  \n",
      " extracting: val2017/000000278705.jpg  \n",
      " extracting: val2017/000000380706.jpg  \n",
      " extracting: val2017/000000229111.jpg  \n",
      " extracting: val2017/000000283038.jpg  \n",
      " extracting: val2017/000000365655.jpg  \n",
      " extracting: val2017/000000049269.jpg  \n",
      " extracting: val2017/000000402118.jpg  \n",
      " extracting: val2017/000000239537.jpg  \n",
      " extracting: val2017/000000298738.jpg  \n",
      " extracting: val2017/000000334371.jpg  \n",
      " extracting: val2017/000000263403.jpg  \n",
      " extracting: val2017/000000106563.jpg  \n",
      " extracting: val2017/000000449603.jpg  \n",
      " extracting: val2017/000000346232.jpg  \n",
      " extracting: val2017/000000248284.jpg  \n",
      " extracting: val2017/000000572620.jpg  \n",
      " extracting: val2017/000000395701.jpg  \n",
      " extracting: val2017/000000054164.jpg  \n",
      " extracting: val2017/000000171382.jpg  \n",
      " extracting: val2017/000000513181.jpg  \n",
      " extracting: val2017/000000161781.jpg  \n",
      " extracting: val2017/000000394199.jpg  \n",
      " extracting: val2017/000000301718.jpg  \n",
      " extracting: val2017/000000555050.jpg  \n",
      " extracting: val2017/000000388846.jpg  \n",
      " extracting: val2017/000000323895.jpg  \n",
      " extracting: val2017/000000234660.jpg  \n",
      " extracting: val2017/000000343453.jpg  \n",
      " extracting: val2017/000000540928.jpg  \n",
      " extracting: val2017/000000190756.jpg  \n",
      " extracting: val2017/000000068387.jpg  \n",
      " extracting: val2017/000000151000.jpg  \n",
      " extracting: val2017/000000244592.jpg  \n",
      " extracting: val2017/000000158956.jpg  \n",
      " extracting: val2017/000000058636.jpg  \n",
      " extracting: val2017/000000326174.jpg  \n",
      " extracting: val2017/000000241319.jpg  \n",
      " extracting: val2017/000000244379.jpg  \n",
      " extracting: val2017/000000263796.jpg  \n",
      " extracting: val2017/000000176799.jpg  \n",
      " extracting: val2017/000000491867.jpg  \n",
      " extracting: val2017/000000017899.jpg  \n",
      " extracting: val2017/000000455716.jpg  \n",
      " extracting: val2017/000000284991.jpg  \n",
      " extracting: val2017/000000084431.jpg  \n",
      " extracting: val2017/000000284762.jpg  \n",
      " extracting: val2017/000000255536.jpg  \n",
      " extracting: val2017/000000043435.jpg  \n",
      " extracting: val2017/000000546325.jpg  \n",
      " extracting: val2017/000000291619.jpg  \n",
      " extracting: val2017/000000512648.jpg  \n",
      " extracting: val2017/000000014226.jpg  \n",
      " extracting: val2017/000000084492.jpg  \n",
      " extracting: val2017/000000376478.jpg  \n",
      " extracting: val2017/000000124636.jpg  \n",
      " extracting: val2017/000000564091.jpg  \n",
      " extracting: val2017/000000477689.jpg  \n",
      " extracting: val2017/000000523957.jpg  \n",
      " extracting: val2017/000000570539.jpg  \n",
      " extracting: val2017/000000470121.jpg  \n",
      " extracting: val2017/000000199442.jpg  \n",
      " extracting: val2017/000000563653.jpg  \n",
      " extracting: val2017/000000181421.jpg  \n",
      " extracting: val2017/000000302990.jpg  \n",
      " extracting: val2017/000000446005.jpg  \n",
      " extracting: val2017/000000329219.jpg  \n",
      " extracting: val2017/000000388258.jpg  \n",
      " extracting: val2017/000000126137.jpg  \n",
      " extracting: val2017/000000500826.jpg  \n",
      "Archive:  annotations_trainval2017.zip\n",
      "  inflating: annotations/instances_train2017.json  \n",
      "  inflating: annotations/instances_val2017.json  \n",
      "  inflating: annotations/captions_train2017.json  \n",
      "  inflating: annotations/captions_val2017.json  \n",
      "  inflating: annotations/person_keypoints_train2017.json  \n",
      "  inflating: annotations/person_keypoints_val2017.json  \n"
     ]
    }
   ],
   "source": [
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "!unzip /content/SOTR/val2017.zip #move the dataset to the location /datasets/coco (subfolder of datasets folder\")\n",
    "!unzip -o annotations_trainval2017.zip #similarly move the annotation folder to the location /datasets/coco (subfolder of datasets folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9RX7Illk0xg",
    "outputId": "12079b99-8411-4a73-80fa-cc5fc8263507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.69s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of Unique Categories: 80\n",
      "Category IDs:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n",
      "Categories Names:\n",
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "Category ID -> Category Name:\n",
      "Category ID: 1, Category Name: person, Supercategory: person\n",
      "Category Name -> ID:\n",
      "Category Name: car, Category ID: 3\n",
      "Number of Images Containing car: 535\n",
      "Image ID: 454661, File Name: 000000454661.jpg, Image URL: http://images.cocodataset.org/val2017/000000454661.jpg\n",
      "Annotations for Image ID 454661:\n",
      "[{'segmentation': [[368.36, 356.08, 498.47, 351.5, 633.17, 338.67, 639.58, 231.46, 591.02, 227.79, 549.79, 185.64, 350.03, 187.48, 295.97, 242.46, 280.39, 238.79, 268.48, 245.2, 276.73, 258.03, 247.4, 284.61, 254.73, 359.74]], 'area': 56297.64605000001, 'iscrowd': 0, 'image_id': 454661, 'bbox': [247.4, 185.64, 392.18, 174.1], 'category_id': 3, 'id': 134116}, {'segmentation': [[181.82, 210.29, 204.78, 207.53, 271.81, 207.53, 295.69, 214.88, 299.36, 220.39, 300.28, 222.22, 300.28, 225.9, 297.52, 231.41, 292.93, 236.92, 282.83, 236.92, 268.14, 244.26, 269.97, 249.77, 273.65, 252.53, 264.46, 258.95, 264.46, 264.46, 258.04, 270.89, 250.69, 275.48, 246.1, 282.83, 247.02, 293.85, 247.02, 302.11, 243.34, 314.05, 243.34, 317.72, 242.43, 320.48, 234.16, 323.23, 219.47, 323.23, 209.37, 324.15, 180.9, 316.81, 189.17, 293.85, 182.74, 290.18, 173.55, 270.89, 168.96, 258.04, 152.43, 243.34, 151.52, 243.34, 149.68, 236.92, 170.8, 212.12, 183.66, 211.2]], 'area': 10699.444349999998, 'iscrowd': 0, 'image_id': 454661, 'bbox': [149.68, 207.53, 150.6, 116.62], 'category_id': 3, 'id': 136684}, {'segmentation': [[180.23, 359.46, 177.59, 325.23, 177.59, 300.21, 176.93, 285.72, 165.08, 267.95, 153.89, 254.12, 141.38, 244.9, 145.99, 221.2, 138.09, 209.35, 120.31, 210.67, 103.19, 196.84, 92.0, 192.89, 84.1, 189.6, 74.22, 187.62, 53.81, 184.99, 26.82, 184.99, 13.65, 185.65, 0.0, 186.31, 0.49, 373.29]], 'area': 28391.276699999995, 'iscrowd': 0, 'image_id': 454661, 'bbox': [0.0, 184.99, 180.23, 188.3], 'category_id': 3, 'id': 137943}, {'segmentation': [[310.68, 128.26, 348.66, 121.93, 414.5, 128.26, 417.67, 185.87, 337.9, 191.56, 310.05, 223.22, 287.89, 204.86, 249.91, 198.53, 253.07, 166.24, 272.06, 163.71, 273.96, 141.55, 309.41, 144.08]], 'area': 10512.914100000002, 'iscrowd': 0, 'image_id': 454661, 'bbox': [249.91, 121.93, 167.76, 101.29], 'category_id': 6, 'id': 163954}, {'segmentation': [[275.39, 38.22, 315.69, 44.94, 309.93, 149.53, 273.47, 146.65]], 'area': 4106.2858, 'iscrowd': 0, 'image_id': 454661, 'bbox': [273.47, 38.22, 42.22, 111.31], 'category_id': 10, 'id': 405641}, {'segmentation': [[172.48, 118.32, 192.82, 117.7, 190.94, 186.22, 183.74, 186.22, 165.91, 186.22, 165.91, 180.59, 166.22, 136.47, 167.16, 123.02, 168.41, 119.89, 169.66, 117.07, 174.36, 116.76]], 'area': 1746.8993499999997, 'iscrowd': 0, 'image_id': 454661, 'bbox': [165.91, 116.76, 26.91, 69.46], 'category_id': 10, 'id': 408541}, {'segmentation': [[236.69, 62.77, 268.21, 63.94, 267.63, 163.2, 234.93, 162.03, 236.1, 62.19]], 'area': 3218.3995999999984, 'iscrowd': 0, 'image_id': 454661, 'bbox': [234.93, 62.19, 33.28, 101.01], 'category_id': 10, 'id': 410901}, {'segmentation': [[60.83, 162.89, 78.67, 162.16, 77.69, 188.06, 60.59, 184.15, 60.34, 164.6]], 'area': 417.91600000000017, 'iscrowd': 0, 'image_id': 454661, 'bbox': [60.34, 162.16, 18.33, 25.9], 'category_id': 10, 'id': 1381083}, {'segmentation': [[41.03, 117.84, 55.99, 117.59, 57.01, 149.28, 42.05, 147.76]], 'area': 460.1950999999999, 'iscrowd': 0, 'image_id': 454661, 'bbox': [41.03, 117.59, 15.98, 31.69], 'category_id': 10, 'id': 1384347}, {'segmentation': [[51.44, 168.71, 59.26, 169.01, 59.11, 185.09, 50.69, 184.79]], 'area': 130.7046, 'iscrowd': 0, 'image_id': 454661, 'bbox': [50.69, 168.71, 8.57, 16.38], 'category_id': 10, 'id': 2057288}]\n"
     ]
    }
   ],
   "source": [
    "#!python datasets/gen_coco_person.py\n",
    "#!export DETECTRON2_DATASETS\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    coco_annotation_file_path = \"/content/SOTR/datasets/coco/annotations/instances_val2017.json\"\n",
    "\n",
    "    coco_annotation = COCO(annotation_file=coco_annotation_file_path)\n",
    "# Category IDs.\n",
    "    cat_ids = coco_annotation.getCatIds()\n",
    "    print(f\"Number of Unique Categories: {len(cat_ids)}\")\n",
    "    print(\"Category IDs:\")\n",
    "    print(cat_ids)  # The IDs are not necessarily consecutive.\n",
    "\n",
    "    # All categories.\n",
    "    cats = coco_annotation.loadCats(cat_ids)\n",
    "    cat_names = [cat[\"name\"] for cat in cats]\n",
    "    print(\"Categories Names:\")\n",
    "    print(cat_names)\n",
    "\n",
    "    # Category ID -> Category Name.\n",
    "    query_id = cat_ids[0]\n",
    "    query_annotation = coco_annotation.loadCats([query_id])[0]\n",
    "    query_name = query_annotation[\"name\"]\n",
    "    query_supercategory = query_annotation[\"supercategory\"]\n",
    "    print(\"Category ID -> Category Name:\")\n",
    "    print(\n",
    "        f\"Category ID: {query_id}, Category Name: {query_name}, Supercategory: {query_supercategory}\"\n",
    "    )\n",
    "\n",
    "    # Category Name -> Category ID.\n",
    "    query_name = cat_names[2]\n",
    "    query_id = coco_annotation.getCatIds(catNms=[query_name])[0]\n",
    "    print(\"Category Name -> ID:\")\n",
    "    print(f\"Category Name: {query_name}, Category ID: {query_id}\")\n",
    "\n",
    "    # Get the ID of all the images containing the object of the category.\n",
    "    img_ids = coco_annotation.getImgIds(catIds=[query_id])\n",
    "    print(f\"Number of Images Containing {query_name}: {len(img_ids)}\")\n",
    "\n",
    "    # Pick one image.\n",
    "    img_id = img_ids[2]\n",
    "    img_info = coco_annotation.loadImgs([img_id])[0]\n",
    "    img_file_name = img_info[\"file_name\"]\n",
    "    img_url = img_info[\"coco_url\"]\n",
    "    print(\n",
    "        f\"Image ID: {img_id}, File Name: {img_file_name}, Image URL: {img_url}\"\n",
    "    )\n",
    "\n",
    "    # Get all the annotations for the specified image.\n",
    "    ann_ids = coco_annotation.getAnnIds(imgIds=[img_id], iscrowd=None)\n",
    "    anns = coco_annotation.loadAnns(ann_ids)\n",
    "    print(f\"Annotations for Image ID {img_id}:\")\n",
    "    print(anns)\n",
    "\n",
    "    # Use URL to load image.\n",
    "    im = Image.open(requests.get(img_url, stream=True).raw)\n",
    "\n",
    "    # Save image and its labeled version.\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.asarray(im))\n",
    "    plt.savefig(f\"{img_id}.jpg\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    # Plot segmentation and bounding box.\n",
    "    coco_annotation.showAnns(anns, draw_bbox=True)\n",
    "    plt.savefig(f\"{img_id}_annotated.jpg\", bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pe3uYyzS2Om",
    "outputId": "8209b7cb-923d-4dd2-d8d5-bd39a6552f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Mounting drive which has the downloaded model R_101 for COCO\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWuXEh1IdsrK",
    "outputId": "d10e7571-b008-410f-869a-72dd4270d8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Args: Namespace(config_file='configs/SOTR/R101.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/content/drive/MyDrive/SOTR_R101.pth'], resume=False)\n",
      "\u001b[32m[03/31 11:39:42 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/31 11:39:43 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ----------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.7.13 (default, Mar 16 2022, 17:37:17) [GCC 7.5.0]\n",
      "numpy                   1.21.5\n",
      "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 11.1\n",
      "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           Yes\n",
      "GPU 0                   Tesla K80 (arch=3.7)\n",
      "Driver version          460.32.03\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  7.1.2\n",
      "torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
      "fvcore                  0.1.5.post20220305\n",
      "iopath                  0.1.9\n",
      "cv2                     4.1.2\n",
      "----------------------  ----------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "\u001b[32m[03/31 11:39:43 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/SOTR/R101.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/content/drive/MyDrive/SOTR_R101.pth'], resume=False)\n",
      "\u001b[32m[03/31 11:39:43 detectron2]: \u001b[0mContents of args.config_file=configs/SOTR/R101.yaml:\n",
      "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mBase-SOTR.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-101.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
      "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(210000, 250000)\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m300000\n",
      "\n",
      "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mtools/output/SOTR_R101\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\n",
      "\u001b[32m[03/31 11:39:43 detectron2]: \u001b[0mRunning with full config:\n",
      "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
      "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
      "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCROP_INSTANCE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mBGR\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHFLIP_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbitmask\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
      "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANTI_ALIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnet_fpn_backbone\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASIS_MODULE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANN_SET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcoco\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m8\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.3\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mProtoNet\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_BASES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m3\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBiFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_REPEATS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m6\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m160\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDLA\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_BODY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDLA34\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFrozenBN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage5\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSOTR\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOBILENET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.53\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.28\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.675\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_INTERVAL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFrozenBN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRes5ROIHeads\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m6000\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m12000\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSOTR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFPN_INSTANCE_STRIDES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m8\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m8\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m16\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFPN_SCALE_RANGES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m96\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m48\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m192\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m96\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m384\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m192\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m384\n",
      "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2048\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_IN_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_IN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mDICE_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m3.0\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mFOCAL_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mFOCAL_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mFOCAL_USE_SIGMOID\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mFOCAL_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMASK_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMASK_IN_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMASK_IN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMASK_THR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_PER_IMG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_KERNEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mgaussian\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_PRE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m500\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_SIGMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mmatrix\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GRIDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m40\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m36\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m24\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m16\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m12\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_INSTANCE_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KERNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_MASKS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRESIZE_INPUT_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIGMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.2\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE_DCN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDCN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUPDATE_THR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_COORD_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_DCN_IN_INSTANCE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTOP_MODULE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mconv\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mVOVNET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBACKBONE_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_BODY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mV-39-eSE\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFrozenBN\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage2\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage3\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage4\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mstage5\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m/content/drive/MyDrive/SOTR_R101.pth\n",
      "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtools/output/SOTR_R101\n",
      "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
      "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m8\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m300000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m210000\n",
      "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m250000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
      "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
      "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
      "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
      "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
      "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
      "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
      "\n",
      "\u001b[32m[03/31 11:39:43 detectron2]: \u001b[0mFull config saved to tools/output/SOTR_R101/config.yaml\n",
      "\u001b[32m[03/31 11:39:43 d2.utils.env]: \u001b[0mUsing a generated random seed 43781693\n",
      "\u001b[32m[03/31 11:39:47 d2.engine.defaults]: \u001b[0mModel:\n",
      "SOTR(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cate_head): TwinTransformerHead(\n",
      "    (transformer): TwinTransformer(\n",
      "      (pos_emb): Identity()\n",
      "      (layers): Sequential(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (8): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (9): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (10): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (11): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (12): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (13): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (14): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (15): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (16): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (17): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (18): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (19): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (20): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (21): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (22): ModuleList(\n",
      "            (0): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): PermuteToFrom(\n",
      "              (fn): Rezero(\n",
      "                (fn): SelfAttention(\n",
      "                  (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "                  (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
      "                  (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (23): ModuleList(\n",
      "            (0): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): Rezero(\n",
      "              (fn): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "                (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cate_pred): Linear(in_features=256, out_features=80, bias=True)\n",
      "    (kernel_pred): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (mask_head): MaskHead(\n",
      "    (convs_all_levels): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "    )\n",
      "    (conv_pred): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[03/31 11:39:47 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /content/drive/MyDrive/SOTR_R101.pth ...\n",
      "\u001b[32m[03/31 11:39:49 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
      "\u001b[32m[03/31 11:39:50 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
      "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
      "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
      "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
      "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
      "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
      "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
      "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
      "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
      "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
      "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
      "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
      "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
      "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
      "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
      "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
      "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
      "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
      "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
      "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
      "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
      "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
      "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
      "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
      "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
      "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
      "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
      "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/31 11:39:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/31 11:39:50 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/31 11:39:50 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/31 11:39:50 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[03/31 11:39:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
      "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "\u001b[32m[03/31 11:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0042 s/iter. Inference: 1.0033 s/iter. Eval: 0.0482 s/iter. Total: 1.0557 s/iter. ETA=1:27:46\n",
      "\u001b[32m[03/31 11:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 16/5000. Dataloading: 0.0039 s/iter. Inference: 0.9983 s/iter. Eval: 0.0389 s/iter. Total: 1.0412 s/iter. ETA=1:26:29\n",
      "\u001b[32m[03/31 11:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 21/5000. Dataloading: 0.0035 s/iter. Inference: 0.9949 s/iter. Eval: 0.0375 s/iter. Total: 1.0360 s/iter. ETA=1:25:58\n",
      "\u001b[32m[03/31 11:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 26/5000. Dataloading: 0.0031 s/iter. Inference: 1.0033 s/iter. Eval: 0.0390 s/iter. Total: 1.0455 s/iter. ETA=1:26:40\n",
      "\u001b[32m[03/31 11:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 31/5000. Dataloading: 0.0031 s/iter. Inference: 1.0085 s/iter. Eval: 0.0385 s/iter. Total: 1.0501 s/iter. ETA=1:26:57\n",
      "\u001b[32m[03/31 11:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 36/5000. Dataloading: 0.0029 s/iter. Inference: 1.0061 s/iter. Eval: 0.0384 s/iter. Total: 1.0475 s/iter. ETA=1:26:39\n",
      "\u001b[32m[03/31 11:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 41/5000. Dataloading: 0.0028 s/iter. Inference: 1.0048 s/iter. Eval: 0.0378 s/iter. Total: 1.0455 s/iter. ETA=1:26:24\n",
      "\u001b[32m[03/31 11:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 46/5000. Dataloading: 0.0028 s/iter. Inference: 1.0045 s/iter. Eval: 0.0375 s/iter. Total: 1.0449 s/iter. ETA=1:26:16\n",
      "\u001b[32m[03/31 11:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 51/5000. Dataloading: 0.0027 s/iter. Inference: 1.0074 s/iter. Eval: 0.0391 s/iter. Total: 1.0493 s/iter. ETA=1:26:32\n",
      "\u001b[32m[03/31 11:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 56/5000. Dataloading: 0.0027 s/iter. Inference: 1.0096 s/iter. Eval: 0.0373 s/iter. Total: 1.0496 s/iter. ETA=1:26:29\n",
      "\u001b[32m[03/31 11:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 61/5000. Dataloading: 0.0026 s/iter. Inference: 1.0108 s/iter. Eval: 0.0369 s/iter. Total: 1.0505 s/iter. ETA=1:26:28\n",
      "\u001b[32m[03/31 11:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 66/5000. Dataloading: 0.0027 s/iter. Inference: 1.0119 s/iter. Eval: 0.0371 s/iter. Total: 1.0519 s/iter. ETA=1:26:30\n",
      "\u001b[32m[03/31 11:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 71/5000. Dataloading: 0.0027 s/iter. Inference: 1.0126 s/iter. Eval: 0.0364 s/iter. Total: 1.0518 s/iter. ETA=1:26:24\n",
      "\u001b[32m[03/31 11:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 76/5000. Dataloading: 0.0027 s/iter. Inference: 1.0132 s/iter. Eval: 0.0364 s/iter. Total: 1.0524 s/iter. ETA=1:26:21\n",
      "\u001b[32m[03/31 11:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 81/5000. Dataloading: 0.0027 s/iter. Inference: 1.0131 s/iter. Eval: 0.0370 s/iter. Total: 1.0529 s/iter. ETA=1:26:19\n",
      "\u001b[32m[03/31 11:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 86/5000. Dataloading: 0.0029 s/iter. Inference: 1.0132 s/iter. Eval: 0.0386 s/iter. Total: 1.0548 s/iter. ETA=1:26:23\n",
      "\u001b[32m[03/31 11:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 91/5000. Dataloading: 0.0029 s/iter. Inference: 1.0131 s/iter. Eval: 0.0392 s/iter. Total: 1.0554 s/iter. ETA=1:26:20\n",
      "\u001b[32m[03/31 11:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 96/5000. Dataloading: 0.0029 s/iter. Inference: 1.0125 s/iter. Eval: 0.0398 s/iter. Total: 1.0554 s/iter. ETA=1:26:15\n",
      "\u001b[32m[03/31 11:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 101/5000. Dataloading: 0.0029 s/iter. Inference: 1.0133 s/iter. Eval: 0.0413 s/iter. Total: 1.0577 s/iter. ETA=1:26:21\n",
      "\u001b[32m[03/31 11:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 106/5000. Dataloading: 0.0029 s/iter. Inference: 1.0132 s/iter. Eval: 0.0413 s/iter. Total: 1.0577 s/iter. ETA=1:26:16\n",
      "\u001b[32m[03/31 11:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 111/5000. Dataloading: 0.0029 s/iter. Inference: 1.0123 s/iter. Eval: 0.0402 s/iter. Total: 1.0556 s/iter. ETA=1:26:00\n",
      "\u001b[32m[03/31 11:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 116/5000. Dataloading: 0.0028 s/iter. Inference: 1.0143 s/iter. Eval: 0.0407 s/iter. Total: 1.0581 s/iter. ETA=1:26:07\n",
      "\u001b[32m[03/31 11:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 121/5000. Dataloading: 0.0028 s/iter. Inference: 1.0169 s/iter. Eval: 0.0409 s/iter. Total: 1.0609 s/iter. ETA=1:26:15\n",
      "\u001b[32m[03/31 11:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 126/5000. Dataloading: 0.0028 s/iter. Inference: 1.0186 s/iter. Eval: 0.0411 s/iter. Total: 1.0627 s/iter. ETA=1:26:19\n",
      "\u001b[32m[03/31 11:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 131/5000. Dataloading: 0.0028 s/iter. Inference: 1.0214 s/iter. Eval: 0.0409 s/iter. Total: 1.0653 s/iter. ETA=1:26:26\n",
      "\u001b[32m[03/31 11:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 136/5000. Dataloading: 0.0028 s/iter. Inference: 1.0235 s/iter. Eval: 0.0415 s/iter. Total: 1.0681 s/iter. ETA=1:26:35\n",
      "\u001b[32m[03/31 11:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 141/5000. Dataloading: 0.0028 s/iter. Inference: 1.0260 s/iter. Eval: 0.0416 s/iter. Total: 1.0706 s/iter. ETA=1:26:42\n",
      "\u001b[32m[03/31 11:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 146/5000. Dataloading: 0.0029 s/iter. Inference: 1.0272 s/iter. Eval: 0.0413 s/iter. Total: 1.0716 s/iter. ETA=1:26:41\n",
      "\u001b[32m[03/31 11:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 151/5000. Dataloading: 0.0029 s/iter. Inference: 1.0290 s/iter. Eval: 0.0414 s/iter. Total: 1.0735 s/iter. ETA=1:26:45\n",
      "\u001b[32m[03/31 11:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 156/5000. Dataloading: 0.0029 s/iter. Inference: 1.0295 s/iter. Eval: 0.0409 s/iter. Total: 1.0735 s/iter. ETA=1:26:39\n",
      "\u001b[32m[03/31 11:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 161/5000. Dataloading: 0.0029 s/iter. Inference: 1.0304 s/iter. Eval: 0.0411 s/iter. Total: 1.0746 s/iter. ETA=1:26:39\n",
      "\u001b[32m[03/31 11:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 166/5000. Dataloading: 0.0029 s/iter. Inference: 1.0297 s/iter. Eval: 0.0413 s/iter. Total: 1.0740 s/iter. ETA=1:26:31\n",
      "\u001b[32m[03/31 11:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 171/5000. Dataloading: 0.0029 s/iter. Inference: 1.0298 s/iter. Eval: 0.0409 s/iter. Total: 1.0738 s/iter. ETA=1:26:25\n",
      "\u001b[32m[03/31 11:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 176/5000. Dataloading: 0.0029 s/iter. Inference: 1.0296 s/iter. Eval: 0.0412 s/iter. Total: 1.0738 s/iter. ETA=1:26:19\n",
      "\u001b[32m[03/31 11:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 181/5000. Dataloading: 0.0029 s/iter. Inference: 1.0301 s/iter. Eval: 0.0417 s/iter. Total: 1.0748 s/iter. ETA=1:26:19\n",
      "\u001b[32m[03/31 11:43:12 d2.evaluation.evaluator]: \u001b[0mInference done 186/5000. Dataloading: 0.0029 s/iter. Inference: 1.0310 s/iter. Eval: 0.0420 s/iter. Total: 1.0761 s/iter. ETA=1:26:20\n",
      "\u001b[32m[03/31 11:43:17 d2.evaluation.evaluator]: \u001b[0mInference done 191/5000. Dataloading: 0.0028 s/iter. Inference: 1.0318 s/iter. Eval: 0.0422 s/iter. Total: 1.0770 s/iter. ETA=1:26:19\n",
      "\u001b[32m[03/31 11:43:22 d2.evaluation.evaluator]: \u001b[0mInference done 196/5000. Dataloading: 0.0028 s/iter. Inference: 1.0314 s/iter. Eval: 0.0419 s/iter. Total: 1.0763 s/iter. ETA=1:26:10\n",
      "\u001b[32m[03/31 11:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 201/5000. Dataloading: 0.0028 s/iter. Inference: 1.0314 s/iter. Eval: 0.0411 s/iter. Total: 1.0754 s/iter. ETA=1:26:01\n",
      "\u001b[32m[03/31 11:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 206/5000. Dataloading: 0.0028 s/iter. Inference: 1.0318 s/iter. Eval: 0.0412 s/iter. Total: 1.0759 s/iter. ETA=1:25:57\n",
      "\u001b[32m[03/31 11:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 211/5000. Dataloading: 0.0028 s/iter. Inference: 1.0315 s/iter. Eval: 0.0411 s/iter. Total: 1.0756 s/iter. ETA=1:25:51\n",
      "\u001b[32m[03/31 11:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 216/5000. Dataloading: 0.0028 s/iter. Inference: 1.0312 s/iter. Eval: 0.0407 s/iter. Total: 1.0748 s/iter. ETA=1:25:42\n",
      "\u001b[32m[03/31 11:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 221/5000. Dataloading: 0.0028 s/iter. Inference: 1.0312 s/iter. Eval: 0.0404 s/iter. Total: 1.0745 s/iter. ETA=1:25:35\n",
      "\u001b[32m[03/31 11:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 226/5000. Dataloading: 0.0028 s/iter. Inference: 1.0306 s/iter. Eval: 0.0399 s/iter. Total: 1.0735 s/iter. ETA=1:25:24\n",
      "\u001b[32m[03/31 11:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 231/5000. Dataloading: 0.0028 s/iter. Inference: 1.0309 s/iter. Eval: 0.0395 s/iter. Total: 1.0733 s/iter. ETA=1:25:18\n",
      "\u001b[32m[03/31 11:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 236/5000. Dataloading: 0.0028 s/iter. Inference: 1.0314 s/iter. Eval: 0.0394 s/iter. Total: 1.0737 s/iter. ETA=1:25:15\n",
      "\u001b[32m[03/31 11:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 241/5000. Dataloading: 0.0028 s/iter. Inference: 1.0316 s/iter. Eval: 0.0399 s/iter. Total: 1.0744 s/iter. ETA=1:25:12\n",
      "\u001b[32m[03/31 11:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 246/5000. Dataloading: 0.0028 s/iter. Inference: 1.0320 s/iter. Eval: 0.0396 s/iter. Total: 1.0746 s/iter. ETA=1:25:08\n",
      "\u001b[32m[03/31 11:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 251/5000. Dataloading: 0.0028 s/iter. Inference: 1.0320 s/iter. Eval: 0.0396 s/iter. Total: 1.0746 s/iter. ETA=1:25:03\n",
      "\u001b[32m[03/31 11:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 256/5000. Dataloading: 0.0028 s/iter. Inference: 1.0326 s/iter. Eval: 0.0403 s/iter. Total: 1.0758 s/iter. ETA=1:25:03\n",
      "\u001b[32m[03/31 11:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 261/5000. Dataloading: 0.0028 s/iter. Inference: 1.0331 s/iter. Eval: 0.0404 s/iter. Total: 1.0764 s/iter. ETA=1:25:01\n",
      "\u001b[32m[03/31 11:44:38 d2.evaluation.evaluator]: \u001b[0mInference done 266/5000. Dataloading: 0.0028 s/iter. Inference: 1.0325 s/iter. Eval: 0.0401 s/iter. Total: 1.0755 s/iter. ETA=1:24:51\n",
      "\u001b[32m[03/31 11:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 271/5000. Dataloading: 0.0028 s/iter. Inference: 1.0317 s/iter. Eval: 0.0398 s/iter. Total: 1.0745 s/iter. ETA=1:24:41\n",
      "\u001b[32m[03/31 11:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 276/5000. Dataloading: 0.0028 s/iter. Inference: 1.0319 s/iter. Eval: 0.0398 s/iter. Total: 1.0746 s/iter. ETA=1:24:36\n",
      "\u001b[32m[03/31 11:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 281/5000. Dataloading: 0.0028 s/iter. Inference: 1.0317 s/iter. Eval: 0.0397 s/iter. Total: 1.0744 s/iter. ETA=1:24:30\n",
      "\u001b[32m[03/31 11:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 286/5000. Dataloading: 0.0028 s/iter. Inference: 1.0320 s/iter. Eval: 0.0395 s/iter. Total: 1.0745 s/iter. ETA=1:24:25\n",
      "\u001b[32m[03/31 11:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 291/5000. Dataloading: 0.0028 s/iter. Inference: 1.0327 s/iter. Eval: 0.0396 s/iter. Total: 1.0752 s/iter. ETA=1:24:23\n",
      "\u001b[32m[03/31 11:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 296/5000. Dataloading: 0.0028 s/iter. Inference: 1.0325 s/iter. Eval: 0.0398 s/iter. Total: 1.0753 s/iter. ETA=1:24:18\n",
      "\u001b[32m[03/31 11:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 301/5000. Dataloading: 0.0027 s/iter. Inference: 1.0327 s/iter. Eval: 0.0396 s/iter. Total: 1.0752 s/iter. ETA=1:24:12\n",
      "\u001b[32m[03/31 11:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 306/5000. Dataloading: 0.0027 s/iter. Inference: 1.0328 s/iter. Eval: 0.0394 s/iter. Total: 1.0751 s/iter. ETA=1:24:06\n",
      "\u001b[32m[03/31 11:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 311/5000. Dataloading: 0.0027 s/iter. Inference: 1.0325 s/iter. Eval: 0.0396 s/iter. Total: 1.0750 s/iter. ETA=1:24:00\n",
      "\u001b[32m[03/31 11:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 316/5000. Dataloading: 0.0027 s/iter. Inference: 1.0328 s/iter. Eval: 0.0395 s/iter. Total: 1.0752 s/iter. ETA=1:23:56\n",
      "\u001b[32m[03/31 11:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 321/5000. Dataloading: 0.0027 s/iter. Inference: 1.0325 s/iter. Eval: 0.0395 s/iter. Total: 1.0750 s/iter. ETA=1:23:49\n",
      "\u001b[32m[03/31 11:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 326/5000. Dataloading: 0.0028 s/iter. Inference: 1.0329 s/iter. Eval: 0.0394 s/iter. Total: 1.0752 s/iter. ETA=1:23:45\n",
      "\u001b[32m[03/31 11:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 331/5000. Dataloading: 0.0028 s/iter. Inference: 1.0330 s/iter. Eval: 0.0402 s/iter. Total: 1.0761 s/iter. ETA=1:23:44\n",
      "\u001b[32m[03/31 11:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 336/5000. Dataloading: 0.0027 s/iter. Inference: 1.0333 s/iter. Eval: 0.0403 s/iter. Total: 1.0765 s/iter. ETA=1:23:40\n",
      "\u001b[32m[03/31 11:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 341/5000. Dataloading: 0.0027 s/iter. Inference: 1.0336 s/iter. Eval: 0.0404 s/iter. Total: 1.0769 s/iter. ETA=1:23:37\n",
      "\u001b[32m[03/31 11:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 346/5000. Dataloading: 0.0027 s/iter. Inference: 1.0337 s/iter. Eval: 0.0404 s/iter. Total: 1.0769 s/iter. ETA=1:23:32\n",
      "\u001b[32m[03/31 11:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 351/5000. Dataloading: 0.0027 s/iter. Inference: 1.0340 s/iter. Eval: 0.0400 s/iter. Total: 1.0769 s/iter. ETA=1:23:26\n",
      "\u001b[32m[03/31 11:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 356/5000. Dataloading: 0.0027 s/iter. Inference: 1.0344 s/iter. Eval: 0.0402 s/iter. Total: 1.0775 s/iter. ETA=1:23:23\n",
      "\u001b[32m[03/31 11:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 361/5000. Dataloading: 0.0027 s/iter. Inference: 1.0344 s/iter. Eval: 0.0401 s/iter. Total: 1.0774 s/iter. ETA=1:23:18\n",
      "\u001b[32m[03/31 11:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 366/5000. Dataloading: 0.0027 s/iter. Inference: 1.0344 s/iter. Eval: 0.0400 s/iter. Total: 1.0773 s/iter. ETA=1:23:11\n",
      "\u001b[32m[03/31 11:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 371/5000. Dataloading: 0.0027 s/iter. Inference: 1.0348 s/iter. Eval: 0.0399 s/iter. Total: 1.0776 s/iter. ETA=1:23:08\n",
      "\u001b[32m[03/31 11:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 376/5000. Dataloading: 0.0027 s/iter. Inference: 1.0348 s/iter. Eval: 0.0399 s/iter. Total: 1.0776 s/iter. ETA=1:23:02\n",
      "\u001b[32m[03/31 11:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 381/5000. Dataloading: 0.0027 s/iter. Inference: 1.0344 s/iter. Eval: 0.0395 s/iter. Total: 1.0768 s/iter. ETA=1:22:53\n",
      "\u001b[32m[03/31 11:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 386/5000. Dataloading: 0.0027 s/iter. Inference: 1.0340 s/iter. Eval: 0.0393 s/iter. Total: 1.0762 s/iter. ETA=1:22:45\n",
      "\u001b[32m[03/31 11:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 391/5000. Dataloading: 0.0028 s/iter. Inference: 1.0337 s/iter. Eval: 0.0391 s/iter. Total: 1.0757 s/iter. ETA=1:22:37\n",
      "\u001b[32m[03/31 11:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 396/5000. Dataloading: 0.0028 s/iter. Inference: 1.0337 s/iter. Eval: 0.0390 s/iter. Total: 1.0756 s/iter. ETA=1:22:32\n",
      "\u001b[32m[03/31 11:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 401/5000. Dataloading: 0.0028 s/iter. Inference: 1.0336 s/iter. Eval: 0.0388 s/iter. Total: 1.0753 s/iter. ETA=1:22:25\n",
      "\u001b[32m[03/31 11:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 406/5000. Dataloading: 0.0028 s/iter. Inference: 1.0338 s/iter. Eval: 0.0390 s/iter. Total: 1.0758 s/iter. ETA=1:22:22\n",
      "\u001b[32m[03/31 11:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 411/5000. Dataloading: 0.0028 s/iter. Inference: 1.0335 s/iter. Eval: 0.0389 s/iter. Total: 1.0753 s/iter. ETA=1:22:14\n",
      "\u001b[32m[03/31 11:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 416/5000. Dataloading: 0.0028 s/iter. Inference: 1.0337 s/iter. Eval: 0.0388 s/iter. Total: 1.0754 s/iter. ETA=1:22:09\n",
      "\u001b[32m[03/31 11:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 421/5000. Dataloading: 0.0028 s/iter. Inference: 1.0334 s/iter. Eval: 0.0387 s/iter. Total: 1.0751 s/iter. ETA=1:22:02\n",
      "\u001b[32m[03/31 11:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 426/5000. Dataloading: 0.0028 s/iter. Inference: 1.0332 s/iter. Eval: 0.0386 s/iter. Total: 1.0747 s/iter. ETA=1:21:55\n",
      "\u001b[32m[03/31 11:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 431/5000. Dataloading: 0.0028 s/iter. Inference: 1.0335 s/iter. Eval: 0.0386 s/iter. Total: 1.0750 s/iter. ETA=1:21:51\n",
      "\u001b[32m[03/31 11:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 436/5000. Dataloading: 0.0028 s/iter. Inference: 1.0337 s/iter. Eval: 0.0385 s/iter. Total: 1.0751 s/iter. ETA=1:21:46\n",
      "\u001b[32m[03/31 11:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 441/5000. Dataloading: 0.0028 s/iter. Inference: 1.0340 s/iter. Eval: 0.0385 s/iter. Total: 1.0754 s/iter. ETA=1:21:42\n",
      "\u001b[32m[03/31 11:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 446/5000. Dataloading: 0.0028 s/iter. Inference: 1.0342 s/iter. Eval: 0.0384 s/iter. Total: 1.0755 s/iter. ETA=1:21:37\n",
      "\u001b[32m[03/31 11:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 451/5000. Dataloading: 0.0028 s/iter. Inference: 1.0337 s/iter. Eval: 0.0386 s/iter. Total: 1.0752 s/iter. ETA=1:21:30\n",
      "\u001b[32m[03/31 11:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 456/5000. Dataloading: 0.0028 s/iter. Inference: 1.0339 s/iter. Eval: 0.0384 s/iter. Total: 1.0752 s/iter. ETA=1:21:25\n",
      "\u001b[32m[03/31 11:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 461/5000. Dataloading: 0.0028 s/iter. Inference: 1.0339 s/iter. Eval: 0.0382 s/iter. Total: 1.0750 s/iter. ETA=1:21:19\n",
      "\u001b[32m[03/31 11:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 466/5000. Dataloading: 0.0028 s/iter. Inference: 1.0340 s/iter. Eval: 0.0381 s/iter. Total: 1.0750 s/iter. ETA=1:21:14\n",
      "\u001b[32m[03/31 11:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 471/5000. Dataloading: 0.0028 s/iter. Inference: 1.0343 s/iter. Eval: 0.0378 s/iter. Total: 1.0750 s/iter. ETA=1:21:08\n",
      "\u001b[32m[03/31 11:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 476/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0378 s/iter. Total: 1.0754 s/iter. ETA=1:21:05\n",
      "\u001b[32m[03/31 11:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 481/5000. Dataloading: 0.0028 s/iter. Inference: 1.0348 s/iter. Eval: 0.0377 s/iter. Total: 1.0754 s/iter. ETA=1:20:59\n",
      "\u001b[32m[03/31 11:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 486/5000. Dataloading: 0.0027 s/iter. Inference: 1.0350 s/iter. Eval: 0.0380 s/iter. Total: 1.0758 s/iter. ETA=1:20:56\n",
      "\u001b[32m[03/31 11:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 491/5000. Dataloading: 0.0027 s/iter. Inference: 1.0352 s/iter. Eval: 0.0381 s/iter. Total: 1.0761 s/iter. ETA=1:20:52\n",
      "\u001b[32m[03/31 11:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 496/5000. Dataloading: 0.0028 s/iter. Inference: 1.0351 s/iter. Eval: 0.0381 s/iter. Total: 1.0762 s/iter. ETA=1:20:47\n",
      "\u001b[32m[03/31 11:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 501/5000. Dataloading: 0.0028 s/iter. Inference: 1.0348 s/iter. Eval: 0.0382 s/iter. Total: 1.0759 s/iter. ETA=1:20:40\n",
      "\u001b[32m[03/31 11:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 506/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0382 s/iter. Total: 1.0758 s/iter. ETA=1:20:34\n",
      "\u001b[32m[03/31 11:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 511/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0382 s/iter. Total: 1.0758 s/iter. ETA=1:20:29\n",
      "\u001b[32m[03/31 11:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 516/5000. Dataloading: 0.0028 s/iter. Inference: 1.0344 s/iter. Eval: 0.0382 s/iter. Total: 1.0755 s/iter. ETA=1:20:22\n",
      "\u001b[32m[03/31 11:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 521/5000. Dataloading: 0.0028 s/iter. Inference: 1.0344 s/iter. Eval: 0.0382 s/iter. Total: 1.0755 s/iter. ETA=1:20:17\n",
      "\u001b[32m[03/31 11:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 526/5000. Dataloading: 0.0028 s/iter. Inference: 1.0346 s/iter. Eval: 0.0383 s/iter. Total: 1.0758 s/iter. ETA=1:20:13\n",
      "\u001b[32m[03/31 11:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 531/5000. Dataloading: 0.0028 s/iter. Inference: 1.0346 s/iter. Eval: 0.0382 s/iter. Total: 1.0758 s/iter. ETA=1:20:07\n",
      "\u001b[32m[03/31 11:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 536/5000. Dataloading: 0.0028 s/iter. Inference: 1.0346 s/iter. Eval: 0.0382 s/iter. Total: 1.0757 s/iter. ETA=1:20:02\n",
      "\u001b[32m[03/31 11:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 541/5000. Dataloading: 0.0028 s/iter. Inference: 1.0349 s/iter. Eval: 0.0384 s/iter. Total: 1.0762 s/iter. ETA=1:19:58\n",
      "\u001b[32m[03/31 11:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 546/5000. Dataloading: 0.0028 s/iter. Inference: 1.0349 s/iter. Eval: 0.0385 s/iter. Total: 1.0763 s/iter. ETA=1:19:53\n",
      "\u001b[32m[03/31 11:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 551/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0384 s/iter. Total: 1.0760 s/iter. ETA=1:19:47\n",
      "\u001b[32m[03/31 11:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 556/5000. Dataloading: 0.0028 s/iter. Inference: 1.0348 s/iter. Eval: 0.0385 s/iter. Total: 1.0762 s/iter. ETA=1:19:42\n",
      "\u001b[32m[03/31 11:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 561/5000. Dataloading: 0.0027 s/iter. Inference: 1.0347 s/iter. Eval: 0.0387 s/iter. Total: 1.0763 s/iter. ETA=1:19:37\n",
      "\u001b[32m[03/31 11:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 566/5000. Dataloading: 0.0027 s/iter. Inference: 1.0348 s/iter. Eval: 0.0386 s/iter. Total: 1.0763 s/iter. ETA=1:19:32\n",
      "\u001b[32m[03/31 11:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 571/5000. Dataloading: 0.0027 s/iter. Inference: 1.0348 s/iter. Eval: 0.0385 s/iter. Total: 1.0761 s/iter. ETA=1:19:26\n",
      "\u001b[32m[03/31 11:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 576/5000. Dataloading: 0.0028 s/iter. Inference: 1.0351 s/iter. Eval: 0.0385 s/iter. Total: 1.0765 s/iter. ETA=1:19:22\n",
      "\u001b[32m[03/31 11:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 581/5000. Dataloading: 0.0028 s/iter. Inference: 1.0351 s/iter. Eval: 0.0387 s/iter. Total: 1.0766 s/iter. ETA=1:19:17\n",
      "\u001b[32m[03/31 11:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 586/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0389 s/iter. Total: 1.0765 s/iter. ETA=1:19:11\n",
      "\u001b[32m[03/31 11:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 591/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0389 s/iter. Total: 1.0766 s/iter. ETA=1:19:06\n",
      "\u001b[32m[03/31 11:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 596/5000. Dataloading: 0.0027 s/iter. Inference: 1.0348 s/iter. Eval: 0.0389 s/iter. Total: 1.0765 s/iter. ETA=1:19:01\n",
      "\u001b[32m[03/31 11:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 601/5000. Dataloading: 0.0028 s/iter. Inference: 1.0348 s/iter. Eval: 0.0388 s/iter. Total: 1.0765 s/iter. ETA=1:18:55\n",
      "\u001b[32m[03/31 11:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 606/5000. Dataloading: 0.0028 s/iter. Inference: 1.0347 s/iter. Eval: 0.0387 s/iter. Total: 1.0763 s/iter. ETA=1:18:49\n",
      "\u001b[32m[03/31 11:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 611/5000. Dataloading: 0.0027 s/iter. Inference: 1.0350 s/iter. Eval: 0.0387 s/iter. Total: 1.0766 s/iter. ETA=1:18:45\n",
      "\u001b[32m[03/31 11:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 616/5000. Dataloading: 0.0028 s/iter. Inference: 1.0351 s/iter. Eval: 0.0387 s/iter. Total: 1.0767 s/iter. ETA=1:18:40\n",
      "\u001b[32m[03/31 11:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 621/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0389 s/iter. Total: 1.0771 s/iter. ETA=1:18:36\n",
      "\u001b[32m[03/31 11:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 626/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0388 s/iter. Total: 1.0770 s/iter. ETA=1:18:30\n",
      "\u001b[32m[03/31 11:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 631/5000. Dataloading: 0.0027 s/iter. Inference: 1.0352 s/iter. Eval: 0.0388 s/iter. Total: 1.0768 s/iter. ETA=1:18:24\n",
      "\u001b[32m[03/31 11:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 636/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0388 s/iter. Total: 1.0771 s/iter. ETA=1:18:20\n",
      "\u001b[32m[03/31 11:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 641/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0390 s/iter. Total: 1.0772 s/iter. ETA=1:18:15\n",
      "\u001b[32m[03/31 11:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 646/5000. Dataloading: 0.0027 s/iter. Inference: 1.0353 s/iter. Eval: 0.0391 s/iter. Total: 1.0773 s/iter. ETA=1:18:10\n",
      "\u001b[32m[03/31 11:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 651/5000. Dataloading: 0.0027 s/iter. Inference: 1.0352 s/iter. Eval: 0.0390 s/iter. Total: 1.0771 s/iter. ETA=1:18:04\n",
      "\u001b[32m[03/31 11:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 656/5000. Dataloading: 0.0027 s/iter. Inference: 1.0352 s/iter. Eval: 0.0392 s/iter. Total: 1.0773 s/iter. ETA=1:17:59\n",
      "\u001b[32m[03/31 11:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 661/5000. Dataloading: 0.0027 s/iter. Inference: 1.0352 s/iter. Eval: 0.0392 s/iter. Total: 1.0772 s/iter. ETA=1:17:54\n",
      "\u001b[32m[03/31 11:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 666/5000. Dataloading: 0.0027 s/iter. Inference: 1.0351 s/iter. Eval: 0.0393 s/iter. Total: 1.0773 s/iter. ETA=1:17:48\n",
      "\u001b[32m[03/31 11:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 671/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0392 s/iter. Total: 1.0775 s/iter. ETA=1:17:44\n",
      "\u001b[32m[03/31 11:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 676/5000. Dataloading: 0.0027 s/iter. Inference: 1.0353 s/iter. Eval: 0.0391 s/iter. Total: 1.0773 s/iter. ETA=1:17:38\n",
      "\u001b[32m[03/31 11:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 681/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0391 s/iter. Total: 1.0774 s/iter. ETA=1:17:33\n",
      "\u001b[32m[03/31 11:52:10 d2.evaluation.evaluator]: \u001b[0mInference done 686/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0390 s/iter. Total: 1.0773 s/iter. ETA=1:17:27\n",
      "\u001b[32m[03/31 11:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 691/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0389 s/iter. Total: 1.0772 s/iter. ETA=1:17:21\n",
      "\u001b[32m[03/31 11:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 696/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0390 s/iter. Total: 1.0773 s/iter. ETA=1:17:16\n",
      "\u001b[32m[03/31 11:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 701/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0390 s/iter. Total: 1.0773 s/iter. ETA=1:17:11\n",
      "\u001b[32m[03/31 11:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 706/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0390 s/iter. Total: 1.0774 s/iter. ETA=1:17:06\n",
      "\u001b[32m[03/31 11:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 711/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0390 s/iter. Total: 1.0775 s/iter. ETA=1:17:01\n",
      "\u001b[32m[03/31 11:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 716/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0390 s/iter. Total: 1.0776 s/iter. ETA=1:16:56\n",
      "\u001b[32m[03/31 11:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 721/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0391 s/iter. Total: 1.0780 s/iter. ETA=1:16:52\n",
      "\u001b[32m[03/31 11:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 726/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0392 s/iter. Total: 1.0779 s/iter. ETA=1:16:47\n",
      "\u001b[32m[03/31 11:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 731/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0393 s/iter. Total: 1.0781 s/iter. ETA=1:16:42\n",
      "\u001b[32m[03/31 11:53:05 d2.evaluation.evaluator]: \u001b[0mInference done 736/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0392 s/iter. Total: 1.0779 s/iter. ETA=1:16:36\n",
      "\u001b[32m[03/31 11:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 741/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0392 s/iter. Total: 1.0780 s/iter. ETA=1:16:31\n",
      "\u001b[32m[03/31 11:53:16 d2.evaluation.evaluator]: \u001b[0mInference done 746/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0392 s/iter. Total: 1.0779 s/iter. ETA=1:16:25\n",
      "\u001b[32m[03/31 11:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 751/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0393 s/iter. Total: 1.0781 s/iter. ETA=1:16:20\n",
      "\u001b[32m[03/31 11:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 756/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0392 s/iter. Total: 1.0781 s/iter. ETA=1:16:15\n",
      "\u001b[32m[03/31 11:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 761/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0392 s/iter. Total: 1.0779 s/iter. ETA=1:16:09\n",
      "\u001b[32m[03/31 11:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 766/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0391 s/iter. Total: 1.0778 s/iter. ETA=1:16:03\n",
      "\u001b[32m[03/31 11:53:43 d2.evaluation.evaluator]: \u001b[0mInference done 771/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0392 s/iter. Total: 1.0779 s/iter. ETA=1:15:58\n",
      "\u001b[32m[03/31 11:53:48 d2.evaluation.evaluator]: \u001b[0mInference done 776/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0390 s/iter. Total: 1.0777 s/iter. ETA=1:15:52\n",
      "\u001b[32m[03/31 11:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 781/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0389 s/iter. Total: 1.0777 s/iter. ETA=1:15:46\n",
      "\u001b[32m[03/31 11:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 786/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0779 s/iter. ETA=1:15:42\n",
      "\u001b[32m[03/31 11:54:04 d2.evaluation.evaluator]: \u001b[0mInference done 791/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0391 s/iter. Total: 1.0780 s/iter. ETA=1:15:37\n",
      "\u001b[32m[03/31 11:54:09 d2.evaluation.evaluator]: \u001b[0mInference done 796/5000. Dataloading: 0.0027 s/iter. Inference: 1.0360 s/iter. Eval: 0.0391 s/iter. Total: 1.0779 s/iter. ETA=1:15:31\n",
      "\u001b[32m[03/31 11:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 801/5000. Dataloading: 0.0027 s/iter. Inference: 1.0360 s/iter. Eval: 0.0391 s/iter. Total: 1.0780 s/iter. ETA=1:15:26\n",
      "\u001b[32m[03/31 11:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 806/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0391 s/iter. Total: 1.0782 s/iter. ETA=1:15:22\n",
      "\u001b[32m[03/31 11:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 811/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0391 s/iter. Total: 1.0780 s/iter. ETA=1:15:15\n",
      "\u001b[32m[03/31 11:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 816/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0390 s/iter. Total: 1.0781 s/iter. ETA=1:15:10\n",
      "\u001b[32m[03/31 11:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 821/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0389 s/iter. Total: 1.0780 s/iter. ETA=1:15:05\n",
      "\u001b[32m[03/31 11:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 826/5000. Dataloading: 0.0027 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0778 s/iter. ETA=1:14:58\n",
      "\u001b[32m[03/31 11:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 831/5000. Dataloading: 0.0027 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:14:52\n",
      "\u001b[32m[03/31 11:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 836/5000. Dataloading: 0.0027 s/iter. Inference: 1.0359 s/iter. Eval: 0.0389 s/iter. Total: 1.0777 s/iter. ETA=1:14:47\n",
      "\u001b[32m[03/31 11:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 841/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0389 s/iter. Total: 1.0777 s/iter. ETA=1:14:41\n",
      "\u001b[32m[03/31 11:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 846/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0389 s/iter. Total: 1.0777 s/iter. ETA=1:14:36\n",
      "\u001b[32m[03/31 11:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 851/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0390 s/iter. Total: 1.0778 s/iter. ETA=1:14:31\n",
      "\u001b[32m[03/31 11:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 856/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0390 s/iter. Total: 1.0779 s/iter. ETA=1:14:26\n",
      "\u001b[32m[03/31 11:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 861/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0390 s/iter. Total: 1.0779 s/iter. ETA=1:14:21\n",
      "\u001b[32m[03/31 11:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 866/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0778 s/iter. ETA=1:14:15\n",
      "\u001b[32m[03/31 11:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 871/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0388 s/iter. Total: 1.0777 s/iter. ETA=1:14:09\n",
      "\u001b[32m[03/31 11:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 876/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:14:03\n",
      "\u001b[32m[03/31 11:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 881/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0387 s/iter. Total: 1.0774 s/iter. ETA=1:13:57\n",
      "\u001b[32m[03/31 11:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 886/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=1:13:52\n",
      "\u001b[32m[03/31 11:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 891/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0386 s/iter. Total: 1.0774 s/iter. ETA=1:13:47\n",
      "\u001b[32m[03/31 11:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 896/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0387 s/iter. Total: 1.0777 s/iter. ETA=1:13:42\n",
      "\u001b[32m[03/31 11:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 901/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0387 s/iter. Total: 1.0777 s/iter. ETA=1:13:37\n",
      "\u001b[32m[03/31 11:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 906/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0386 s/iter. Total: 1.0776 s/iter. ETA=1:13:31\n",
      "\u001b[32m[03/31 11:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 911/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=1:13:25\n",
      "\u001b[32m[03/31 11:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 916/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=1:13:19\n",
      "\u001b[32m[03/31 11:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 921/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0385 s/iter. Total: 1.0773 s/iter. ETA=1:13:14\n",
      "\u001b[32m[03/31 11:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 926/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=1:13:08\n",
      "\u001b[32m[03/31 11:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 931/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0385 s/iter. Total: 1.0773 s/iter. ETA=1:13:03\n",
      "\u001b[32m[03/31 11:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 936/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0384 s/iter. Total: 1.0773 s/iter. ETA=1:12:58\n",
      "\u001b[32m[03/31 11:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 941/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0384 s/iter. Total: 1.0771 s/iter. ETA=1:12:52\n",
      "\u001b[32m[03/31 11:56:51 d2.evaluation.evaluator]: \u001b[0mInference done 946/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0383 s/iter. Total: 1.0772 s/iter. ETA=1:12:47\n",
      "\u001b[32m[03/31 11:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 951/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0384 s/iter. Total: 1.0773 s/iter. ETA=1:12:41\n",
      "\u001b[32m[03/31 11:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 956/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0383 s/iter. Total: 1.0773 s/iter. ETA=1:12:36\n",
      "\u001b[32m[03/31 11:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 961/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0384 s/iter. Total: 1.0773 s/iter. ETA=1:12:31\n",
      "\u001b[32m[03/31 11:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 966/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0383 s/iter. Total: 1.0774 s/iter. ETA=1:12:26\n",
      "\u001b[32m[03/31 11:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 971/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0384 s/iter. Total: 1.0775 s/iter. ETA=1:12:21\n",
      "\u001b[32m[03/31 11:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 976/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0385 s/iter. Total: 1.0776 s/iter. ETA=1:12:16\n",
      "\u001b[32m[03/31 11:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 981/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0385 s/iter. Total: 1.0776 s/iter. ETA=1:12:10\n",
      "\u001b[32m[03/31 11:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 986/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0385 s/iter. Total: 1.0777 s/iter. ETA=1:12:05\n",
      "\u001b[32m[03/31 11:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 991/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0385 s/iter. Total: 1.0778 s/iter. ETA=1:12:00\n",
      "\u001b[32m[03/31 11:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 996/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0384 s/iter. Total: 1.0776 s/iter. ETA=1:11:54\n",
      "\u001b[32m[03/31 11:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 1001/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0383 s/iter. Total: 1.0775 s/iter. ETA=1:11:48\n",
      "\u001b[32m[03/31 11:57:56 d2.evaluation.evaluator]: \u001b[0mInference done 1006/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0384 s/iter. Total: 1.0776 s/iter. ETA=1:11:44\n",
      "\u001b[32m[03/31 11:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 1011/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0383 s/iter. Total: 1.0775 s/iter. ETA=1:11:38\n",
      "\u001b[32m[03/31 11:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 1016/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0383 s/iter. Total: 1.0774 s/iter. ETA=1:11:32\n",
      "\u001b[32m[03/31 11:58:12 d2.evaluation.evaluator]: \u001b[0mInference done 1021/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0385 s/iter. Total: 1.0776 s/iter. ETA=1:11:27\n",
      "\u001b[32m[03/31 11:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 1026/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0385 s/iter. Total: 1.0776 s/iter. ETA=1:11:22\n",
      "\u001b[32m[03/31 11:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 1031/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0384 s/iter. Total: 1.0774 s/iter. ETA=1:11:16\n",
      "\u001b[32m[03/31 11:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 1036/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0385 s/iter. Total: 1.0776 s/iter. ETA=1:11:11\n",
      "\u001b[32m[03/31 11:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 1041/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0385 s/iter. Total: 1.0776 s/iter. ETA=1:11:06\n",
      "\u001b[32m[03/31 11:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 1046/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0386 s/iter. Total: 1.0777 s/iter. ETA=1:11:01\n",
      "\u001b[32m[03/31 11:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 1051/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0385 s/iter. Total: 1.0777 s/iter. ETA=1:10:55\n",
      "\u001b[32m[03/31 11:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 1056/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0385 s/iter. Total: 1.0777 s/iter. ETA=1:10:50\n",
      "\u001b[32m[03/31 11:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 1061/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0384 s/iter. Total: 1.0777 s/iter. ETA=1:10:45\n",
      "\u001b[32m[03/31 11:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 1066/5000. Dataloading: 0.0028 s/iter. Inference: 1.0365 s/iter. Eval: 0.0385 s/iter. Total: 1.0779 s/iter. ETA=1:10:40\n",
      "\u001b[32m[03/31 11:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 1071/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:10:36\n",
      "\u001b[32m[03/31 11:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 1076/5000. Dataloading: 0.0028 s/iter. Inference: 1.0366 s/iter. Eval: 0.0385 s/iter. Total: 1.0781 s/iter. ETA=1:10:30\n",
      "\u001b[32m[03/31 11:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 1081/5000. Dataloading: 0.0028 s/iter. Inference: 1.0366 s/iter. Eval: 0.0384 s/iter. Total: 1.0780 s/iter. ETA=1:10:24\n",
      "\u001b[32m[03/31 11:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 1086/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:10:19\n",
      "\u001b[32m[03/31 11:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 1091/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:10:14\n",
      "\u001b[32m[03/31 11:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 1096/5000. Dataloading: 0.0028 s/iter. Inference: 1.0366 s/iter. Eval: 0.0385 s/iter. Total: 1.0780 s/iter. ETA=1:10:08\n",
      "\u001b[32m[03/31 11:59:38 d2.evaluation.evaluator]: \u001b[0mInference done 1101/5000. Dataloading: 0.0028 s/iter. Inference: 1.0366 s/iter. Eval: 0.0385 s/iter. Total: 1.0781 s/iter. ETA=1:10:03\n",
      "\u001b[32m[03/31 11:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 1106/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0384 s/iter. Total: 1.0780 s/iter. ETA=1:09:57\n",
      "\u001b[32m[03/31 11:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 1111/5000. Dataloading: 0.0028 s/iter. Inference: 1.0368 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:09:53\n",
      "\u001b[32m[03/31 11:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 1116/5000. Dataloading: 0.0028 s/iter. Inference: 1.0368 s/iter. Eval: 0.0384 s/iter. Total: 1.0781 s/iter. ETA=1:09:47\n",
      "\u001b[32m[03/31 12:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 1121/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0384 s/iter. Total: 1.0780 s/iter. ETA=1:09:41\n",
      "\u001b[32m[03/31 12:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 1126/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0384 s/iter. Total: 1.0781 s/iter. ETA=1:09:36\n",
      "\u001b[32m[03/31 12:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 1131/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0384 s/iter. Total: 1.0782 s/iter. ETA=1:09:31\n",
      "\u001b[32m[03/31 12:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 1136/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0384 s/iter. Total: 1.0783 s/iter. ETA=1:09:26\n",
      "\u001b[32m[03/31 12:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 1141/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0384 s/iter. Total: 1.0783 s/iter. ETA=1:09:21\n",
      "\u001b[32m[03/31 12:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 1146/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0383 s/iter. Total: 1.0782 s/iter. ETA=1:09:15\n",
      "\u001b[32m[03/31 12:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 1151/5000. Dataloading: 0.0028 s/iter. Inference: 1.0368 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:09:10\n",
      "\u001b[32m[03/31 12:00:38 d2.evaluation.evaluator]: \u001b[0mInference done 1156/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0384 s/iter. Total: 1.0782 s/iter. ETA=1:09:04\n",
      "\u001b[32m[03/31 12:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 1161/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0384 s/iter. Total: 1.0782 s/iter. ETA=1:08:59\n",
      "\u001b[32m[03/31 12:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 1166/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0384 s/iter. Total: 1.0785 s/iter. ETA=1:08:54\n",
      "\u001b[32m[03/31 12:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0385 s/iter. Total: 1.0786 s/iter. ETA=1:08:49\n",
      "\u001b[32m[03/31 12:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 1176/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0384 s/iter. Total: 1.0785 s/iter. ETA=1:08:44\n",
      "\u001b[32m[03/31 12:01:05 d2.evaluation.evaluator]: \u001b[0mInference done 1181/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0384 s/iter. Total: 1.0784 s/iter. ETA=1:08:38\n",
      "\u001b[32m[03/31 12:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 1186/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0384 s/iter. Total: 1.0785 s/iter. ETA=1:08:33\n",
      "\u001b[32m[03/31 12:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 1191/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0384 s/iter. Total: 1.0785 s/iter. ETA=1:08:27\n",
      "\u001b[32m[03/31 12:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 1196/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0384 s/iter. Total: 1.0784 s/iter. ETA=1:08:22\n",
      "\u001b[32m[03/31 12:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 1201/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0384 s/iter. Total: 1.0785 s/iter. ETA=1:08:17\n",
      "\u001b[32m[03/31 12:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 1206/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0385 s/iter. Total: 1.0786 s/iter. ETA=1:08:12\n",
      "\u001b[32m[03/31 12:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 1211/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0386 s/iter. Total: 1.0788 s/iter. ETA=1:08:07\n",
      "\u001b[32m[03/31 12:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 1216/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0387 s/iter. Total: 1.0788 s/iter. ETA=1:08:02\n",
      "\u001b[32m[03/31 12:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 1221/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0387 s/iter. Total: 1.0788 s/iter. ETA=1:07:56\n",
      "\u001b[32m[03/31 12:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 1226/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0387 s/iter. Total: 1.0789 s/iter. ETA=1:07:51\n",
      "\u001b[32m[03/31 12:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 1231/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0387 s/iter. Total: 1.0789 s/iter. ETA=1:07:46\n",
      "\u001b[32m[03/31 12:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 1236/5000. Dataloading: 0.0028 s/iter. Inference: 1.0374 s/iter. Eval: 0.0387 s/iter. Total: 1.0791 s/iter. ETA=1:07:41\n",
      "\u001b[32m[03/31 12:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 1241/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0388 s/iter. Total: 1.0790 s/iter. ETA=1:07:36\n",
      "\u001b[32m[03/31 12:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 1246/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0388 s/iter. Total: 1.0791 s/iter. ETA=1:07:30\n",
      "\u001b[32m[03/31 12:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 1251/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0388 s/iter. Total: 1.0790 s/iter. ETA=1:07:25\n",
      "\u001b[32m[03/31 12:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 1256/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0388 s/iter. Total: 1.0790 s/iter. ETA=1:07:19\n",
      "\u001b[32m[03/31 12:02:32 d2.evaluation.evaluator]: \u001b[0mInference done 1261/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0388 s/iter. Total: 1.0790 s/iter. ETA=1:07:14\n",
      "\u001b[32m[03/31 12:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 1266/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0388 s/iter. Total: 1.0788 s/iter. ETA=1:07:08\n",
      "\u001b[32m[03/31 12:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 1271/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0388 s/iter. Total: 1.0788 s/iter. ETA=1:07:02\n",
      "\u001b[32m[03/31 12:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 1276/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0388 s/iter. Total: 1.0789 s/iter. ETA=1:06:57\n",
      "\u001b[32m[03/31 12:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 1281/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0388 s/iter. Total: 1.0790 s/iter. ETA=1:06:52\n",
      "\u001b[32m[03/31 12:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 1286/5000. Dataloading: 0.0028 s/iter. Inference: 1.0373 s/iter. Eval: 0.0388 s/iter. Total: 1.0791 s/iter. ETA=1:06:47\n",
      "\u001b[32m[03/31 12:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 1291/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0387 s/iter. Total: 1.0789 s/iter. ETA=1:06:41\n",
      "\u001b[32m[03/31 12:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 1296/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0387 s/iter. Total: 1.0788 s/iter. ETA=1:06:35\n",
      "\u001b[32m[03/31 12:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 1301/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0387 s/iter. Total: 1.0788 s/iter. ETA=1:06:30\n",
      "\u001b[32m[03/31 12:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 1306/5000. Dataloading: 0.0028 s/iter. Inference: 1.0372 s/iter. Eval: 0.0387 s/iter. Total: 1.0788 s/iter. ETA=1:06:25\n",
      "\u001b[32m[03/31 12:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 1311/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0387 s/iter. Total: 1.0787 s/iter. ETA=1:06:19\n",
      "\u001b[32m[03/31 12:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 1316/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0387 s/iter. Total: 1.0787 s/iter. ETA=1:06:13\n",
      "\u001b[32m[03/31 12:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 1321/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0386 s/iter. Total: 1.0785 s/iter. ETA=1:06:07\n",
      "\u001b[32m[03/31 12:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 1326/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0385 s/iter. Total: 1.0784 s/iter. ETA=1:06:01\n",
      "\u001b[32m[03/31 12:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 1331/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0386 s/iter. Total: 1.0785 s/iter. ETA=1:05:57\n",
      "\u001b[32m[03/31 12:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 1336/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0386 s/iter. Total: 1.0786 s/iter. ETA=1:05:52\n",
      "\u001b[32m[03/31 12:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 1341/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0386 s/iter. Total: 1.0786 s/iter. ETA=1:05:46\n",
      "\u001b[32m[03/31 12:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 1346/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0387 s/iter. Total: 1.0787 s/iter. ETA=1:05:41\n",
      "\u001b[32m[03/31 12:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 1351/5000. Dataloading: 0.0028 s/iter. Inference: 1.0371 s/iter. Eval: 0.0387 s/iter. Total: 1.0787 s/iter. ETA=1:05:36\n",
      "\u001b[32m[03/31 12:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 1356/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0387 s/iter. Total: 1.0786 s/iter. ETA=1:05:30\n",
      "\u001b[32m[03/31 12:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 1361/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0386 s/iter. Total: 1.0785 s/iter. ETA=1:05:24\n",
      "\u001b[32m[03/31 12:04:25 d2.evaluation.evaluator]: \u001b[0mInference done 1366/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0386 s/iter. Total: 1.0786 s/iter. ETA=1:05:19\n",
      "\u001b[32m[03/31 12:04:30 d2.evaluation.evaluator]: \u001b[0mInference done 1371/5000. Dataloading: 0.0028 s/iter. Inference: 1.0370 s/iter. Eval: 0.0386 s/iter. Total: 1.0785 s/iter. ETA=1:05:14\n",
      "\u001b[32m[03/31 12:04:35 d2.evaluation.evaluator]: \u001b[0mInference done 1376/5000. Dataloading: 0.0028 s/iter. Inference: 1.0368 s/iter. Eval: 0.0386 s/iter. Total: 1.0784 s/iter. ETA=1:05:08\n",
      "\u001b[32m[03/31 12:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 1381/5000. Dataloading: 0.0028 s/iter. Inference: 1.0369 s/iter. Eval: 0.0386 s/iter. Total: 1.0784 s/iter. ETA=1:05:02\n",
      "\u001b[32m[03/31 12:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 1386/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0386 s/iter. Total: 1.0783 s/iter. ETA=1:04:56\n",
      "\u001b[32m[03/31 12:04:51 d2.evaluation.evaluator]: \u001b[0mInference done 1391/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0386 s/iter. Total: 1.0781 s/iter. ETA=1:04:50\n",
      "\u001b[32m[03/31 12:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 1396/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0386 s/iter. Total: 1.0782 s/iter. ETA=1:04:45\n",
      "\u001b[32m[03/31 12:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 1401/5000. Dataloading: 0.0028 s/iter. Inference: 1.0367 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:04:40\n",
      "\u001b[32m[03/31 12:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 1406/5000. Dataloading: 0.0028 s/iter. Inference: 1.0368 s/iter. Eval: 0.0385 s/iter. Total: 1.0782 s/iter. ETA=1:04:35\n",
      "\u001b[32m[03/31 12:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 1411/5000. Dataloading: 0.0028 s/iter. Inference: 1.0366 s/iter. Eval: 0.0385 s/iter. Total: 1.0779 s/iter. ETA=1:04:28\n",
      "\u001b[32m[03/31 12:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 1416/5000. Dataloading: 0.0028 s/iter. Inference: 1.0366 s/iter. Eval: 0.0384 s/iter. Total: 1.0780 s/iter. ETA=1:04:23\n",
      "\u001b[32m[03/31 12:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 1421/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0384 s/iter. Total: 1.0778 s/iter. ETA=1:04:17\n",
      "\u001b[32m[03/31 12:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 1426/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0385 s/iter. Total: 1.0778 s/iter. ETA=1:04:12\n",
      "\u001b[32m[03/31 12:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 1431/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0385 s/iter. Total: 1.0778 s/iter. ETA=1:04:06\n",
      "\u001b[32m[03/31 12:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 1436/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0385 s/iter. Total: 1.0778 s/iter. ETA=1:04:01\n",
      "\u001b[32m[03/31 12:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 1441/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0385 s/iter. Total: 1.0778 s/iter. ETA=1:03:55\n",
      "\u001b[32m[03/31 12:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 1446/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0384 s/iter. Total: 1.0778 s/iter. ETA=1:03:50\n",
      "\u001b[32m[03/31 12:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 1451/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0384 s/iter. Total: 1.0777 s/iter. ETA=1:03:44\n",
      "\u001b[32m[03/31 12:06:01 d2.evaluation.evaluator]: \u001b[0mInference done 1456/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0383 s/iter. Total: 1.0776 s/iter. ETA=1:03:39\n",
      "\u001b[32m[03/31 12:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 1461/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0384 s/iter. Total: 1.0776 s/iter. ETA=1:03:33\n",
      "\u001b[32m[03/31 12:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 1466/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0384 s/iter. Total: 1.0774 s/iter. ETA=1:03:27\n",
      "\u001b[32m[03/31 12:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 1471/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0384 s/iter. Total: 1.0774 s/iter. ETA=1:03:21\n",
      "\u001b[32m[03/31 12:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 1476/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0384 s/iter. Total: 1.0773 s/iter. ETA=1:03:16\n",
      "\u001b[32m[03/31 12:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 1481/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0385 s/iter. Total: 1.0775 s/iter. ETA=1:03:11\n",
      "\u001b[32m[03/31 12:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 1486/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0384 s/iter. Total: 1.0774 s/iter. ETA=1:03:06\n",
      "\u001b[32m[03/31 12:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 1491/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0384 s/iter. Total: 1.0774 s/iter. ETA=1:03:00\n",
      "\u001b[32m[03/31 12:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 1496/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0385 s/iter. Total: 1.0775 s/iter. ETA=1:02:55\n",
      "\u001b[32m[03/31 12:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 1501/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0385 s/iter. Total: 1.0775 s/iter. ETA=1:02:50\n",
      "\u001b[32m[03/31 12:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 1506/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0386 s/iter. Total: 1.0775 s/iter. ETA=1:02:44\n",
      "\u001b[32m[03/31 12:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 1511/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0385 s/iter. Total: 1.0773 s/iter. ETA=1:02:38\n",
      "\u001b[32m[03/31 12:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 1516/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0772 s/iter. ETA=1:02:32\n",
      "\u001b[32m[03/31 12:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 1521/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0386 s/iter. Total: 1.0772 s/iter. ETA=1:02:27\n",
      "\u001b[32m[03/31 12:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 1526/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0385 s/iter. Total: 1.0771 s/iter. ETA=1:02:21\n",
      "\u001b[32m[03/31 12:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 1531/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0385 s/iter. Total: 1.0771 s/iter. ETA=1:02:16\n",
      "\u001b[32m[03/31 12:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 1536/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0386 s/iter. Total: 1.0772 s/iter. ETA=1:02:11\n",
      "\u001b[32m[03/31 12:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 1541/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=1:02:06\n",
      "\u001b[32m[03/31 12:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 1546/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=1:02:01\n",
      "\u001b[32m[03/31 12:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 1551/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0774 s/iter. ETA=1:01:55\n",
      "\u001b[32m[03/31 12:07:48 d2.evaluation.evaluator]: \u001b[0mInference done 1556/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=1:01:50\n",
      "\u001b[32m[03/31 12:07:53 d2.evaluation.evaluator]: \u001b[0mInference done 1561/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0388 s/iter. Total: 1.0775 s/iter. ETA=1:01:45\n",
      "\u001b[32m[03/31 12:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 1566/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:01:40\n",
      "\u001b[32m[03/31 12:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 1571/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=1:01:34\n",
      "\u001b[32m[03/31 12:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 1576/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0388 s/iter. Total: 1.0775 s/iter. ETA=1:01:29\n",
      "\u001b[32m[03/31 12:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 1581/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0388 s/iter. Total: 1.0775 s/iter. ETA=1:01:24\n",
      "\u001b[32m[03/31 12:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 1586/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:01:18\n",
      "\u001b[32m[03/31 12:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 1591/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0778 s/iter. ETA=1:01:14\n",
      "\u001b[32m[03/31 12:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 1596/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0778 s/iter. ETA=1:01:08\n",
      "\u001b[32m[03/31 12:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 1601/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0778 s/iter. ETA=1:01:03\n",
      "\u001b[32m[03/31 12:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 1606/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0779 s/iter. ETA=1:00:58\n",
      "\u001b[32m[03/31 12:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 1611/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0389 s/iter. Total: 1.0778 s/iter. ETA=1:00:52\n",
      "\u001b[32m[03/31 12:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 1616/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0389 s/iter. Total: 1.0779 s/iter. ETA=1:00:47\n",
      "\u001b[32m[03/31 12:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 1621/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0389 s/iter. Total: 1.0777 s/iter. ETA=1:00:41\n",
      "\u001b[32m[03/31 12:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 1626/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0388 s/iter. Total: 1.0777 s/iter. ETA=1:00:36\n",
      "\u001b[32m[03/31 12:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 1631/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:00:30\n",
      "\u001b[32m[03/31 12:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 1636/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0389 s/iter. Total: 1.0777 s/iter. ETA=1:00:25\n",
      "\u001b[32m[03/31 12:09:20 d2.evaluation.evaluator]: \u001b[0mInference done 1641/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:00:19\n",
      "\u001b[32m[03/31 12:09:25 d2.evaluation.evaluator]: \u001b[0mInference done 1646/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:00:14\n",
      "\u001b[32m[03/31 12:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 1651/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0776 s/iter. ETA=1:00:08\n",
      "\u001b[32m[03/31 12:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 1656/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0776 s/iter. ETA=1:00:03\n",
      "\u001b[32m[03/31 12:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 1661/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0776 s/iter. ETA=0:59:58\n",
      "\u001b[32m[03/31 12:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 1666/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0388 s/iter. Total: 1.0775 s/iter. ETA=0:59:52\n",
      "\u001b[32m[03/31 12:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 1671/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0776 s/iter. ETA=0:59:47\n",
      "\u001b[32m[03/31 12:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 1676/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0776 s/iter. ETA=0:59:41\n",
      "\u001b[32m[03/31 12:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 1681/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=0:59:36\n",
      "\u001b[32m[03/31 12:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 1686/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0387 s/iter. Total: 1.0774 s/iter. ETA=0:59:30\n",
      "\u001b[32m[03/31 12:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 1691/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=0:59:25\n",
      "\u001b[32m[03/31 12:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 1696/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0776 s/iter. ETA=0:59:20\n",
      "\u001b[32m[03/31 12:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 1701/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=0:59:14\n",
      "\u001b[32m[03/31 12:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 1706/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=0:59:09\n",
      "\u001b[32m[03/31 12:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 1711/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0386 s/iter. Total: 1.0774 s/iter. ETA=0:59:03\n",
      "\u001b[32m[03/31 12:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 1716/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=0:58:58\n",
      "\u001b[32m[03/31 12:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 1721/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0776 s/iter. ETA=0:58:53\n",
      "\u001b[32m[03/31 12:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 1726/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0387 s/iter. Total: 1.0775 s/iter. ETA=0:58:47\n",
      "\u001b[32m[03/31 12:10:56 d2.evaluation.evaluator]: \u001b[0mInference done 1731/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0387 s/iter. Total: 1.0774 s/iter. ETA=0:58:42\n",
      "\u001b[32m[03/31 12:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 1736/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0387 s/iter. Total: 1.0773 s/iter. ETA=0:58:36\n",
      "\u001b[32m[03/31 12:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 1741/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=0:58:30\n",
      "\u001b[32m[03/31 12:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 1746/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0386 s/iter. Total: 1.0773 s/iter. ETA=0:58:25\n",
      "\u001b[32m[03/31 12:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 1751/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0386 s/iter. Total: 1.0774 s/iter. ETA=0:58:20\n",
      "\u001b[32m[03/31 12:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 1756/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0385 s/iter. Total: 1.0773 s/iter. ETA=0:58:14\n",
      "\u001b[32m[03/31 12:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 1761/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0385 s/iter. Total: 1.0773 s/iter. ETA=0:58:09\n",
      "\u001b[32m[03/31 12:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 1766/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0385 s/iter. Total: 1.0772 s/iter. ETA=0:58:03\n",
      "\u001b[32m[03/31 12:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 1771/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0385 s/iter. Total: 1.0771 s/iter. ETA=0:57:57\n",
      "\u001b[32m[03/31 12:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 1776/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:57:52\n",
      "\u001b[32m[03/31 12:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 1781/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0771 s/iter. ETA=0:57:47\n",
      "\u001b[32m[03/31 12:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 1786/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:57:41\n",
      "\u001b[32m[03/31 12:12:00 d2.evaluation.evaluator]: \u001b[0mInference done 1791/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:57:35\n",
      "\u001b[32m[03/31 12:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 1796/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0769 s/iter. ETA=0:57:30\n",
      "\u001b[32m[03/31 12:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 1801/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0769 s/iter. ETA=0:57:24\n",
      "\u001b[32m[03/31 12:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 1806/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:57:19\n",
      "\u001b[32m[03/31 12:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 1811/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:57:13\n",
      "\u001b[32m[03/31 12:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 1816/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:57:09\n",
      "\u001b[32m[03/31 12:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 1821/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0385 s/iter. Total: 1.0771 s/iter. ETA=0:57:03\n",
      "\u001b[32m[03/31 12:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 1826/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0384 s/iter. Total: 1.0769 s/iter. ETA=0:56:58\n",
      "\u001b[32m[03/31 12:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 1831/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:56:53\n",
      "\u001b[32m[03/31 12:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 1836/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:56:47\n",
      "\u001b[32m[03/31 12:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 1841/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:56:42\n",
      "\u001b[32m[03/31 12:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 1846/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:56:36\n",
      "\u001b[32m[03/31 12:13:05 d2.evaluation.evaluator]: \u001b[0mInference done 1851/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0768 s/iter. ETA=0:56:30\n",
      "\u001b[32m[03/31 12:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 1856/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0768 s/iter. ETA=0:56:25\n",
      "\u001b[32m[03/31 12:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 1861/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0386 s/iter. Total: 1.0769 s/iter. ETA=0:56:20\n",
      "\u001b[32m[03/31 12:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 1866/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0386 s/iter. Total: 1.0769 s/iter. ETA=0:56:15\n",
      "\u001b[32m[03/31 12:13:27 d2.evaluation.evaluator]: \u001b[0mInference done 1871/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0386 s/iter. Total: 1.0770 s/iter. ETA=0:56:09\n",
      "\u001b[32m[03/31 12:13:32 d2.evaluation.evaluator]: \u001b[0mInference done 1876/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0386 s/iter. Total: 1.0770 s/iter. ETA=0:56:04\n",
      "\u001b[32m[03/31 12:13:37 d2.evaluation.evaluator]: \u001b[0mInference done 1881/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0386 s/iter. Total: 1.0770 s/iter. ETA=0:55:59\n",
      "\u001b[32m[03/31 12:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 1886/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0386 s/iter. Total: 1.0770 s/iter. ETA=0:55:53\n",
      "\u001b[32m[03/31 12:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 1891/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0386 s/iter. Total: 1.0770 s/iter. ETA=0:55:48\n",
      "\u001b[32m[03/31 12:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 1896/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:55:42\n",
      "\u001b[32m[03/31 12:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 1901/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:55:37\n",
      "\u001b[32m[03/31 12:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 1906/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:55:31\n",
      "\u001b[32m[03/31 12:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 1911/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:55:26\n",
      "\u001b[32m[03/31 12:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 1916/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0768 s/iter. ETA=0:55:20\n",
      "\u001b[32m[03/31 12:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 1921/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:55:15\n",
      "\u001b[32m[03/31 12:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 1926/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0384 s/iter. Total: 1.0769 s/iter. ETA=0:55:10\n",
      "\u001b[32m[03/31 12:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 1931/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:55:04\n",
      "\u001b[32m[03/31 12:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 1936/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0769 s/iter. ETA=0:54:59\n",
      "\u001b[32m[03/31 12:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 1941/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:54:53\n",
      "\u001b[32m[03/31 12:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 1946/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:54:48\n",
      "\u001b[32m[03/31 12:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 1951/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:54:42\n",
      "\u001b[32m[03/31 12:14:58 d2.evaluation.evaluator]: \u001b[0mInference done 1956/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:54:37\n",
      "\u001b[32m[03/31 12:15:03 d2.evaluation.evaluator]: \u001b[0mInference done 1961/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:54:32\n",
      "\u001b[32m[03/31 12:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 1966/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:54:26\n",
      "\u001b[32m[03/31 12:15:14 d2.evaluation.evaluator]: \u001b[0mInference done 1971/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:54:21\n",
      "\u001b[32m[03/31 12:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 1976/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:54:16\n",
      "\u001b[32m[03/31 12:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 1981/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:54:11\n",
      "\u001b[32m[03/31 12:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 1986/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:54:05\n",
      "\u001b[32m[03/31 12:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 1991/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:54:00\n",
      "\u001b[32m[03/31 12:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 1996/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:53:55\n",
      "\u001b[32m[03/31 12:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 2001/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:53:49\n",
      "\u001b[32m[03/31 12:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 2006/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:53:44\n",
      "\u001b[32m[03/31 12:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 2011/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:53:39\n",
      "\u001b[32m[03/31 12:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 2016/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0385 s/iter. Total: 1.0770 s/iter. ETA=0:53:33\n",
      "\u001b[32m[03/31 12:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 2021/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0385 s/iter. Total: 1.0771 s/iter. ETA=0:53:28\n",
      "\u001b[32m[03/31 12:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 2026/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0386 s/iter. Total: 1.0772 s/iter. ETA=0:53:23\n",
      "\u001b[32m[03/31 12:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 2031/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0386 s/iter. Total: 1.0771 s/iter. ETA=0:53:17\n",
      "\u001b[32m[03/31 12:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 2036/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0386 s/iter. Total: 1.0770 s/iter. ETA=0:53:12\n",
      "\u001b[32m[03/31 12:16:30 d2.evaluation.evaluator]: \u001b[0mInference done 2041/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0386 s/iter. Total: 1.0771 s/iter. ETA=0:53:07\n",
      "\u001b[32m[03/31 12:16:35 d2.evaluation.evaluator]: \u001b[0mInference done 2046/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0387 s/iter. Total: 1.0771 s/iter. ETA=0:53:01\n",
      "\u001b[32m[03/31 12:16:40 d2.evaluation.evaluator]: \u001b[0mInference done 2051/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0386 s/iter. Total: 1.0769 s/iter. ETA=0:52:55\n",
      "\u001b[32m[03/31 12:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 2056/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0386 s/iter. Total: 1.0769 s/iter. ETA=0:52:50\n",
      "\u001b[32m[03/31 12:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 2061/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:52:44\n",
      "\u001b[32m[03/31 12:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 2066/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:52:39\n",
      "\u001b[32m[03/31 12:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 2071/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:52:34\n",
      "\u001b[32m[03/31 12:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 2076/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0768 s/iter. ETA=0:52:28\n",
      "\u001b[32m[03/31 12:17:12 d2.evaluation.evaluator]: \u001b[0mInference done 2081/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:52:23\n",
      "\u001b[32m[03/31 12:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 2086/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:52:17\n",
      "\u001b[32m[03/31 12:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 2091/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:52:12\n",
      "\u001b[32m[03/31 12:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 2096/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:52:07\n",
      "\u001b[32m[03/31 12:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 2101/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0768 s/iter. ETA=0:52:01\n",
      "\u001b[32m[03/31 12:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 2106/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:51:56\n",
      "\u001b[32m[03/31 12:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 2111/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:51:51\n",
      "\u001b[32m[03/31 12:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 2116/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0769 s/iter. ETA=0:51:45\n",
      "\u001b[32m[03/31 12:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 2121/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0385 s/iter. Total: 1.0768 s/iter. ETA=0:51:40\n",
      "\u001b[32m[03/31 12:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 2126/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:51:34\n",
      "\u001b[32m[03/31 12:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 2131/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:51:28\n",
      "\u001b[32m[03/31 12:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 2136/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:51:23\n",
      "\u001b[32m[03/31 12:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 2141/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:51:18\n",
      "\u001b[32m[03/31 12:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 2146/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:51:12\n",
      "\u001b[32m[03/31 12:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 2151/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:51:07\n",
      "\u001b[32m[03/31 12:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 2156/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0385 s/iter. Total: 1.0767 s/iter. ETA=0:51:02\n",
      "\u001b[32m[03/31 12:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 2161/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0385 s/iter. Total: 1.0767 s/iter. ETA=0:50:56\n",
      "\u001b[32m[03/31 12:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 2166/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:50:51\n",
      "\u001b[32m[03/31 12:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 2171/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:50:45\n",
      "\u001b[32m[03/31 12:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 2176/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:50:40\n",
      "\u001b[32m[03/31 12:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 2181/5000. Dataloading: 0.0028 s/iter. Inference: 1.0352 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:50:34\n",
      "\u001b[32m[03/31 12:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 2186/5000. Dataloading: 0.0028 s/iter. Inference: 1.0352 s/iter. Eval: 0.0384 s/iter. Total: 1.0765 s/iter. ETA=0:50:29\n",
      "\u001b[32m[03/31 12:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 2191/5000. Dataloading: 0.0028 s/iter. Inference: 1.0352 s/iter. Eval: 0.0384 s/iter. Total: 1.0765 s/iter. ETA=0:50:23\n",
      "\u001b[32m[03/31 12:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 2196/5000. Dataloading: 0.0028 s/iter. Inference: 1.0352 s/iter. Eval: 0.0383 s/iter. Total: 1.0765 s/iter. ETA=0:50:18\n",
      "\u001b[32m[03/31 12:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 2201/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0765 s/iter. ETA=0:50:13\n",
      "\u001b[32m[03/31 12:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 2206/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:50:08\n",
      "\u001b[32m[03/31 12:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 2211/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:50:02\n",
      "\u001b[32m[03/31 12:19:37 d2.evaluation.evaluator]: \u001b[0mInference done 2216/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0765 s/iter. ETA=0:49:57\n",
      "\u001b[32m[03/31 12:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 2221/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:49:51\n",
      "\u001b[32m[03/31 12:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 2226/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:49:46\n",
      "\u001b[32m[03/31 12:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 2231/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:49:41\n",
      "\u001b[32m[03/31 12:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 2236/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:49:35\n",
      "\u001b[32m[03/31 12:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 2241/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0766 s/iter. ETA=0:49:30\n",
      "\u001b[32m[03/31 12:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 2246/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0384 s/iter. Total: 1.0767 s/iter. ETA=0:49:25\n",
      "\u001b[32m[03/31 12:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 2251/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:49:20\n",
      "\u001b[32m[03/31 12:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 2256/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:49:14\n",
      "\u001b[32m[03/31 12:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 2261/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0384 s/iter. Total: 1.0769 s/iter. ETA=0:49:09\n",
      "\u001b[32m[03/31 12:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 2266/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0383 s/iter. Total: 1.0768 s/iter. ETA=0:49:03\n",
      "\u001b[32m[03/31 12:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 2271/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0384 s/iter. Total: 1.0768 s/iter. ETA=0:48:58\n",
      "\u001b[32m[03/31 12:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 2276/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0383 s/iter. Total: 1.0767 s/iter. ETA=0:48:53\n",
      "\u001b[32m[03/31 12:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 2281/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0383 s/iter. Total: 1.0767 s/iter. ETA=0:48:47\n",
      "\u001b[32m[03/31 12:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 2286/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0383 s/iter. Total: 1.0767 s/iter. ETA=0:48:42\n",
      "\u001b[32m[03/31 12:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 2291/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0383 s/iter. Total: 1.0766 s/iter. ETA=0:48:36\n",
      "\u001b[32m[03/31 12:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 2296/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:48:30\n",
      "\u001b[32m[03/31 12:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 2301/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:48:25\n",
      "\u001b[32m[03/31 12:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 2306/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0383 s/iter. Total: 1.0765 s/iter. ETA=0:48:20\n",
      "\u001b[32m[03/31 12:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 2311/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0383 s/iter. Total: 1.0765 s/iter. ETA=0:48:14\n",
      "\u001b[32m[03/31 12:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 2316/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:48:09\n",
      "\u001b[32m[03/31 12:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 2321/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:48:03\n",
      "\u001b[32m[03/31 12:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 2326/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0382 s/iter. Total: 1.0764 s/iter. ETA=0:47:58\n",
      "\u001b[32m[03/31 12:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 2331/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0764 s/iter. ETA=0:47:52\n",
      "\u001b[32m[03/31 12:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 2336/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0381 s/iter. Total: 1.0764 s/iter. ETA=0:47:47\n",
      "\u001b[32m[03/31 12:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 2341/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0381 s/iter. Total: 1.0762 s/iter. ETA=0:47:41\n",
      "\u001b[32m[03/31 12:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 2346/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:47:36\n",
      "\u001b[32m[03/31 12:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 2351/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:47:31\n",
      "\u001b[32m[03/31 12:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 2356/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:47:25\n",
      "\u001b[32m[03/31 12:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 2361/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:47:20\n",
      "\u001b[32m[03/31 12:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 2366/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:47:14\n",
      "\u001b[32m[03/31 12:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 2371/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0762 s/iter. ETA=0:47:09\n",
      "\u001b[32m[03/31 12:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 2376/5000. Dataloading: 0.0028 s/iter. Inference: 1.0353 s/iter. Eval: 0.0380 s/iter. Total: 1.0762 s/iter. ETA=0:47:03\n",
      "\u001b[32m[03/31 12:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 2381/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0762 s/iter. ETA=0:46:58\n",
      "\u001b[32m[03/31 12:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 2386/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:46:53\n",
      "\u001b[32m[03/31 12:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 2391/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:46:47\n",
      "\u001b[32m[03/31 12:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 2396/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0763 s/iter. ETA=0:46:42\n",
      "\u001b[32m[03/31 12:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 2401/5000. Dataloading: 0.0028 s/iter. Inference: 1.0354 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:46:37\n",
      "\u001b[32m[03/31 12:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 2406/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:46:32\n",
      "\u001b[32m[03/31 12:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 2411/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:46:26\n",
      "\u001b[32m[03/31 12:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 2416/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:46:21\n",
      "\u001b[32m[03/31 12:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 2421/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:46:16\n",
      "\u001b[32m[03/31 12:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 2426/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:46:11\n",
      "\u001b[32m[03/31 12:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 2431/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:46:05\n",
      "\u001b[32m[03/31 12:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 2436/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:46:00\n",
      "\u001b[32m[03/31 12:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 2441/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:45:55\n",
      "\u001b[32m[03/31 12:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 2446/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:45:49\n",
      "\u001b[32m[03/31 12:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 2451/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:45:44\n",
      "\u001b[32m[03/31 12:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 2456/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:45:39\n",
      "\u001b[32m[03/31 12:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 2461/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:45:33\n",
      "\u001b[32m[03/31 12:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 2466/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:45:28\n",
      "\u001b[32m[03/31 12:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 2471/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:45:22\n",
      "\u001b[32m[03/31 12:24:17 d2.evaluation.evaluator]: \u001b[0mInference done 2476/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:45:17\n",
      "\u001b[32m[03/31 12:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 2481/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:45:11\n",
      "\u001b[32m[03/31 12:24:28 d2.evaluation.evaluator]: \u001b[0mInference done 2486/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:45:06\n",
      "\u001b[32m[03/31 12:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 2491/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:45:01\n",
      "\u001b[32m[03/31 12:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 2496/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:44:55\n",
      "\u001b[32m[03/31 12:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 2501/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:44:50\n",
      "\u001b[32m[03/31 12:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 2506/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0766 s/iter. ETA=0:44:44\n",
      "\u001b[32m[03/31 12:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 2511/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:44:39\n",
      "\u001b[32m[03/31 12:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 2516/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:44:34\n",
      "\u001b[32m[03/31 12:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 2521/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:44:28\n",
      "\u001b[32m[03/31 12:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 2526/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:44:23\n",
      "\u001b[32m[03/31 12:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 2531/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:44:17\n",
      "\u001b[32m[03/31 12:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 2536/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0764 s/iter. ETA=0:44:12\n",
      "\u001b[32m[03/31 12:25:27 d2.evaluation.evaluator]: \u001b[0mInference done 2541/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:44:07\n",
      "\u001b[32m[03/31 12:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 2546/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:44:01\n",
      "\u001b[32m[03/31 12:25:38 d2.evaluation.evaluator]: \u001b[0mInference done 2551/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:43:56\n",
      "\u001b[32m[03/31 12:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 2556/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:43:51\n",
      "\u001b[32m[03/31 12:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 2561/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:43:45\n",
      "\u001b[32m[03/31 12:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 2566/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:43:40\n",
      "\u001b[32m[03/31 12:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 2571/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:43:34\n",
      "\u001b[32m[03/31 12:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 2576/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:43:29\n",
      "\u001b[32m[03/31 12:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 2581/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:43:24\n",
      "\u001b[32m[03/31 12:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 2586/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0383 s/iter. Total: 1.0766 s/iter. ETA=0:43:18\n",
      "\u001b[32m[03/31 12:26:21 d2.evaluation.evaluator]: \u001b[0mInference done 2591/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:43:13\n",
      "\u001b[32m[03/31 12:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 2596/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:43:07\n",
      "\u001b[32m[03/31 12:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 2601/5000. Dataloading: 0.0027 s/iter. Inference: 1.0353 s/iter. Eval: 0.0382 s/iter. Total: 1.0764 s/iter. ETA=0:43:02\n",
      "\u001b[32m[03/31 12:26:37 d2.evaluation.evaluator]: \u001b[0mInference done 2606/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:42:57\n",
      "\u001b[32m[03/31 12:26:42 d2.evaluation.evaluator]: \u001b[0mInference done 2611/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:42:51\n",
      "\u001b[32m[03/31 12:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 2616/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:42:46\n",
      "\u001b[32m[03/31 12:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 2621/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0383 s/iter. Total: 1.0766 s/iter. ETA=0:42:41\n",
      "\u001b[32m[03/31 12:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 2626/5000. Dataloading: 0.0027 s/iter. Inference: 1.0354 s/iter. Eval: 0.0382 s/iter. Total: 1.0765 s/iter. ETA=0:42:35\n",
      "\u001b[32m[03/31 12:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 2631/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0383 s/iter. Total: 1.0766 s/iter. ETA=0:42:30\n",
      "\u001b[32m[03/31 12:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 2636/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:42:25\n",
      "\u001b[32m[03/31 12:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 2641/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:42:19\n",
      "\u001b[32m[03/31 12:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 2646/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0766 s/iter. ETA=0:42:14\n",
      "\u001b[32m[03/31 12:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 2651/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:42:09\n",
      "\u001b[32m[03/31 12:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 2656/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:42:03\n",
      "\u001b[32m[03/31 12:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 2661/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:41:58\n",
      "\u001b[32m[03/31 12:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 2666/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:41:53\n",
      "\u001b[32m[03/31 12:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 2671/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:41:47\n",
      "\u001b[32m[03/31 12:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 2676/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:41:42\n",
      "\u001b[32m[03/31 12:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 2681/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:41:36\n",
      "\u001b[32m[03/31 12:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 2686/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0382 s/iter. Total: 1.0767 s/iter. ETA=0:41:31\n",
      "\u001b[32m[03/31 12:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 2691/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:41:26\n",
      "\u001b[32m[03/31 12:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 2696/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:41:20\n",
      "\u001b[32m[03/31 12:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2701/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0766 s/iter. ETA=0:41:15\n",
      "\u001b[32m[03/31 12:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 2706/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0766 s/iter. ETA=0:41:09\n",
      "\u001b[32m[03/31 12:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 2711/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:41:04\n",
      "\u001b[32m[03/31 12:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 2716/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:40:58\n",
      "\u001b[32m[03/31 12:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 2721/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:40:53\n",
      "\u001b[32m[03/31 12:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 2726/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:40:48\n",
      "\u001b[32m[03/31 12:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 2731/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:40:42\n",
      "\u001b[32m[03/31 12:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 2736/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:40:37\n",
      "\u001b[32m[03/31 12:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 2741/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:40:31\n",
      "\u001b[32m[03/31 12:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 2746/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:40:26\n",
      "\u001b[32m[03/31 12:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 2751/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:40:20\n",
      "\u001b[32m[03/31 12:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 2756/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:40:15\n",
      "\u001b[32m[03/31 12:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 2761/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:40:10\n",
      "\u001b[32m[03/31 12:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 2766/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:40:04\n",
      "\u001b[32m[03/31 12:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 2771/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:39:59\n",
      "\u001b[32m[03/31 12:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 2776/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:39:54\n",
      "\u001b[32m[03/31 12:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 2781/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:39:48\n",
      "\u001b[32m[03/31 12:29:51 d2.evaluation.evaluator]: \u001b[0mInference done 2786/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:39:43\n",
      "\u001b[32m[03/31 12:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 2791/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:39:37\n",
      "\u001b[32m[03/31 12:30:01 d2.evaluation.evaluator]: \u001b[0mInference done 2796/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:39:32\n",
      "\u001b[32m[03/31 12:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 2801/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0764 s/iter. ETA=0:39:27\n",
      "\u001b[32m[03/31 12:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 2806/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0764 s/iter. ETA=0:39:21\n",
      "\u001b[32m[03/31 12:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 2811/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:39:16\n",
      "\u001b[32m[03/31 12:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 2816/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:39:10\n",
      "\u001b[32m[03/31 12:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 2821/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0764 s/iter. ETA=0:39:05\n",
      "\u001b[32m[03/31 12:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 2826/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0381 s/iter. Total: 1.0764 s/iter. ETA=0:39:00\n",
      "\u001b[32m[03/31 12:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 2831/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0764 s/iter. ETA=0:38:54\n",
      "\u001b[32m[03/31 12:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 2836/5000. Dataloading: 0.0027 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:38:49\n",
      "\u001b[32m[03/31 12:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 2841/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:38:44\n",
      "\u001b[32m[03/31 12:30:55 d2.evaluation.evaluator]: \u001b[0mInference done 2846/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0766 s/iter. ETA=0:38:38\n",
      "\u001b[32m[03/31 12:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 2851/5000. Dataloading: 0.0027 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:38:33\n",
      "\u001b[32m[03/31 12:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 2856/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0766 s/iter. ETA=0:38:28\n",
      "\u001b[32m[03/31 12:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 2861/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0381 s/iter. Total: 1.0765 s/iter. ETA=0:38:22\n",
      "\u001b[32m[03/31 12:31:17 d2.evaluation.evaluator]: \u001b[0mInference done 2866/5000. Dataloading: 0.0028 s/iter. Inference: 1.0355 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:38:17\n",
      "\u001b[32m[03/31 12:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 2871/5000. Dataloading: 0.0027 s/iter. Inference: 1.0356 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:38:11\n",
      "\u001b[32m[03/31 12:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 2876/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:38:06\n",
      "\u001b[32m[03/31 12:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 2881/5000. Dataloading: 0.0028 s/iter. Inference: 1.0356 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:38:01\n",
      "\u001b[32m[03/31 12:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 2886/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:37:55\n",
      "\u001b[32m[03/31 12:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 2891/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0767 s/iter. ETA=0:37:50\n",
      "\u001b[32m[03/31 12:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 2896/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0767 s/iter. ETA=0:37:45\n",
      "\u001b[32m[03/31 12:31:55 d2.evaluation.evaluator]: \u001b[0mInference done 2901/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:37:39\n",
      "\u001b[32m[03/31 12:32:00 d2.evaluation.evaluator]: \u001b[0mInference done 2906/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:37:34\n",
      "\u001b[32m[03/31 12:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 2911/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:37:29\n",
      "\u001b[32m[03/31 12:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 2916/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0767 s/iter. ETA=0:37:23\n",
      "\u001b[32m[03/31 12:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 2921/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0381 s/iter. Total: 1.0766 s/iter. ETA=0:37:18\n",
      "\u001b[32m[03/31 12:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 2926/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:37:12\n",
      "\u001b[32m[03/31 12:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 2931/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:37:07\n",
      "\u001b[32m[03/31 12:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 2936/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:37:02\n",
      "\u001b[32m[03/31 12:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 2941/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0380 s/iter. Total: 1.0767 s/iter. ETA=0:36:56\n",
      "\u001b[32m[03/31 12:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 2946/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:36:51\n",
      "\u001b[32m[03/31 12:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 2951/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:36:45\n",
      "\u001b[32m[03/31 12:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 2956/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:36:40\n",
      "\u001b[32m[03/31 12:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 2961/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:36:35\n",
      "\u001b[32m[03/31 12:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 2966/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0765 s/iter. ETA=0:36:29\n",
      "\u001b[32m[03/31 12:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 2971/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:36:24\n",
      "\u001b[32m[03/31 12:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 2976/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:36:18\n",
      "\u001b[32m[03/31 12:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 2981/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:36:13\n",
      "\u001b[32m[03/31 12:33:26 d2.evaluation.evaluator]: \u001b[0mInference done 2986/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:36:08\n",
      "\u001b[32m[03/31 12:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 2991/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:36:02\n",
      "\u001b[32m[03/31 12:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 2996/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0380 s/iter. Total: 1.0766 s/iter. ETA=0:35:57\n",
      "\u001b[32m[03/31 12:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 3001/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:35:51\n",
      "\u001b[32m[03/31 12:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 3006/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:35:46\n",
      "\u001b[32m[03/31 12:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 3011/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:35:41\n",
      "\u001b[32m[03/31 12:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 3016/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0766 s/iter. ETA=0:35:35\n",
      "\u001b[32m[03/31 12:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 3021/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0765 s/iter. ETA=0:35:30\n",
      "\u001b[32m[03/31 12:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 3026/5000. Dataloading: 0.0028 s/iter. Inference: 1.0357 s/iter. Eval: 0.0379 s/iter. Total: 1.0766 s/iter. ETA=0:35:25\n",
      "\u001b[32m[03/31 12:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 3031/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0379 s/iter. Total: 1.0766 s/iter. ETA=0:35:19\n",
      "\u001b[32m[03/31 12:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 3036/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0379 s/iter. Total: 1.0766 s/iter. ETA=0:35:14\n",
      "\u001b[32m[03/31 12:34:25 d2.evaluation.evaluator]: \u001b[0mInference done 3041/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0379 s/iter. Total: 1.0766 s/iter. ETA=0:35:09\n",
      "\u001b[32m[03/31 12:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 3046/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0379 s/iter. Total: 1.0766 s/iter. ETA=0:35:03\n",
      "\u001b[32m[03/31 12:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 3051/5000. Dataloading: 0.0028 s/iter. Inference: 1.0358 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:58\n",
      "\u001b[32m[03/31 12:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 3056/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:34:53\n",
      "\u001b[32m[03/31 12:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 3061/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:47\n",
      "\u001b[32m[03/31 12:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 3066/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:42\n",
      "\u001b[32m[03/31 12:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 3071/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:36\n",
      "\u001b[32m[03/31 12:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 3076/5000. Dataloading: 0.0028 s/iter. Inference: 1.0359 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:31\n",
      "\u001b[32m[03/31 12:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 3081/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:26\n",
      "\u001b[32m[03/31 12:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 3086/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:34:20\n",
      "\u001b[32m[03/31 12:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 3091/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0377 s/iter. Total: 1.0766 s/iter. ETA=0:34:15\n",
      "\u001b[32m[03/31 12:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 3096/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:09\n",
      "\u001b[32m[03/31 12:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 3101/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:34:04\n",
      "\u001b[32m[03/31 12:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 3106/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:59\n",
      "\u001b[32m[03/31 12:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 3111/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:33:53\n",
      "\u001b[32m[03/31 12:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 3116/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0766 s/iter. ETA=0:33:48\n",
      "\u001b[32m[03/31 12:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 3121/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:43\n",
      "\u001b[32m[03/31 12:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 3126/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:37\n",
      "\u001b[32m[03/31 12:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 3131/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:32\n",
      "\u001b[32m[03/31 12:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 3136/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:27\n",
      "\u001b[32m[03/31 12:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 3141/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:33:21\n",
      "\u001b[32m[03/31 12:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 3146/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:33:16\n",
      "\u001b[32m[03/31 12:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 3151/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:33:10\n",
      "\u001b[32m[03/31 12:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 3156/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:05\n",
      "\u001b[32m[03/31 12:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 3161/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:33:00\n",
      "\u001b[32m[03/31 12:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 3166/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:54\n",
      "\u001b[32m[03/31 12:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 3171/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0377 s/iter. Total: 1.0766 s/iter. ETA=0:32:49\n",
      "\u001b[32m[03/31 12:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 3176/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:43\n",
      "\u001b[32m[03/31 12:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 3181/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:38\n",
      "\u001b[32m[03/31 12:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 3186/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:33\n",
      "\u001b[32m[03/31 12:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 3191/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:27\n",
      "\u001b[32m[03/31 12:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 3196/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:22\n",
      "\u001b[32m[03/31 12:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 3201/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0767 s/iter. ETA=0:32:17\n",
      "\u001b[32m[03/31 12:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 3206/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:32:11\n",
      "\u001b[32m[03/31 12:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 3211/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:32:06\n",
      "\u001b[32m[03/31 12:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 3216/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:32:00\n",
      "\u001b[32m[03/31 12:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 3221/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:55\n",
      "\u001b[32m[03/31 12:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 3226/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:50\n",
      "\u001b[32m[03/31 12:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 3231/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:31:44\n",
      "\u001b[32m[03/31 12:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 3236/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:39\n",
      "\u001b[32m[03/31 12:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 3241/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:34\n",
      "\u001b[32m[03/31 12:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 3246/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:28\n",
      "\u001b[32m[03/31 12:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 3251/5000. Dataloading: 0.0028 s/iter. Inference: 1.0360 s/iter. Eval: 0.0378 s/iter. Total: 1.0768 s/iter. ETA=0:31:23\n",
      "\u001b[32m[03/31 12:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 3256/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:17\n",
      "\u001b[32m[03/31 12:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 3261/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:12\n",
      "\u001b[32m[03/31 12:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 3266/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:07\n",
      "\u001b[32m[03/31 12:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 3271/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0768 s/iter. ETA=0:31:01\n",
      "\u001b[32m[03/31 12:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 3276/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:30:56\n",
      "\u001b[32m[03/31 12:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 3281/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:30:51\n",
      "\u001b[32m[03/31 12:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 3286/5000. Dataloading: 0.0028 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:30:45\n",
      "\u001b[32m[03/31 12:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 3291/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:30:40\n",
      "\u001b[32m[03/31 12:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 3296/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:30:35\n",
      "\u001b[32m[03/31 12:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 3301/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:30:29\n",
      "\u001b[32m[03/31 12:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 3306/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0770 s/iter. ETA=0:30:24\n",
      "\u001b[32m[03/31 12:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 3311/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:30:19\n",
      "\u001b[32m[03/31 12:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 3316/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:30:13\n",
      "\u001b[32m[03/31 12:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 3321/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:30:08\n",
      "\u001b[32m[03/31 12:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 3326/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:30:02\n",
      "\u001b[32m[03/31 12:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 3331/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:29:57\n",
      "\u001b[32m[03/31 12:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 3336/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:29:52\n",
      "\u001b[32m[03/31 12:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 3341/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:29:46\n",
      "\u001b[32m[03/31 12:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 3346/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:29:41\n",
      "\u001b[32m[03/31 12:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 3351/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:29:35\n",
      "\u001b[32m[03/31 12:40:06 d2.evaluation.evaluator]: \u001b[0mInference done 3356/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0770 s/iter. ETA=0:29:30\n",
      "\u001b[32m[03/31 12:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 3361/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0770 s/iter. ETA=0:29:25\n",
      "\u001b[32m[03/31 12:40:17 d2.evaluation.evaluator]: \u001b[0mInference done 3366/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:29:20\n",
      "\u001b[32m[03/31 12:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 3371/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:29:14\n",
      "\u001b[32m[03/31 12:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 3376/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:29:09\n",
      "\u001b[32m[03/31 12:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 3381/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:29:03\n",
      "\u001b[32m[03/31 12:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 3386/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:28:58\n",
      "\u001b[32m[03/31 12:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 3391/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:28:52\n",
      "\u001b[32m[03/31 12:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 3396/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:28:47\n",
      "\u001b[32m[03/31 12:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 3401/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:28:42\n",
      "\u001b[32m[03/31 12:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 3406/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:28:36\n",
      "\u001b[32m[03/31 12:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 3411/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:28:31\n",
      "\u001b[32m[03/31 12:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 3416/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:28:25\n",
      "\u001b[32m[03/31 12:41:16 d2.evaluation.evaluator]: \u001b[0mInference done 3421/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:28:20\n",
      "\u001b[32m[03/31 12:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 3426/5000. Dataloading: 0.0027 s/iter. Inference: 1.0361 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:28:15\n",
      "\u001b[32m[03/31 12:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 3431/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:28:09\n",
      "\u001b[32m[03/31 12:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 3436/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:28:04\n",
      "\u001b[32m[03/31 12:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 3441/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:27:59\n",
      "\u001b[32m[03/31 12:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 3446/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:27:53\n",
      "\u001b[32m[03/31 12:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 3451/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:27:48\n",
      "\u001b[32m[03/31 12:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 3456/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:27:43\n",
      "\u001b[32m[03/31 12:41:59 d2.evaluation.evaluator]: \u001b[0mInference done 3461/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0380 s/iter. Total: 1.0771 s/iter. ETA=0:27:37\n",
      "\u001b[32m[03/31 12:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 3466/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:27:32\n",
      "\u001b[32m[03/31 12:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 3471/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:27:26\n",
      "\u001b[32m[03/31 12:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 3476/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:27:21\n",
      "\u001b[32m[03/31 12:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 3481/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:27:15\n",
      "\u001b[32m[03/31 12:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 3486/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0379 s/iter. Total: 1.0769 s/iter. ETA=0:27:10\n",
      "\u001b[32m[03/31 12:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 3491/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0378 s/iter. Total: 1.0769 s/iter. ETA=0:27:05\n",
      "\u001b[32m[03/31 12:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 3496/5000. Dataloading: 0.0027 s/iter. Inference: 1.0362 s/iter. Eval: 0.0378 s/iter. Total: 1.0769 s/iter. ETA=0:26:59\n",
      "\u001b[32m[03/31 12:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 3501/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:26:54\n",
      "\u001b[32m[03/31 12:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 3506/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:26:49\n",
      "\u001b[32m[03/31 12:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 3511/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:26:43\n",
      "\u001b[32m[03/31 12:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 3516/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:26:38\n",
      "\u001b[32m[03/31 12:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 3521/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0770 s/iter. ETA=0:26:32\n",
      "\u001b[32m[03/31 12:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 3526/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:26:27\n",
      "\u001b[32m[03/31 12:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 3531/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:26:22\n",
      "\u001b[32m[03/31 12:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 3536/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:26:16\n",
      "\u001b[32m[03/31 12:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 3541/5000. Dataloading: 0.0028 s/iter. Inference: 1.0362 s/iter. Eval: 0.0378 s/iter. Total: 1.0769 s/iter. ETA=0:26:11\n",
      "\u001b[32m[03/31 12:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 3546/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:26:05\n",
      "\u001b[32m[03/31 12:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 3551/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:26:00\n",
      "\u001b[32m[03/31 12:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 3556/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:25:55\n",
      "\u001b[32m[03/31 12:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 3561/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:25:49\n",
      "\u001b[32m[03/31 12:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 3566/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:25:44\n",
      "\u001b[32m[03/31 12:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 3571/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:25:39\n",
      "\u001b[32m[03/31 12:44:03 d2.evaluation.evaluator]: \u001b[0mInference done 3576/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:25:33\n",
      "\u001b[32m[03/31 12:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 3581/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:25:28\n",
      "\u001b[32m[03/31 12:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 3586/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:25:22\n",
      "\u001b[32m[03/31 12:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 3591/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:25:17\n",
      "\u001b[32m[03/31 12:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 3596/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:25:12\n",
      "\u001b[32m[03/31 12:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 3601/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:25:06\n",
      "\u001b[32m[03/31 12:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 3606/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:25:01\n",
      "\u001b[32m[03/31 12:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 3611/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:24:56\n",
      "\u001b[32m[03/31 12:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 3616/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:24:50\n",
      "\u001b[32m[03/31 12:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 3621/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:24:45\n",
      "\u001b[32m[03/31 12:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 3626/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:24:39\n",
      "\u001b[32m[03/31 12:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 3631/5000. Dataloading: 0.0028 s/iter. Inference: 1.0363 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:34\n",
      "\u001b[32m[03/31 12:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 3636/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:29\n",
      "\u001b[32m[03/31 12:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 3641/5000. Dataloading: 0.0028 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:23\n",
      "\u001b[32m[03/31 12:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 3646/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:18\n",
      "\u001b[32m[03/31 12:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 3651/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:13\n",
      "\u001b[32m[03/31 12:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 3656/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:07\n",
      "\u001b[32m[03/31 12:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 3661/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:24:02\n",
      "\u001b[32m[03/31 12:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 3666/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:23:56\n",
      "\u001b[32m[03/31 12:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 3671/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:23:51\n",
      "\u001b[32m[03/31 12:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 3676/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0379 s/iter. Total: 1.0771 s/iter. ETA=0:23:46\n",
      "\u001b[32m[03/31 12:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 3681/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:23:40\n",
      "\u001b[32m[03/31 12:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 3686/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:23:35\n",
      "\u001b[32m[03/31 12:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 3691/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:23:29\n",
      "\u001b[32m[03/31 12:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 3696/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:23:24\n",
      "\u001b[32m[03/31 12:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 3701/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:23:19\n",
      "\u001b[32m[03/31 12:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 3706/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0379 s/iter. Total: 1.0772 s/iter. ETA=0:23:13\n",
      "\u001b[32m[03/31 12:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 3711/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0379 s/iter. Total: 1.0772 s/iter. ETA=0:23:08\n",
      "\u001b[32m[03/31 12:46:34 d2.evaluation.evaluator]: \u001b[0mInference done 3716/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:23:03\n",
      "\u001b[32m[03/31 12:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 3721/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:22:57\n",
      "\u001b[32m[03/31 12:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 3726/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:52\n",
      "\u001b[32m[03/31 12:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 3731/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:46\n",
      "\u001b[32m[03/31 12:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 3736/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:41\n",
      "\u001b[32m[03/31 12:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 3741/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:36\n",
      "\u001b[32m[03/31 12:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 3746/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:30\n",
      "\u001b[32m[03/31 12:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 3751/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:25\n",
      "\u001b[32m[03/31 12:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 3756/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:20\n",
      "\u001b[32m[03/31 12:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 3761/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:14\n",
      "\u001b[32m[03/31 12:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 3766/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:09\n",
      "\u001b[32m[03/31 12:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 3771/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:22:03\n",
      "\u001b[32m[03/31 12:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 3776/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:21:58\n",
      "\u001b[32m[03/31 12:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 3781/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:21:53\n",
      "\u001b[32m[03/31 12:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 3786/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:21:47\n",
      "\u001b[32m[03/31 12:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 3791/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:42\n",
      "\u001b[32m[03/31 12:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 3796/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:37\n",
      "\u001b[32m[03/31 12:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 3801/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:31\n",
      "\u001b[32m[03/31 12:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 3806/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:26\n",
      "\u001b[32m[03/31 12:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 3811/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:20\n",
      "\u001b[32m[03/31 12:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 3816/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:15\n",
      "\u001b[32m[03/31 12:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 3821/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:10\n",
      "\u001b[32m[03/31 12:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 3826/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:21:04\n",
      "\u001b[32m[03/31 12:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 3831/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:20:59\n",
      "\u001b[32m[03/31 12:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 3836/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:53\n",
      "\u001b[32m[03/31 12:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 3841/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:48\n",
      "\u001b[32m[03/31 12:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 3846/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:43\n",
      "\u001b[32m[03/31 12:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 3851/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:37\n",
      "\u001b[32m[03/31 12:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 3856/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:32\n",
      "\u001b[32m[03/31 12:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 3861/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:27\n",
      "\u001b[32m[03/31 12:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 3866/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:21\n",
      "\u001b[32m[03/31 12:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 3876/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:20:10\n",
      "\u001b[32m[03/31 12:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 3881/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:05\n",
      "\u001b[32m[03/31 12:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 3886/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:20:00\n",
      "\u001b[32m[03/31 12:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 3891/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0377 s/iter. Total: 1.0773 s/iter. ETA=0:19:54\n",
      "\u001b[32m[03/31 12:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 3896/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:49\n",
      "\u001b[32m[03/31 12:49:54 d2.evaluation.evaluator]: \u001b[0mInference done 3901/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:43\n",
      "\u001b[32m[03/31 12:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 3906/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:38\n",
      "\u001b[32m[03/31 12:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 3911/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:33\n",
      "\u001b[32m[03/31 12:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 3916/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:27\n",
      "\u001b[32m[03/31 12:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 3921/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:22\n",
      "\u001b[32m[03/31 12:50:20 d2.evaluation.evaluator]: \u001b[0mInference done 3926/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:16\n",
      "\u001b[32m[03/31 12:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 3931/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:11\n",
      "\u001b[32m[03/31 12:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 3936/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:19:06\n",
      "\u001b[32m[03/31 12:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 3941/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:19:00\n",
      "\u001b[32m[03/31 12:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 3946/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:18:55\n",
      "\u001b[32m[03/31 12:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 3951/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:18:49\n",
      "\u001b[32m[03/31 12:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 3956/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:18:44\n",
      "\u001b[32m[03/31 12:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 3961/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0377 s/iter. Total: 1.0772 s/iter. ETA=0:18:39\n",
      "\u001b[32m[03/31 12:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 3966/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:18:33\n",
      "\u001b[32m[03/31 12:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 3971/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:18:28\n",
      "\u001b[32m[03/31 12:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 3976/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:18:22\n",
      "\u001b[32m[03/31 12:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 3981/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:18:17\n",
      "\u001b[32m[03/31 12:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 3986/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:18:12\n",
      "\u001b[32m[03/31 12:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 3991/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:18:06\n",
      "\u001b[32m[03/31 12:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 3996/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:18:01\n",
      "\u001b[32m[03/31 12:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 4001/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:17:55\n",
      "\u001b[32m[03/31 12:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 4006/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:17:50\n",
      "\u001b[32m[03/31 12:51:52 d2.evaluation.evaluator]: \u001b[0mInference done 4011/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:17:45\n",
      "\u001b[32m[03/31 12:51:57 d2.evaluation.evaluator]: \u001b[0mInference done 4016/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:17:39\n",
      "\u001b[32m[03/31 12:52:02 d2.evaluation.evaluator]: \u001b[0mInference done 4021/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:17:34\n",
      "\u001b[32m[03/31 12:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 4026/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:17:29\n",
      "\u001b[32m[03/31 12:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 4031/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:17:23\n",
      "\u001b[32m[03/31 12:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 4036/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:17:18\n",
      "\u001b[32m[03/31 12:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 4041/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:17:13\n",
      "\u001b[32m[03/31 12:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 4046/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:17:07\n",
      "\u001b[32m[03/31 12:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 4051/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:17:02\n",
      "\u001b[32m[03/31 12:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 4056/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:56\n",
      "\u001b[32m[03/31 12:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 4061/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:51\n",
      "\u001b[32m[03/31 12:52:51 d2.evaluation.evaluator]: \u001b[0mInference done 4066/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:46\n",
      "\u001b[32m[03/31 12:52:57 d2.evaluation.evaluator]: \u001b[0mInference done 4071/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:40\n",
      "\u001b[32m[03/31 12:53:02 d2.evaluation.evaluator]: \u001b[0mInference done 4076/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:35\n",
      "\u001b[32m[03/31 12:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 4081/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:29\n",
      "\u001b[32m[03/31 12:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 4086/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:24\n",
      "\u001b[32m[03/31 12:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 4091/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:16:19\n",
      "\u001b[32m[03/31 12:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 4096/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:16:13\n",
      "\u001b[32m[03/31 12:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 4101/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:16:08\n",
      "\u001b[32m[03/31 12:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 4106/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:16:03\n",
      "\u001b[32m[03/31 12:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 4111/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:57\n",
      "\u001b[32m[03/31 12:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 4116/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:15:52\n",
      "\u001b[32m[03/31 12:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 4121/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:46\n",
      "\u001b[32m[03/31 12:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 4126/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:41\n",
      "\u001b[32m[03/31 12:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 4131/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:36\n",
      "\u001b[32m[03/31 12:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 4136/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:30\n",
      "\u001b[32m[03/31 12:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 4141/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:25\n",
      "\u001b[32m[03/31 12:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 4146/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:15:19\n",
      "\u001b[32m[03/31 12:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 4151/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:15:14\n",
      "\u001b[32m[03/31 12:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 4156/5000. Dataloading: 0.0027 s/iter. Inference: 1.0367 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:09\n",
      "\u001b[32m[03/31 12:54:34 d2.evaluation.evaluator]: \u001b[0mInference done 4161/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:15:03\n",
      "\u001b[32m[03/31 12:54:39 d2.evaluation.evaluator]: \u001b[0mInference done 4166/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:58\n",
      "\u001b[32m[03/31 12:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 4171/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0379 s/iter. Total: 1.0773 s/iter. ETA=0:14:53\n",
      "\u001b[32m[03/31 12:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 4176/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:47\n",
      "\u001b[32m[03/31 12:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 4181/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0379 s/iter. Total: 1.0773 s/iter. ETA=0:14:42\n",
      "\u001b[32m[03/31 12:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 4186/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0379 s/iter. Total: 1.0773 s/iter. ETA=0:14:36\n",
      "\u001b[32m[03/31 12:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 4191/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:31\n",
      "\u001b[32m[03/31 12:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 4196/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:26\n",
      "\u001b[32m[03/31 12:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 4201/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:20\n",
      "\u001b[32m[03/31 12:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 4206/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:15\n",
      "\u001b[32m[03/31 12:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 4211/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:09\n",
      "\u001b[32m[03/31 12:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 4216/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:14:04\n",
      "\u001b[32m[03/31 12:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 4221/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:13:59\n",
      "\u001b[32m[03/31 12:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 4226/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0773 s/iter. ETA=0:13:53\n",
      "\u001b[32m[03/31 12:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 4231/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:48\n",
      "\u001b[32m[03/31 12:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 4236/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:42\n",
      "\u001b[32m[03/31 12:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 4241/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:13:37\n",
      "\u001b[32m[03/31 12:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 4246/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:32\n",
      "\u001b[32m[03/31 12:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 4251/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:26\n",
      "\u001b[32m[03/31 12:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 4256/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:13:21\n",
      "\u001b[32m[03/31 12:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 4261/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:16\n",
      "\u001b[32m[03/31 12:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 4266/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:10\n",
      "\u001b[32m[03/31 12:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 4271/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:13:05\n",
      "\u001b[32m[03/31 12:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 4276/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:59\n",
      "\u001b[32m[03/31 12:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 4281/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:12:54\n",
      "\u001b[32m[03/31 12:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 4286/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:12:49\n",
      "\u001b[32m[03/31 12:56:54 d2.evaluation.evaluator]: \u001b[0mInference done 4291/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:43\n",
      "\u001b[32m[03/31 12:56:59 d2.evaluation.evaluator]: \u001b[0mInference done 4296/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:38\n",
      "\u001b[32m[03/31 12:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 4301/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:32\n",
      "\u001b[32m[03/31 12:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 4306/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:27\n",
      "\u001b[32m[03/31 12:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 4311/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:22\n",
      "\u001b[32m[03/31 12:57:20 d2.evaluation.evaluator]: \u001b[0mInference done 4316/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:12:16\n",
      "\u001b[32m[03/31 12:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 4321/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:12:11\n",
      "\u001b[32m[03/31 12:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 4326/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0772 s/iter. ETA=0:12:06\n",
      "\u001b[32m[03/31 12:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 4331/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:12:00\n",
      "\u001b[32m[03/31 12:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 4336/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:11:55\n",
      "\u001b[32m[03/31 12:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 4341/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0771 s/iter. ETA=0:11:49\n",
      "\u001b[32m[03/31 12:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 4346/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:11:44\n",
      "\u001b[32m[03/31 12:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 4351/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:11:38\n",
      "\u001b[32m[03/31 12:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 4356/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:11:33\n",
      "\u001b[32m[03/31 12:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 4361/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:11:28\n",
      "\u001b[32m[03/31 12:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 4366/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:11:22\n",
      "\u001b[32m[03/31 12:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 4371/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:11:17\n",
      "\u001b[32m[03/31 12:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 4376/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:11:12\n",
      "\u001b[32m[03/31 12:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 4381/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:11:06\n",
      "\u001b[32m[03/31 12:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 4386/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:11:01\n",
      "\u001b[32m[03/31 12:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 4391/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:55\n",
      "\u001b[32m[03/31 12:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 4396/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:10:50\n",
      "\u001b[32m[03/31 12:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 4401/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0378 s/iter. Total: 1.0770 s/iter. ETA=0:10:45\n",
      "\u001b[32m[03/31 12:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 4406/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:39\n",
      "\u001b[32m[03/31 12:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 4411/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:34\n",
      "\u001b[32m[03/31 12:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 4416/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:28\n",
      "\u001b[32m[03/31 12:59:13 d2.evaluation.evaluator]: \u001b[0mInference done 4421/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:23\n",
      "\u001b[32m[03/31 12:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 4426/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:18\n",
      "\u001b[32m[03/31 12:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 4431/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:12\n",
      "\u001b[32m[03/31 12:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 4436/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:07\n",
      "\u001b[32m[03/31 12:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 4441/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:10:02\n",
      "\u001b[32m[03/31 12:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 4446/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:56\n",
      "\u001b[32m[03/31 12:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 4451/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:51\n",
      "\u001b[32m[03/31 12:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 4456/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:45\n",
      "\u001b[32m[03/31 12:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 4461/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:40\n",
      "\u001b[32m[03/31 13:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 4466/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:35\n",
      "\u001b[32m[03/31 13:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 4471/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:29\n",
      "\u001b[32m[03/31 13:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 4476/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:24\n",
      "\u001b[32m[03/31 13:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 4481/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:09:18\n",
      "\u001b[32m[03/31 13:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 4486/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:09:13\n",
      "\u001b[32m[03/31 13:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 4491/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:08\n",
      "\u001b[32m[03/31 13:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 4496/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:09:02\n",
      "\u001b[32m[03/31 13:00:39 d2.evaluation.evaluator]: \u001b[0mInference done 4501/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:08:57\n",
      "\u001b[32m[03/31 13:00:44 d2.evaluation.evaluator]: \u001b[0mInference done 4506/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:08:52\n",
      "\u001b[32m[03/31 13:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 4511/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:08:46\n",
      "\u001b[32m[03/31 13:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 4516/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:08:41\n",
      "\u001b[32m[03/31 13:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 4521/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:08:35\n",
      "\u001b[32m[03/31 13:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 4526/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:08:30\n",
      "\u001b[32m[03/31 13:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 4531/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:08:25\n",
      "\u001b[32m[03/31 13:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 4536/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:08:19\n",
      "\u001b[32m[03/31 13:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 4541/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:08:14\n",
      "\u001b[32m[03/31 13:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 4546/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0377 s/iter. Total: 1.0768 s/iter. ETA=0:08:08\n",
      "\u001b[32m[03/31 13:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 4551/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:08:03\n",
      "\u001b[32m[03/31 13:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 4556/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:07:58\n",
      "\u001b[32m[03/31 13:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 4561/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:07:52\n",
      "\u001b[32m[03/31 13:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 4566/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:07:47\n",
      "\u001b[32m[03/31 13:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 4571/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:07:42\n",
      "\u001b[32m[03/31 13:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 4576/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:07:36\n",
      "\u001b[32m[03/31 13:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 4581/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:07:31\n",
      "\u001b[32m[03/31 13:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 4586/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:07:25\n",
      "\u001b[32m[03/31 13:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 4591/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:07:20\n",
      "\u001b[32m[03/31 13:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 4596/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:07:15\n",
      "\u001b[32m[03/31 13:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 4601/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:07:09\n",
      "\u001b[32m[03/31 13:02:32 d2.evaluation.evaluator]: \u001b[0mInference done 4606/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:07:04\n",
      "\u001b[32m[03/31 13:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 4611/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:58\n",
      "\u001b[32m[03/31 13:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 4616/5000. Dataloading: 0.0027 s/iter. Inference: 1.0363 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:53\n",
      "\u001b[32m[03/31 13:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 4621/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:48\n",
      "\u001b[32m[03/31 13:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 4626/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:42\n",
      "\u001b[32m[03/31 13:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 4631/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:37\n",
      "\u001b[32m[03/31 13:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 4636/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:06:31\n",
      "\u001b[32m[03/31 13:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 4641/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:26\n",
      "\u001b[32m[03/31 13:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 4646/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:21\n",
      "\u001b[32m[03/31 13:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 4651/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:06:15\n",
      "\u001b[32m[03/31 13:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 4656/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:06:10\n",
      "\u001b[32m[03/31 13:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 4661/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:06:05\n",
      "\u001b[32m[03/31 13:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 4666/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:05:59\n",
      "\u001b[32m[03/31 13:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 4671/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:05:54\n",
      "\u001b[32m[03/31 13:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 4676/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:48\n",
      "\u001b[32m[03/31 13:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 4681/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:43\n",
      "\u001b[32m[03/31 13:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 4686/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:38\n",
      "\u001b[32m[03/31 13:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 4691/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:32\n",
      "\u001b[32m[03/31 13:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 4696/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:27\n",
      "\u001b[32m[03/31 13:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 4701/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:22\n",
      "\u001b[32m[03/31 13:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 4706/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:05:16\n",
      "\u001b[32m[03/31 13:04:25 d2.evaluation.evaluator]: \u001b[0mInference done 4711/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:11\n",
      "\u001b[32m[03/31 13:04:30 d2.evaluation.evaluator]: \u001b[0mInference done 4716/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:05:05\n",
      "\u001b[32m[03/31 13:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 4721/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:05:00\n",
      "\u001b[32m[03/31 13:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 4726/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:04:55\n",
      "\u001b[32m[03/31 13:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 4731/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:04:49\n",
      "\u001b[32m[03/31 13:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 4736/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:04:44\n",
      "\u001b[32m[03/31 13:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 4741/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:04:38\n",
      "\u001b[32m[03/31 13:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 4746/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:04:33\n",
      "\u001b[32m[03/31 13:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 4751/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:04:28\n",
      "\u001b[32m[03/31 13:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 4756/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:04:22\n",
      "\u001b[32m[03/31 13:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 4761/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:04:17\n",
      "\u001b[32m[03/31 13:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 4766/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:04:12\n",
      "\u001b[32m[03/31 13:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 4771/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:04:06\n",
      "\u001b[32m[03/31 13:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 4776/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:04:01\n",
      "\u001b[32m[03/31 13:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 4781/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:03:55\n",
      "\u001b[32m[03/31 13:05:46 d2.evaluation.evaluator]: \u001b[0mInference done 4786/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:03:50\n",
      "\u001b[32m[03/31 13:05:51 d2.evaluation.evaluator]: \u001b[0mInference done 4791/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:03:45\n",
      "\u001b[32m[03/31 13:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 4796/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:03:39\n",
      "\u001b[32m[03/31 13:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 4801/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:03:34\n",
      "\u001b[32m[03/31 13:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 4806/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:03:28\n",
      "\u001b[32m[03/31 13:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 4811/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0771 s/iter. ETA=0:03:23\n",
      "\u001b[32m[03/31 13:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 4816/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:03:18\n",
      "\u001b[32m[03/31 13:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 4821/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:03:12\n",
      "\u001b[32m[03/31 13:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 4826/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:03:07\n",
      "\u001b[32m[03/31 13:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 4832/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:03:00\n",
      "\u001b[32m[03/31 13:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 4837/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:02:55\n",
      "\u001b[32m[03/31 13:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 4842/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:02:50\n",
      "\u001b[32m[03/31 13:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 4847/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:02:44\n",
      "\u001b[32m[03/31 13:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 4852/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:02:39\n",
      "\u001b[32m[03/31 13:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 4857/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:02:34\n",
      "\u001b[32m[03/31 13:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 4862/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0377 s/iter. Total: 1.0769 s/iter. ETA=0:02:28\n",
      "\u001b[32m[03/31 13:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 4867/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:02:23\n",
      "\u001b[32m[03/31 13:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 4872/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:02:17\n",
      "\u001b[32m[03/31 13:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 4877/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:02:12\n",
      "\u001b[32m[03/31 13:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 4882/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:02:07\n",
      "\u001b[32m[03/31 13:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 4887/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:02:01\n",
      "\u001b[32m[03/31 13:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 4892/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:56\n",
      "\u001b[32m[03/31 13:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 4897/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:01:50\n",
      "\u001b[32m[03/31 13:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 4902/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:01:45\n",
      "\u001b[32m[03/31 13:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 4907/5000. Dataloading: 0.0027 s/iter. Inference: 1.0364 s/iter. Eval: 0.0376 s/iter. Total: 1.0769 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/31 13:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 4912/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/31 13:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 4917/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/31 13:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 4922/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/31 13:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 4927/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:18\n",
      "\u001b[32m[03/31 13:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 4932/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:13\n",
      "\u001b[32m[03/31 13:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 4937/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:07\n",
      "\u001b[32m[03/31 13:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 4942/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0377 s/iter. Total: 1.0770 s/iter. ETA=0:01:02\n",
      "\u001b[32m[03/31 13:08:39 d2.evaluation.evaluator]: \u001b[0mInference done 4947/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:57\n",
      "\u001b[32m[03/31 13:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 4952/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:51\n",
      "\u001b[32m[03/31 13:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 4957/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/31 13:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 4962/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:40\n",
      "\u001b[32m[03/31 13:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 4967/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/31 13:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 4972/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:30\n",
      "\u001b[32m[03/31 13:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 4977/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/31 13:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 4982/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/31 13:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 4987/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/31 13:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 4992/5000. Dataloading: 0.0027 s/iter. Inference: 1.0366 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/31 13:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 4997/5000. Dataloading: 0.0027 s/iter. Inference: 1.0365 s/iter. Eval: 0.0376 s/iter. Total: 1.0770 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/31 13:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 1:29:39.667733 (1.077011 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/31 13:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 1:26:17 (1.036551 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/31 13:09:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/31 13:09:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to tools/output/SOTR_R101/inference/coco_instances_results.json\n",
      "\u001b[32m[03/31 13:09:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.30s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/31 13:09:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/31 13:09:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 10.22 seconds.\n",
      "\u001b[32m[03/31 13:09:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/31 13:09:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 1.38 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/31 13:09:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[03/31 13:09:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP    | category     | AP    | category       | AP    |\n",
      "|:--------------|:------|:-------------|:------|:---------------|:------|\n",
      "| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |\n",
      "| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |\n",
      "| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |\n",
      "| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |\n",
      "| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |\n",
      "| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |\n",
      "| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |\n",
      "| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |\n",
      "| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |\n",
      "| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |\n",
      "| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |\n",
      "| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |\n",
      "| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |\n",
      "| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |\n",
      "| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |\n",
      "| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |\n",
      "| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |\n",
      "| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |\n",
      "| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |\n",
      "| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |\n",
      "| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |\n",
      "| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |\n",
      "| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |\n",
      "| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |\n",
      "| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |\n",
      "| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |\n",
      "| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=3.35s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/31 13:10:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[03/31 13:10:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 14.15 seconds.\n",
      "\u001b[32m[03/31 13:10:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/31 13:10:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 1.46 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.427\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.504\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730\n",
      "\u001b[32m[03/31 13:10:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.728 | 60.301 | 42.698 | 18.040 | 43.414 | 59.797 |\n",
      "\u001b[32m[03/31 13:10:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category      | AP     | category     | AP     | category       | AP     |\n",
      "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
      "| person        | 47.927 | bicycle      | 21.331 | car            | 40.839 |\n",
      "| motorcycle    | 37.318 | airplane     | 56.021 | bus            | 67.146 |\n",
      "| train         | 68.519 | truck        | 39.466 | boat           | 25.682 |\n",
      "| traffic light | 25.169 | fire hydrant | 64.607 | stop sign      | 62.935 |\n",
      "| parking meter | 45.868 | bench        | 19.649 | bird           | 30.987 |\n",
      "| cat           | 72.267 | dog          | 61.946 | horse          | 49.158 |\n",
      "| sheep         | 48.971 | cow          | 49.913 | elephant       | 63.832 |\n",
      "| bear          | 75.786 | zebra        | 64.723 | giraffe        | 60.166 |\n",
      "| backpack      | 17.877 | umbrella     | 50.054 | handbag        | 15.829 |\n",
      "| tie           | 32.925 | suitcase     | 43.603 | frisbee        | 61.438 |\n",
      "| skis          | 7.638  | snowboard    | 25.069 | sports ball    | 39.248 |\n",
      "| kite          | 31.932 | baseball bat | 26.439 | baseball glove | 38.891 |\n",
      "| skateboard    | 38.872 | surfboard    | 34.453 | tennis racket  | 57.338 |\n",
      "| bottle        | 33.943 | wine glass   | 32.647 | cup            | 41.974 |\n",
      "| fork          | 22.518 | knife        | 15.894 | spoon          | 12.914 |\n",
      "| bowl          | 40.995 | banana       | 20.155 | apple          | 19.696 |\n",
      "| sandwich      | 38.750 | orange       | 29.807 | broccoli       | 24.832 |\n",
      "| carrot        | 22.072 | hot dog      | 31.380 | pizza          | 52.158 |\n",
      "| donut         | 49.781 | cake         | 38.403 | chair          | 22.180 |\n",
      "| couch         | 42.165 | potted plant | 23.880 | bed            | 36.722 |\n",
      "| dining table  | 19.606 | toilet       | 62.896 | tv             | 61.438 |\n",
      "| laptop        | 63.107 | mouse        | 58.997 | remote         | 32.117 |\n",
      "| keyboard      | 51.392 | cell phone   | 35.692 | microwave      | 57.478 |\n",
      "| oven          | 36.585 | toaster      | 36.242 | sink           | 37.628 |\n",
      "| refrigerator  | 62.289 | book         | 6.940  | clock          | 49.591 |\n",
      "| vase          | 34.381 | scissors     | 25.109 | teddy bear     | 48.300 |\n",
      "| hair drier    | 4.674  | toothbrush   | 19.120 |                |        |\n",
      "\u001b[32m[03/31 13:10:25 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
      "\u001b[32m[03/31 13:10:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/31 13:10:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/31 13:10:25 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[03/31 13:10:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/31 13:10:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/31 13:10:25 d2.evaluation.testing]: \u001b[0mcopypaste: 39.7285,60.3010,42.6983,18.0405,43.4145,59.7968\n"
     ]
    }
   ],
   "source": [
    "!python tools/train_net.py \\\n",
    "    --config-file configs/SOTR/R101.yaml \\\n",
    "    --eval-only \\\n",
    "    MODEL.WEIGHTS /content/drive/MyDrive/SOTR_R101.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpSdKKhDq-Pb"
   },
   "outputs": [],
   "source": [
    "!python tools/train_net.py \\\n",
    "    --config-file configs/SOTR/R50.yaml \\\n",
    "    #--num-gpus 1\\"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Untitled11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
